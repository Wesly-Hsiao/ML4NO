{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 244)]             0         \n",
      "_________________________________________________________________\n",
      "multi_category_encoding (Mul (None, 244)               0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 244)               489       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              250880    \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                32800     \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "regression_head_1 (Dense)    (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 284,202\n",
      "Trainable params: 283,713\n",
      "Non-trainable params: 489\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/home/ML4NO/Data/n1000000_0804_all_flat.npz')\n",
    "model = tf.keras.models.load_model('/home/ML4NO/ML/Regression/models_furthurTrain/0804_theta23_5.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_all = np.column_stack([data['ve_dune'], data['vu_dune'], data['vebar_dune'], data['vubar_dune'], data['ve_t2hk'], data['vu_t2hk'], data['vebar_t2hk'], data['vubar_t2hk']])\n",
    "target = data['theta23']\n",
    "\n",
    "x_train = data_all[:10000]\n",
    "y_train = target[:10000]\n",
    "x_train2 = data_all[10000:900000]\n",
    "y_train2 = target[10000:900000]\n",
    "x_test = data_all[900000:]\n",
<<<<<<< HEAD
    "y_test = target[900000:]"
=======
    "y_test = target[900000:]\n",
    "num_of_bins = len(x_train[0])"
>>>>>>> e1adf89c0bf7950f6a6540a1a2975aea111f02fd
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, target):\n",
    "    yield (np.random.poisson(data), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
>>>>>>> e1adf89c0bf7950f6a6540a1a2975aea111f02fd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 1/2\n",
      "12516/12516 [==============================] - 197s 16ms/step - loss: 0.7791 - mean_squared_error: 0.7791 - val_loss: 0.5217 - val_mean_squared_error: 0.5217\n",
      "Epoch 2/2\n",
      "12516/12516 [==============================] - 188s 15ms/step - loss: 0.4812 - mean_squared_error: 0.4812 - val_loss: 0.4432 - val_mean_squared_error: 0.4432\n",
      "Epoch 1/2\n",
      "12516/12516 [==============================] - 192s 15ms/step - loss: 0.4320 - mean_squared_error: 0.4320 - val_loss: 0.4337 - val_mean_squared_error: 0.4337\n",
      "Epoch 2/2\n",
      "12516/12516 [==============================] - 194s 15ms/step - loss: 0.4058 - mean_squared_error: 0.4058 - val_loss: 0.4056 - val_mean_squared_error: 0.4056\n",
      "Epoch 1/2\n",
      "12516/12516 [==============================] - 189s 15ms/step - loss: 0.3989 - mean_squared_error: 0.3989 - val_loss: 0.4154 - val_mean_squared_error: 0.4154\n",
      "Epoch 2/2\n",
      "12516/12516 [==============================] - 193s 15ms/step - loss: 0.3886 - mean_squared_error: 0.3886 - val_loss: 0.3849 - val_mean_squared_error: 0.3849\n",
      "Epoch 1/2\n",
      "12516/12516 [==============================] - 193s 15ms/step - loss: 0.3898 - mean_squared_error: 0.3898 - val_loss: 0.3754 - val_mean_squared_error: 0.3754\n",
      "Epoch 2/2\n",
      "12516/12516 [==============================] - 192s 15ms/step - loss: 0.3812 - mean_squared_error: 0.3812 - val_loss: 0.3798 - val_mean_squared_error: 0.3798\n",
      "Epoch 1/2\n",
      "12516/12516 [==============================] - 192s 15ms/step - loss: 0.3868 - mean_squared_error: 0.3868 - val_loss: 0.3792 - val_mean_squared_error: 0.3792\n",
      "Epoch 2/2\n",
      " 2546/12516 [=====>........................] - ETA: 2:15 - loss: 0.3706 - mean_squared_error: 0.3706"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12516/12516 [==============================] - 187s 15ms/step - loss: 0.3796 - mean_squared_error: 0.3796 - val_loss: 0.3733 - val_mean_squared_error: 0.3733\n",
      "Epoch 2/2\n",
      " 3373/12516 [=======>......................] - ETA: 2:11 - loss: 0.3721 - mean_squared_error: 0.3721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12516/12516 [==============================] - 190s 15ms/step - loss: 0.3766 - mean_squared_error: 0.3766 - val_loss: 0.3643 - val_mean_squared_error: 0.3643\n",
      "Epoch 2/2\n",
      "12516/12516 [==============================] - 192s 15ms/step - loss: 0.3694 - mean_squared_error: 0.3694 - val_loss: 0.3781 - val_mean_squared_error: 0.3781\n",
      "Epoch 1/2\n",
      "12516/12516 [==============================] - 195s 16ms/step - loss: 0.3754 - mean_squared_error: 0.3754 - val_loss: 0.3755 - val_mean_squared_error: 0.3755\n",
      "Epoch 2/2\n",
      "12516/12516 [==============================] - 193s 15ms/step - loss: 0.3684 - mean_squared_error: 0.3684 - val_loss: 0.3754 - val_mean_squared_error: 0.3754\n",
      "Epoch 1/2\n",
      "12516/12516 [==============================] - 190s 15ms/step - loss: 0.3742 - mean_squared_error: 0.3742 - val_loss: 0.3736 - val_mean_squared_error: 0.3736\n",
      "Epoch 2/2\n",
      "12516/12516 [==============================] - 188s 15ms/step - loss: 0.3670 - mean_squared_error: 0.3670 - val_loss: 0.3690 - val_mean_squared_error: 0.3690\n",
      "Epoch 1/2\n",
      "12516/12516 [==============================] - 188s 15ms/step - loss: 0.3723 - mean_squared_error: 0.3723 - val_loss: 0.3670 - val_mean_squared_error: 0.3670\n",
      "Epoch 2/2\n",
      "12516/12516 [==============================] - 192s 15ms/step - loss: 0.3645 - mean_squared_error: 0.3645 - val_loss: 0.3668 - val_mean_squared_error: 0.3668\n",
      "3125/3125 [==============================] - 36s 11ms/step - loss: 0.3683 - mean_squared_error: 0.3683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3682902455329895, 0.3682902455329895]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_gen = np.random.poisson(x_test)\n",
    "for i in range(10):\n",
    "    x_train2_gen = np.random.poisson(x_train2)\n",
    "    \n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "              validation_split=0.1,\n",
    "               batch_size=64,\n",
    "               epochs=2,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "model.evaluate(x_test_gen, y_test)"
=======
      "1/1 [==============================] - 0s 283ms/step - loss: 38.9507 - mean_squared_error: 38.9507\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1f60eb66f85a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m            \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m          )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bba0a19ccfa9>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(data, target)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.poisson\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.int64_to_long\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36misscalar\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m   1814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1816\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1817\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.evaluate(generator(x_test, y_test))\n",
    "\n",
    "model.fit(generator(x_train2, y_train2),\n",
    "           batch_size=64,\n",
    "           epochs=20,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "         )\n",
    "\n",
    "model.evaluate(generator(x_test, y_test))"
>>>>>>> e1adf89c0bf7950f6a6540a1a2975aea111f02fd
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = '/home/ML4NO/ML/Regression/models_PoissonTrain/0804_theta23_5_3.h5'\n",
=======
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = '/home/ML4NO/ML/Regression/models_PoissonTrain/0804_theta23_5_2.h5'\n",
>>>>>>> e1adf89c0bf7950f6a6540a1a2975aea111f02fd
    "if not os.path.isfile(modelname):\n",
    "    model.save(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
