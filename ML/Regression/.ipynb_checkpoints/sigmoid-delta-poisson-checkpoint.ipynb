{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import autokeras as ak\n",
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "%config InlineBackend. figure_format = 'retina'\n",
    "\n",
    "# Install TensorFlow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten , Convolution2D, MaxPooling2D , Lambda, Conv2D, Activation,Concatenate, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam , SGD , Adagrad\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers , initializers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.load('/work/n1000000_0804_all_flat.npz')\n",
    "cut_index = np.load('/work/NIO_largerthan1000_index.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_state = 2\n",
    "target = data['delta']\n",
    "if input_state == 0:\n",
    "    data_all = data['ve_dune']\n",
    "elif input_state == 1:\n",
    "    data_all = np.column_stack([data['ve_dune'], data['vu_dune'], data['vebar_dune'], data['vubar_dune']])\n",
    "elif input_state == 2:\n",
    "    data_all = np.column_stack([data['ve_dune'], data['vu_dune'], data['vebar_dune'], data['vubar_dune'], data['ve_t2hk'], data['vu_t2hk'], data['vebar_t2hk'], data['vubar_t2hk']])\n",
    "\n",
    "x_train = data_all[:10000, cut_index]\n",
    "y_train = target[:10000]\n",
    "x_train2 = data_all[10000:900000, cut_index]\n",
    "y_train2 = target[10000:900000]\n",
    "x_test = data_all[900000:, cut_index]\n",
    "y_test = target[900000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = 10\n",
    "num_of_bins = len(x_train[0])\n",
    "x_train_gen = np.reshape(np.random.normal(x_train, np.sqrt(x_train), size = (generate, len(x_train), num_of_bins)), (generate*len(x_train), num_of_bins))\n",
    "y_train_gen = np.repeat(y_train, generate)\n",
    "x_train2_gen = np.reshape(np.random.normal(x_train2, np.sqrt(x_train2), size = (generate, len(x_train2), num_of_bins)), (generate*len(x_train2), num_of_bins))\n",
    "y_train2_gen = np.repeat(y_train2, generate)\n",
    "x_test_gen = np.reshape(np.random.normal(x_test, np.sqrt(x_test), size = (generate, len(x_test), num_of_bins)), (generate*len(x_test), num_of_bins))\n",
    "y_test_gen = np.repeat(y_test, generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 17)                68        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4608      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 37,701\n",
      "Trainable params: 37,667\n",
      "Non-trainable params: 34\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (num_of_bins,)\n",
    "model = Sequential(name = 'Sequential')\n",
    "model.add(BatchNormalization(input_shape=input_shape))\n",
    "model.add(Dense(32, activation='relu', name = 'dense_1'))\n",
    "model.add(Dense(128, activation='relu', name = 'dense_2'))\n",
    "model.add(Dense(1, activation='sigmoid', name = 'dense_3'))\n",
    "model_opt = keras.optimizers.Adadelta()\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "                   optimizer=model_opt,\n",
    "                   metrics=[\"accuracy\",\"mse\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 2.1493e-05 - accuracy: 0.0000e+00 - mse: 43103.9336 - val_loss: 2.1591e-05 - val_accuracy: 0.0000e+00 - val_mse: 43218.0664\n",
      "Epoch 2/5\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 2.1493e-05 - accuracy: 0.0000e+00 - mse: 43103.9336 - val_loss: 2.1591e-05 - val_accuracy: 0.0000e+00 - val_mse: 43153.5703\n",
      "Epoch 3/5\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 2.1493e-05 - accuracy: 0.0000e+00 - mse: 43103.9414 - val_loss: 2.1591e-05 - val_accuracy: 0.0000e+00 - val_mse: 43146.8711\n",
      "Epoch 4/5\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 2.1493e-05 - accuracy: 0.0000e+00 - mse: 43103.9375 - val_loss: 2.1591e-05 - val_accuracy: 0.0000e+00 - val_mse: 43146.2031\n",
      "Epoch 5/5\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 2.1493e-05 - accuracy: 0.0000e+00 - mse: 43103.9492 - val_loss: 2.1591e-05 - val_accuracy: 0.0000e+00 - val_mse: 43146.0781\n"
     ]
    }
   ],
   "source": [
    "History = model.fit(x_train_gen, y_train_gen,\n",
    "               validation_split = 0.1,\n",
    "               batch_size=512,\n",
    "               epochs=5,\n",
    "               verbose=1\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42631897],\n",
       "       [0.49399808],\n",
       "       [0.5206355 ],\n",
       "       ...,\n",
       "       [0.41215003],\n",
       "       [0.425066  ],\n",
       "       [0.4996284 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 08s]\n",
      "val_loss: 12630.029296875\n",
      "\n",
      "Best val_loss So Far: 12630.029296875\n",
      "Total elapsed time: 00h 00m 08s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "dense_block_1/u...|False             |False             \n",
      "dense_block_1/n...|2                 |2                 \n",
      "dense_block_1/u...|32                |32                \n",
      "dense_block_1/d...|0.25              |0                 \n",
      "dense_block_1/u...|32                |32                \n",
      "regression_head...|0                 |0                 \n",
      "optimizer         |adam              |adam              \n",
      "learning_rate     |0.001             |0.001             \n",
      "\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1/2\n",
      "1039/1407 [=====================>........] - ETA: 0s - loss: 48521.5977 - mean_squared_error: 48521.5977"
     ]
    }
   ],
   "source": [
    "clf.fit(x_train_gen, y_train_gen,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=2,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x_train2_gen, y_train2_gen,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=20,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test_gen, y_test_gen)\n",
    "pre_test = model.predict(x_test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pre_test, histtype = 'step', bins = 100, label = 'prediction')\n",
    "plt.hist(y_test, histtype = 'step', bins = 100, label = 'target')\n",
    "plt.xlabel('delta')\n",
    "plt.ylabel('number')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(pre_test, y_test, '.', alpha = 0.05)\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('target')\n",
    "plt.title('delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if input_state == 0:\n",
    "    modelname = '/work/Regression/models_ve_dune/0803_delta4.h5'\n",
    "    if not os.path.isfile(modelname):\n",
    "        model.save(modelname)\n",
    "elif input_state == 1:\n",
    "    modelname = '/work/Regression/models_all_dune/0803_delta2.h5'\n",
    "    if not os.path.isfile(modelname):\n",
    "        model.save(modelname)\n",
    "elif input_state == 2:\n",
    "    modelname = '/work/Regression/models_all/0804_delta2.h5'\n",
    "    if not os.path.isfile(modelname):\n",
    "        model.save(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_state == 0:\n",
    "    modelname = '/work/Regression/models_ve_dune/0803_delta1.h5'\n",
    "    if not os.path.isfile(modelname):\n",
    "        model.save(modelname)\n",
    "elif input_state == 1:\n",
    "    modelname = '/work/Regression/models_all_dune/0803_delta1.h5'\n",
    "    if not os.path.isfile(modelname):\n",
    "        model.save(modelname)\n",
    "elif input_state == 2:\n",
    "    modelname = '/work/ML4NO/ML/Regression/perturb_cut/0804_cut1000_delta1.h5'\n",
    "    if not os.path.isfile(modelname):\n",
    "        model.save(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
