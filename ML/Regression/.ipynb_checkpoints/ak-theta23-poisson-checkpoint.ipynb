{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import autokeras as ak\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.load('/work/n1000000_0804_all_flat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_state = 2\n",
    "target = data['theta23']\n",
    "if input_state == 0:\n",
    "    data_all = data['ve_dune']\n",
    "elif input_state == 1:\n",
    "    data_all = np.column_stack([data['ve_dune'], data['vu_dune'], data['vebar_dune'], data['vubar_dune']])\n",
    "elif input_state == 2:\n",
    "    data_all = np.column_stack([data['ve_dune'], data['vu_dune'], data['vebar_dune'], data['vubar_dune'], data['ve_t2hk'], data['vu_t2hk'], data['vebar_t2hk'], data['vubar_t2hk']])\n",
    "\n",
    "x_train = data_all[:10000]\n",
    "y_train = target[:10000]\n",
    "x_train2 = data_all[10000:900000]\n",
    "y_train2 = target[10000:900000]\n",
    "x_test = data_all[900000:]\n",
    "y_test = target[900000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 Complete [00h 00m 35s]\n",
      "val_loss: 0.00550146633759141\n",
      "\n",
      "Best val_loss So Far: 0.00392884761095047\n",
      "Total elapsed time: 00h 24m 24s\n",
      "\n",
      "Search: Running Trial #44\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "structured_data...|True              |True              \n",
      "structured_data...|True              |False             \n",
      "structured_data...|3                 |3                 \n",
      "structured_data...|256               |256               \n",
      "structured_data...|0                 |0                 \n",
      "structured_data...|1024              |1024              \n",
      "regression_head...|0                 |0                 \n",
      "optimizer         |adam_weight_decay |adam_weight_decay \n",
      "learning_rate     |0.01              |0.01              \n",
      "structured_data...|32                |32                \n",
      "\n",
      "WARNING:tensorflow:Layer multi_category_encoding is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 1740.8431 - mean_squared_error: 1740.8431 - val_loss: 1014.1807 - val_mean_squared_error: 1014.1807\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 323.0168 - mean_squared_error: 323.0168 - val_loss: 89.3426 - val_mean_squared_error: 89.3426\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 1.5493 - mean_squared_error: 1.5493 - val_loss: 4.1247 - val_mean_squared_error: 4.1247\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.9376 - mean_squared_error: 0.9376 - val_loss: 1.4463 - val_mean_squared_error: 1.4463\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.8029 - mean_squared_error: 0.8029 - val_loss: 0.9457 - val_mean_squared_error: 0.9457\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.7522 - mean_squared_error: 0.7522 - val_loss: 0.7288 - val_mean_squared_error: 0.7288\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.7288 - mean_squared_error: 0.7288 - val_loss: 0.6792 - val_mean_squared_error: 0.6792\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.5106 - mean_squared_error: 0.5106 - val_loss: 0.3136 - val_mean_squared_error: 0.3136\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.4217 - mean_squared_error: 0.4217 - val_loss: 0.2173 - val_mean_squared_error: 0.2173\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.3766 - mean_squared_error: 0.3766 - val_loss: 0.2142 - val_mean_squared_error: 0.2142\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.3624 - mean_squared_error: 0.3624 - val_loss: 0.2334 - val_mean_squared_error: 0.2334\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.3403 - mean_squared_error: 0.3403 - val_loss: 0.1651 - val_mean_squared_error: 0.1651\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.2878 - mean_squared_error: 0.2878 - val_loss: 0.1728 - val_mean_squared_error: 0.1728\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.2420 - mean_squared_error: 0.2420 - val_loss: 0.0999 - val_mean_squared_error: 0.0999\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.2387 - mean_squared_error: 0.2387 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.2412 - mean_squared_error: 0.2412 - val_loss: 0.0444 - val_mean_squared_error: 0.0444\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.2162 - mean_squared_error: 0.2162 - val_loss: 0.0723 - val_mean_squared_error: 0.0723\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.1808 - mean_squared_error: 0.1808 - val_loss: 0.0414 - val_mean_squared_error: 0.0414\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 0.1438 - mean_squared_error: 0.1438 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
      "Epoch 20/20\n",
      " 51/142 [=========>....................] - ETA: 1s - loss: 0.1501 - mean_squared_error: 0.1501"
     ]
    }
   ],
   "source": [
    "clf = ak.StructuredDataRegressor(overwrite=True, max_trials=50)\n",
    "clf.fit(x_train, y_train,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=20,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x_train2, y_train2,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=20,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)\n",
    "pre_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(pre_test, histtype = 'step', bins = 100, label = 'prediction')\n",
    "plt.hist(y_test, histtype = 'step', bins = 100, label = 'target')\n",
    "plt.xlabel('theta23')\n",
    "plt.ylabel('number')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(pre_test, y_test, '.', alpha = 0.05)\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('target')\n",
    "plt.title('theta23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if input_state == 0:\n",
    "    modelname = '/work/Regression/models_ve_dune/0803_theta23_1.h5'\n",
    "    if not os.path.isfile(modelname):\n",
    "        model.save(modelname)\n",
    "elif input_state == 1:\n",
    "    modelname = '/work/Regression/models_all_dune/0803_theta23_1.h5'\n",
    "    if not os.path.isfile(modelname):\n",
    "        model.save(modelname)\n",
    "elif input_state == 2:\n",
    "    modelname = '/work/Regression/models_all/0804_theta23_1.h5'\n",
    "    if not os.path.isfile(modelname):\n",
    "        model.save(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
