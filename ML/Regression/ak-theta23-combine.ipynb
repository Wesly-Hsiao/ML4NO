{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import os\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.load('/home/ML4NO/Data/n1000000_0910_all_flat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_all = np.column_stack([data['ve_dune'], data['vu_dune'], data['vebar_dune'], data['vubar_dune'], data['ve_t2hk'], data['vu_t2hk'], data['vebar_t2hk'], data['vubar_t2hk']])\n",
    "target = data['theta23']\n",
    "\n",
    "x_train = data_all[:10000]\n",
    "y_train = target[:10000]\n",
    "\n",
    "x_train2 = data_all[10000:900000]\n",
    "y_train2 = target[10000:900000]\n",
    "\n",
    "x_test = data_all[900000:]\n",
    "y_test = target[900000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 01m 01s]\n",
      "val_loss: 0.007453565951436758\n",
      "\n",
      "Best val_loss So Far: 0.005114410072565079\n",
      "Total elapsed time: 00h 48m 10s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/20\n",
      "157/157 [==============================] - 5s 16ms/step - loss: 863.1394 - mean_squared_error: 863.1394\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 16.2109 - mean_squared_error: 16.2109\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 7.8313 - mean_squared_error: 7.8313\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 7.6371 - mean_squared_error: 7.6371\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 4.7101 - mean_squared_error: 4.7101\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 6.4930 - mean_squared_error: 6.4930\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 5.2365 - mean_squared_error: 5.2365\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 3.5811 - mean_squared_error: 3.5811\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 2.7215 - mean_squared_error: 2.7215\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.9858 - mean_squared_error: 0.9858\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.7101 - mean_squared_error: 1.7101\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.6615 - mean_squared_error: 0.6615\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.9360 - mean_squared_error: 0.9360\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.6347 - mean_squared_error: 0.6347\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.5365 - mean_squared_error: 0.5365\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.2836 - mean_squared_error: 0.2836\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.2018 - mean_squared_error: 0.2018\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.1226 - mean_squared_error: 0.1226\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0526 - mean_squared_error: 0.0526\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0150 - mean_squared_error: 0.0150\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: ./structured_data_regressor/best_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1cf031bd30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ak.StructuredDataRegressor(overwrite=True, max_trials=50)\n",
    "clf.fit(x_train, y_train,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=20,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 304)]             0         \n",
      "_________________________________________________________________\n",
      "multi_category_encoding (Mul (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 304)               609       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                9760      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "regression_head_1 (Dense)    (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 283,010\n",
      "Trainable params: 282,401\n",
      "Non-trainable params: 609\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12516/12516 [==============================] - 223s 18ms/step - loss: 0.1808 - mean_squared_error: 0.1808 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 2/20\n",
      "12516/12516 [==============================] - 219s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 3/20\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 4/20\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 5/20\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 6/20\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 7/20\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 8/20\n",
      "12516/12516 [==============================] - 221s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 9/20\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 10/20\n",
      "12516/12516 [==============================] - 221s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 11/20\n",
      "12516/12516 [==============================] - 221s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 12/20\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 13/20\n",
      "12516/12516 [==============================] - 219s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 14/20\n",
      "12516/12516 [==============================] - 221s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 15/20\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 16/20\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 17/20\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 18/20\n",
      "12516/12516 [==============================] - 219s 17ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 19/20\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 20/20\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1ccc419080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train2, y_train2,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=20,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "while os.path.isfile('/home/ML4NO/ML/Regression/models/0910_theta23_{}.h5'.format(index)):\n",
    "    index += 1\n",
    "model.save('/home/ML4NO/ML/Regression/models/0910_theta23_{}.h5'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 38s 12ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 219s 18ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 218s 17ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 219s 18ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 219s 18ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 221s 18ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 221s 18ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 219s 18ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 218s 17ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 220s 18ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 218s 17ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 209s 17ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 208s 17ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 209s 17ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 208s 17ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "3125/3125 [==============================] - 35s 11ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0146 - mean_squared_error: 0.0146\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 222s 18ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 223s 18ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 0.0146 - mean_squared_error: 0.0146\n",
      "3125/3125 [==============================] - 35s 11ms/step - loss: 0.0208 - mean_squared_error: 0.0208\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 222s 18ms/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 219s 18ms/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 218s 17ms/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0208 - mean_squared_error: 0.0208\n",
      "3125/3125 [==============================] - 39s 13ms/step - loss: 0.0312 - mean_squared_error: 0.0312\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 223s 18ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0312 - mean_squared_error: 0.0312\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0479 - mean_squared_error: 0.0479\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 219s 17ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 221s 18ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 209s 17ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0479 - mean_squared_error: 0.0479\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 0.0752 - mean_squared_error: 0.0752\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 0.0743 - mean_squared_error: 0.0743 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 0.0743 - mean_squared_error: 0.0743 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 0.0743 - mean_squared_error: 0.0743 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 0.0743 - mean_squared_error: 0.0743 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 0.0743 - mean_squared_error: 0.0743 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "3125/3125 [==============================] - 39s 13ms/step - loss: 0.0752 - mean_squared_error: 0.0752\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 0.1175 - mean_squared_error: 0.1175\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 0.1174 - mean_squared_error: 0.1174 - val_loss: 0.1174 - val_mean_squared_error: 0.1174\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 0.1174 - mean_squared_error: 0.1174 - val_loss: 0.1174 - val_mean_squared_error: 0.1174\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 0.1174 - mean_squared_error: 0.1174 - val_loss: 0.1174 - val_mean_squared_error: 0.1174\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 0.1174 - mean_squared_error: 0.1174 - val_loss: 0.1174 - val_mean_squared_error: 0.1174\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 0.1174 - mean_squared_error: 0.1174 - val_loss: 0.1174 - val_mean_squared_error: 0.1174\n",
      "3125/3125 [==============================] - 39s 12ms/step - loss: 0.1175 - mean_squared_error: 0.1175\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 0.1871 - mean_squared_error: 0.1871\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 0.1863 - mean_squared_error: 0.1863 - val_loss: 0.1864 - val_mean_squared_error: 0.1864\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 0.1863 - mean_squared_error: 0.1863 - val_loss: 0.1864 - val_mean_squared_error: 0.1864\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 0.1863 - mean_squared_error: 0.1863 - val_loss: 0.1864 - val_mean_squared_error: 0.1864\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 0.1863 - mean_squared_error: 0.1863 - val_loss: 0.1864 - val_mean_squared_error: 0.1864\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 0.1863 - mean_squared_error: 0.1863 - val_loss: 0.1864 - val_mean_squared_error: 0.1864\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 0.1871 - mean_squared_error: 0.1871\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.2973 - mean_squared_error: 0.2973\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 0.2983 - mean_squared_error: 0.2983 - val_loss: 0.2979 - val_mean_squared_error: 0.2979\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 0.2983 - mean_squared_error: 0.2983 - val_loss: 0.2979 - val_mean_squared_error: 0.2979\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 222s 18ms/step - loss: 0.2983 - mean_squared_error: 0.2983 - val_loss: 0.2979 - val_mean_squared_error: 0.2979\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 0.2983 - mean_squared_error: 0.2983 - val_loss: 0.2979 - val_mean_squared_error: 0.2979\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 230s 18ms/step - loss: 0.2983 - mean_squared_error: 0.2983 - val_loss: 0.2979 - val_mean_squared_error: 0.2979\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.2973 - mean_squared_error: 0.2973\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 0.4812 - mean_squared_error: 0.4812\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 0.4778 - mean_squared_error: 0.4778 - val_loss: 0.4772 - val_mean_squared_error: 0.4772\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 0.4778 - mean_squared_error: 0.4778 - val_loss: 0.4772 - val_mean_squared_error: 0.4772\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 0.4778 - mean_squared_error: 0.4778 - val_loss: 0.4772 - val_mean_squared_error: 0.4772\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 0.4778 - mean_squared_error: 0.4778 - val_loss: 0.4772 - val_mean_squared_error: 0.4772\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 0.4778 - mean_squared_error: 0.4778 - val_loss: 0.4772 - val_mean_squared_error: 0.4772\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.4812 - mean_squared_error: 0.4812\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.7697 - mean_squared_error: 0.7697\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 0.7699 - mean_squared_error: 0.7699 - val_loss: 0.7688 - val_mean_squared_error: 0.7688\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 0.7699 - mean_squared_error: 0.7699 - val_loss: 0.7688 - val_mean_squared_error: 0.7688\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 0.7699 - mean_squared_error: 0.7699 - val_loss: 0.7688 - val_mean_squared_error: 0.7688\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 0.7699 - mean_squared_error: 0.7699 - val_loss: 0.7688 - val_mean_squared_error: 0.7688\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 0.7699 - mean_squared_error: 0.7699 - val_loss: 0.7688 - val_mean_squared_error: 0.7688\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 0.7697 - mean_squared_error: 0.7697\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 1.2287 - mean_squared_error: 1.2287\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 1.2381 - mean_squared_error: 1.2381 - val_loss: 1.2381 - val_mean_squared_error: 1.2381\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 1.2381 - mean_squared_error: 1.2381 - val_loss: 1.2381 - val_mean_squared_error: 1.2381\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 1.2381 - mean_squared_error: 1.2381 - val_loss: 1.2381 - val_mean_squared_error: 1.2381\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 1.2381 - mean_squared_error: 1.2381 - val_loss: 1.2381 - val_mean_squared_error: 1.2381\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 1.2381 - mean_squared_error: 1.2381 - val_loss: 1.2381 - val_mean_squared_error: 1.2381\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 1.2287 - mean_squared_error: 1.2287\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 1.9933 - mean_squared_error: 1.9933\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 223s 18ms/step - loss: 1.9845 - mean_squared_error: 1.9845 - val_loss: 1.9842 - val_mean_squared_error: 1.9842\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 1.9845 - mean_squared_error: 1.9845 - val_loss: 1.9842 - val_mean_squared_error: 1.9842\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 1.9845 - mean_squared_error: 1.9845 - val_loss: 1.9842 - val_mean_squared_error: 1.9842\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 223s 18ms/step - loss: 1.9845 - mean_squared_error: 1.9845 - val_loss: 1.9842 - val_mean_squared_error: 1.9842\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 1.9845 - mean_squared_error: 1.9845 - val_loss: 1.9842 - val_mean_squared_error: 1.9842\n",
      "3125/3125 [==============================] - 39s 13ms/step - loss: 1.9933 - mean_squared_error: 1.9933\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 3.2148 - mean_squared_error: 3.2148\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 3.1966 - mean_squared_error: 3.1966 - val_loss: 3.2116 - val_mean_squared_error: 3.2116\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 3.1966 - mean_squared_error: 3.1966 - val_loss: 3.2116 - val_mean_squared_error: 3.2116\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 3.1966 - mean_squared_error: 3.1966 - val_loss: 3.2116 - val_mean_squared_error: 3.2116\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 3.1966 - mean_squared_error: 3.1966 - val_loss: 3.2116 - val_mean_squared_error: 3.2116\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 3.1966 - mean_squared_error: 3.1966 - val_loss: 3.2116 - val_mean_squared_error: 3.2116\n",
      "3125/3125 [==============================] - 39s 12ms/step - loss: 3.2148 - mean_squared_error: 3.2148\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 5.1843 - mean_squared_error: 5.1843\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 223s 18ms/step - loss: 5.1634 - mean_squared_error: 5.1634 - val_loss: 5.1273 - val_mean_squared_error: 5.1273\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 5.1634 - mean_squared_error: 5.1634 - val_loss: 5.1273 - val_mean_squared_error: 5.1273\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 5.1634 - mean_squared_error: 5.1634 - val_loss: 5.1273 - val_mean_squared_error: 5.1273\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 5.1634 - mean_squared_error: 5.1634 - val_loss: 5.1273 - val_mean_squared_error: 5.1273\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 5.1634 - mean_squared_error: 5.1634 - val_loss: 5.1273 - val_mean_squared_error: 5.1273\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 5.1843 - mean_squared_error: 5.1843\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 8.4025 - mean_squared_error: 8.4025\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 8.3134 - mean_squared_error: 8.3134 - val_loss: 8.2860 - val_mean_squared_error: 8.2860\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 8.3134 - mean_squared_error: 8.3134 - val_loss: 8.2860 - val_mean_squared_error: 8.2860\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 8.3134 - mean_squared_error: 8.3134 - val_loss: 8.2860 - val_mean_squared_error: 8.2860\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 8.3134 - mean_squared_error: 8.3134 - val_loss: 8.2860 - val_mean_squared_error: 8.2860\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 8.3134 - mean_squared_error: 8.3134 - val_loss: 8.2860 - val_mean_squared_error: 8.2860\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 8.4025 - mean_squared_error: 8.4025\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 13.4234 - mean_squared_error: 13.4234\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 13.4665 - mean_squared_error: 13.4665 - val_loss: 13.4334 - val_mean_squared_error: 13.4334\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 222s 18ms/step - loss: 13.4665 - mean_squared_error: 13.4665 - val_loss: 13.4334 - val_mean_squared_error: 13.4334\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 13.4665 - mean_squared_error: 13.4665 - val_loss: 13.4334 - val_mean_squared_error: 13.4334\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 13.4664 - mean_squared_error: 13.4664 - val_loss: 13.4334 - val_mean_squared_error: 13.4334\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 223s 18ms/step - loss: 13.4664 - mean_squared_error: 13.4664 - val_loss: 13.4334 - val_mean_squared_error: 13.4334\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 13.4234 - mean_squared_error: 13.4234\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 21.8089 - mean_squared_error: 21.8089\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 21.7592 - mean_squared_error: 21.7592 - val_loss: 21.6409 - val_mean_squared_error: 21.6409\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 21.7592 - mean_squared_error: 21.7592 - val_loss: 21.6409 - val_mean_squared_error: 21.6409\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 21.7593 - mean_squared_error: 21.7593 - val_loss: 21.6409 - val_mean_squared_error: 21.6409\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 21.7592 - mean_squared_error: 21.7592 - val_loss: 21.6409 - val_mean_squared_error: 21.6409\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 229s 18ms/step - loss: 21.7593 - mean_squared_error: 21.7593 - val_loss: 21.6409 - val_mean_squared_error: 21.6409\n",
      "3125/3125 [==============================] - 39s 13ms/step - loss: 21.8089 - mean_squared_error: 21.8089\n",
      "3125/3125 [==============================] - 39s 12ms/step - loss: 35.3578 - mean_squared_error: 35.3578\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 35.3112 - mean_squared_error: 35.3112 - val_loss: 35.0409 - val_mean_squared_error: 35.0409\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 35.3111 - mean_squared_error: 35.3111 - val_loss: 35.0409 - val_mean_squared_error: 35.0409\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 35.3111 - mean_squared_error: 35.3111 - val_loss: 35.0409 - val_mean_squared_error: 35.0409\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 35.3111 - mean_squared_error: 35.3111 - val_loss: 35.0409 - val_mean_squared_error: 35.0409\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 35.3111 - mean_squared_error: 35.3111 - val_loss: 35.0409 - val_mean_squared_error: 35.0409\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 35.3578 - mean_squared_error: 35.3578\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 57.0493 - mean_squared_error: 57.0493\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 223s 18ms/step - loss: 56.9355 - mean_squared_error: 56.9355 - val_loss: 56.6565 - val_mean_squared_error: 56.6565\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 56.9356 - mean_squared_error: 56.9356 - val_loss: 56.6565 - val_mean_squared_error: 56.6565\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 56.9358 - mean_squared_error: 56.9358 - val_loss: 56.6565 - val_mean_squared_error: 56.6565\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 56.9357 - mean_squared_error: 56.9357 - val_loss: 56.6565 - val_mean_squared_error: 56.6565\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 56.9356 - mean_squared_error: 56.9356 - val_loss: 56.6565 - val_mean_squared_error: 56.6565\n",
      "3125/3125 [==============================] - 39s 12ms/step - loss: 57.0493 - mean_squared_error: 57.0493\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 92.2255 - mean_squared_error: 92.2255\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 91.7276 - mean_squared_error: 91.7276 - val_loss: 91.0988 - val_mean_squared_error: 91.0988\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 91.7274 - mean_squared_error: 91.7274 - val_loss: 91.0988 - val_mean_squared_error: 91.0988\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 91.7273 - mean_squared_error: 91.7273 - val_loss: 91.0988 - val_mean_squared_error: 91.0988\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 91.7277 - mean_squared_error: 91.7277 - val_loss: 91.0988 - val_mean_squared_error: 91.0988\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 91.7274 - mean_squared_error: 91.7274 - val_loss: 91.0988 - val_mean_squared_error: 91.0988\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 92.2255 - mean_squared_error: 92.2255\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 147.6702 - mean_squared_error: 147.6702\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 147.1873 - mean_squared_error: 147.1873 - val_loss: 147.3080 - val_mean_squared_error: 147.3080\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 223s 18ms/step - loss: 147.1870 - mean_squared_error: 147.1870 - val_loss: 147.3080 - val_mean_squared_error: 147.3080\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 147.1870 - mean_squared_error: 147.1870 - val_loss: 147.3080 - val_mean_squared_error: 147.3080\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 147.1872 - mean_squared_error: 147.1872 - val_loss: 147.3080 - val_mean_squared_error: 147.3080\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 147.1870 - mean_squared_error: 147.1870 - val_loss: 147.3080 - val_mean_squared_error: 147.3080\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 147.6702 - mean_squared_error: 147.6702\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 237.5779 - mean_squared_error: 237.5779\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 237.2089 - mean_squared_error: 237.2089 - val_loss: 237.0341 - val_mean_squared_error: 237.0341\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 237.2085 - mean_squared_error: 237.2085 - val_loss: 237.0341 - val_mean_squared_error: 237.0341\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 237.2081 - mean_squared_error: 237.2081 - val_loss: 237.0341 - val_mean_squared_error: 237.0341\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 237.2083 - mean_squared_error: 237.2083 - val_loss: 237.0341 - val_mean_squared_error: 237.0341\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 237.2083 - mean_squared_error: 237.2083 - val_loss: 237.0341 - val_mean_squared_error: 237.0341\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 237.5779 - mean_squared_error: 237.5779\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 390.8755 - mean_squared_error: 390.8755\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 389.1846 - mean_squared_error: 389.1846 - val_loss: 391.1846 - val_mean_squared_error: 391.1846\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 389.1848 - mean_squared_error: 389.1848 - val_loss: 391.1846 - val_mean_squared_error: 391.1846\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 389.1846 - mean_squared_error: 389.1846 - val_loss: 391.1846 - val_mean_squared_error: 391.1846\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 389.1848 - mean_squared_error: 389.1848 - val_loss: 391.1846 - val_mean_squared_error: 391.1846\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 389.1835 - mean_squared_error: 389.1835 - val_loss: 391.1846 - val_mean_squared_error: 391.1846\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 390.8755 - mean_squared_error: 390.8755\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 658.8054 - mean_squared_error: 658.8054\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 660.8017 - mean_squared_error: 660.8017 - val_loss: 659.2291 - val_mean_squared_error: 659.2291\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 222s 18ms/step - loss: 660.8051 - mean_squared_error: 660.8051 - val_loss: 659.2291 - val_mean_squared_error: 659.2291\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 660.8017 - mean_squared_error: 660.8017 - val_loss: 659.2291 - val_mean_squared_error: 659.2291\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 225s 18ms/step - loss: 660.8033 - mean_squared_error: 660.8033 - val_loss: 659.2291 - val_mean_squared_error: 659.2291\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 660.8038 - mean_squared_error: 660.8038 - val_loss: 659.2291 - val_mean_squared_error: 659.2291\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 658.8054 - mean_squared_error: 658.8054\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 1160.3540 - mean_squared_error: 1160.3540\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 228s 18ms/step - loss: 1148.5150 - mean_squared_error: 1148.5150 - val_loss: 1156.1199 - val_mean_squared_error: 1156.1199\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 227s 18ms/step - loss: 1148.5205 - mean_squared_error: 1148.5205 - val_loss: 1156.1199 - val_mean_squared_error: 1156.1199\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 224s 18ms/step - loss: 1148.5176 - mean_squared_error: 1148.5176 - val_loss: 1156.1199 - val_mean_squared_error: 1156.1199\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 1148.5225 - mean_squared_error: 1148.5225 - val_loss: 1156.1199 - val_mean_squared_error: 1156.1199\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 226s 18ms/step - loss: 1148.5178 - mean_squared_error: 1148.5178 - val_loss: 1156.1199 - val_mean_squared_error: 1156.1199\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 1160.3540 - mean_squared_error: 1160.3540\n"
     ]
    }
   ],
   "source": [
    "scale_steps = np.logspace(-3, 0, 30)\n",
    "before_train_loss = []\n",
    "after_train_loss = []\n",
    "\n",
    "for scale in scale_steps:\n",
    "    x_train2_gen = np.random.normal(x_train2, np.sqrt(x_train2)*scale)\n",
    "    x_test_gen = np.random.normal(x_test, np.sqrt(x_test)*scale)\n",
    "\n",
    "    before_train_loss.append(model.evaluate(x_test_gen, y_test)[0])\n",
    "\n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "               validation_split = 0.1,\n",
    "               batch_size=64,\n",
    "               epochs=5,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "\n",
    "    after_train_loss.append(model.evaluate(x_test_gen, y_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index = index\n",
    "index = 1\n",
    "path = '/home/ML4NO/ML/Regression/models_furthurTrain/0910_theta23_{}_{}.h5'\n",
    "while os.path.isfile(path.format(model_index, index)):\n",
    "    index += 1\n",
    "model.save(path.format(model_index, index))\n",
    "outfile = {'scale_steps': scale_steps,\n",
    "           'before_train_loss': before_train_loss,\n",
    "           'after_train_loss' :after_train_loss}\n",
    "np.save(file = '/home/ML4NO/ML/Regression/models_furthurTrain/0910_theta23_{}_{}_result.npy'.format(model_index, index),\n",
    "        arr = outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12516/12516 [==============================] - 245s 19ms/step - loss: 1162.1111 - mean_squared_error: 1162.1111 - val_loss: 1159.3936 - val_mean_squared_error: 1159.3936\n",
      "12516/12516 [==============================] - 244s 19ms/step - loss: 1161.8428 - mean_squared_error: 1161.8428 - val_loss: 1153.8303 - val_mean_squared_error: 1153.8303\n",
      "12516/12516 [==============================] - 242s 19ms/step - loss: 1163.0513 - mean_squared_error: 1163.0513 - val_loss: 1153.1299 - val_mean_squared_error: 1153.1299\n",
      "12516/12516 [==============================] - 242s 19ms/step - loss: 1157.7845 - mean_squared_error: 1157.7845 - val_loss: 1153.0651 - val_mean_squared_error: 1153.0651\n",
      "12516/12516 [==============================] - 244s 19ms/step - loss: 1161.0154 - mean_squared_error: 1161.0154 - val_loss: 1157.3705 - val_mean_squared_error: 1157.3705\n",
      "12516/12516 [==============================] - 245s 20ms/step - loss: 1161.0078 - mean_squared_error: 1161.0078 - val_loss: 1162.5222 - val_mean_squared_error: 1162.5222\n",
      "12516/12516 [==============================] - 244s 20ms/step - loss: 1162.7083 - mean_squared_error: 1162.7083 - val_loss: 1175.8983 - val_mean_squared_error: 1175.8983\n",
      "12516/12516 [==============================] - 242s 19ms/step - loss: 1162.4041 - mean_squared_error: 1162.4041 - val_loss: 1154.4095 - val_mean_squared_error: 1154.4095\n",
      "12516/12516 [==============================] - 244s 19ms/step - loss: 1159.8389 - mean_squared_error: 1159.8389 - val_loss: 1156.7042 - val_mean_squared_error: 1156.7042\n",
      "12516/12516 [==============================] - 242s 19ms/step - loss: 1160.0510 - mean_squared_error: 1160.0510 - val_loss: 1173.7427 - val_mean_squared_error: 1173.7427\n",
      "3125/3125 [==============================] - 46s 15ms/step - loss: 1154.4673 - mean_squared_error: 1154.4673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1154.46728515625, 1154.46728515625]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test2_gen = np.random.poisson(x_test)\n",
    "\n",
    "for i in range(10):\n",
    "    x_train2_gen = np.random.poisson(x_train2)\n",
    "    \n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "              validation_split=0.1,\n",
    "               batch_size=64,\n",
    "               epochs=1,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "model.evaluate(x_test2_gen, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "furthur_index = index\n",
    "index = 1\n",
    "path = '/home/ML4NO/ML/Regression/models_PoissonTrain/0910_theta23_{}_{}_{}.h5'\n",
    "while os.path.isfile(path.format(model_index, furthur_index, index)):\n",
    "    index += 1\n",
    "model.save(path.format(model_index, furthur_index, index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
