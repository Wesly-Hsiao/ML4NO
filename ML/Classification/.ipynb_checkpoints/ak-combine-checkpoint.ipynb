{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Tensorflow Version is 2.4.0-rc3\n",
      "INFO:root:Keras Version is 2.4.0\n",
      "INFO:root:[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9432837825740413385\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5242880000\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8372761631892607751\n",
      "physical_device_desc: \"device: 0, name: TITAN RTX, pci bus id: 0000:03:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x7f2ef463b088>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only use the first GPU\n",
    "try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     logging.info(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "except RuntimeError as e:\n",
    "# Visible devices must be set before GPUs have been initialized\n",
    "    logging.info(e)\n",
    "    \n",
    "    \n",
    "logging.info(\"Tensorflow Version is {}\".format(tf.__version__))\n",
    "logging.info(\"Keras Version is {}\".format(tf.keras.__version__))\n",
    "from tensorflow.python.client import device_lib\n",
    "logging.info(device_lib.list_local_devices())\n",
    "tf.device('/device:XLA_GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.load('/home/ML4NO/Data/n1000000_0910_classification.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = np.column_stack([data['ve_dune'], data['vu_dune'], data['vebar_dune'], data['vubar_dune'], data['ve_t2hk'], data['vu_t2hk'], data['vebar_t2hk'], data['vubar_t2hk']])\n",
    "target = data['cpv']\n",
    "\n",
    "x_train = data_all[:10000]\n",
    "y_train = target[:10000]\n",
    "x_train2 = data_all[10000:900000]\n",
    "y_train2 = target[10000:900000]\n",
    "x_test = data_all[900000:]\n",
    "y_test = target[900000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 Complete [00h 01m 01s]\n",
      "val_accuracy: 0.9813596606254578\n",
      "\n",
      "Best val_accuracy So Far: 0.9923245906829834\n",
      "Total elapsed time: 00h 09m 08s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 5s 16ms/step - loss: 0.5868 - accuracy: 0.6745\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.1970 - accuracy: 0.9357\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.1381 - accuracy: 0.9544\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.1175 - accuracy: 0.9632\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.1079 - accuracy: 0.9674\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.1043 - accuracy: 0.9686\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0933 - accuracy: 0.9714\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.0925 - accuracy: 0.9730\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.0901 - accuracy: 0.9738\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.0869 - accuracy: 0.9760\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0882 - accuracy: 0.9746\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0868 - accuracy: 0.9750\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0803 - accuracy: 0.9783\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.0822 - accuracy: 0.9783\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0762 - accuracy: 0.9801\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.0861 - accuracy: 0.9776\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0771 - accuracy: 0.9797\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 0.0755 - accuracy: 0.9801\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0744 - accuracy: 0.9810\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0755 - accuracy: 0.9811\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2c405316a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ak.StructuredDataClassifier(overwrite=True, max_trials=50)\n",
    "clf.fit(x_train, y_train,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=20,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 304)]             0         \n",
      "_________________________________________________________________\n",
      "multi_category_encoding (Mul (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 304)               609       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                9760      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "classification_head_1 (Activ (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 11,458\n",
      "Trainable params: 10,849\n",
      "Non-trainable params: 609\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 213s 17ms/step - loss: 0.0505 - accuracy: 0.9880 - val_loss: 0.0528 - val_accuracy: 0.9890\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 209s 17ms/step - loss: 0.0388 - accuracy: 0.9913 - val_loss: 0.0361 - val_accuracy: 0.9920\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 207s 17ms/step - loss: 0.0354 - accuracy: 0.9921 - val_loss: 0.0299 - val_accuracy: 0.9928\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 208s 17ms/step - loss: 0.0328 - accuracy: 0.9928 - val_loss: 0.0407 - val_accuracy: 0.9927\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 206s 16ms/step - loss: 0.0301 - accuracy: 0.9934 - val_loss: 0.0235 - val_accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2d083c5518>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train2, y_train2,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=5,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "while os.path.isfile('/home/ML4NO/ML/Classification/models/0910_{}.h5'.format(index)):\n",
    "    index += 1\n",
    "model.save('/home/ML4NO/ML/Classification/models/0910_{}.h5'.format(index), overwrite=False, include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 38s 12ms/step - loss: 0.0229 - accuracy: 0.9949\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.0293 - accuracy: 0.9937 - val_loss: 0.0219 - val_accuracy: 0.9950\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 202s 16ms/step - loss: 0.0279 - accuracy: 0.9940 - val_loss: 0.0334 - val_accuracy: 0.9937\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 212s 17ms/step - loss: 0.0271 - accuracy: 0.9942 - val_loss: 0.0209 - val_accuracy: 0.9953\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 210s 17ms/step - loss: 0.0261 - accuracy: 0.9944 - val_loss: 0.0243 - val_accuracy: 0.9945\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 208s 17ms/step - loss: 0.0254 - accuracy: 0.9947 - val_loss: 0.0231 - val_accuracy: 0.9953\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 0.0219 - accuracy: 0.9956\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0221 - accuracy: 0.9957\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 210s 17ms/step - loss: 0.0255 - accuracy: 0.9946 - val_loss: 0.0332 - val_accuracy: 0.9939\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 209s 17ms/step - loss: 0.0252 - accuracy: 0.9947 - val_loss: 0.0282 - val_accuracy: 0.9955\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 213s 17ms/step - loss: 0.0236 - accuracy: 0.9951 - val_loss: 0.0204 - val_accuracy: 0.9956\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 212s 17ms/step - loss: 0.0236 - accuracy: 0.9951 - val_loss: 0.0275 - val_accuracy: 0.9951\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 208s 17ms/step - loss: 0.0228 - accuracy: 0.9952 - val_loss: 0.0315 - val_accuracy: 0.9939\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 0.0302 - accuracy: 0.9939\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 0.0305 - accuracy: 0.9938\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 208s 17ms/step - loss: 0.0237 - accuracy: 0.9950 - val_loss: 0.0292 - val_accuracy: 0.9944\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 210s 17ms/step - loss: 0.0232 - accuracy: 0.9951 - val_loss: 0.0196 - val_accuracy: 0.9958\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 208s 17ms/step - loss: 0.0224 - accuracy: 0.9953 - val_loss: 0.0179 - val_accuracy: 0.9961\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.0225 - accuracy: 0.9953 - val_loss: 0.0217 - val_accuracy: 0.9958\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 209s 17ms/step - loss: 0.0226 - accuracy: 0.9952 - val_loss: 0.0197 - val_accuracy: 0.9955\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 0.0194 - accuracy: 0.9957\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0206 - accuracy: 0.9958\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 209s 17ms/step - loss: 0.0254 - accuracy: 0.9945 - val_loss: 0.0302 - val_accuracy: 0.9933\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 210s 17ms/step - loss: 0.0250 - accuracy: 0.9945 - val_loss: 0.0236 - val_accuracy: 0.9950\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 210s 17ms/step - loss: 0.0243 - accuracy: 0.9948 - val_loss: 0.0206 - val_accuracy: 0.9956\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 206s 16ms/step - loss: 0.0235 - accuracy: 0.9950 - val_loss: 0.0205 - val_accuracy: 0.9956\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.0237 - accuracy: 0.9950 - val_loss: 0.0228 - val_accuracy: 0.9952\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0224 - accuracy: 0.9954\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0606 - accuracy: 0.9812\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 206s 16ms/step - loss: 0.0315 - accuracy: 0.9927 - val_loss: 0.0309 - val_accuracy: 0.9931\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 207s 17ms/step - loss: 0.0299 - accuracy: 0.9932 - val_loss: 0.0283 - val_accuracy: 0.9935\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.0291 - accuracy: 0.9934 - val_loss: 0.0259 - val_accuracy: 0.9940\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.0280 - accuracy: 0.9937 - val_loss: 0.0476 - val_accuracy: 0.9873\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.0272 - accuracy: 0.9939 - val_loss: 0.0261 - val_accuracy: 0.9941\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0249 - accuracy: 0.9947\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0988 - accuracy: 0.9698\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 204s 16ms/step - loss: 0.0402 - accuracy: 0.9904 - val_loss: 0.0393 - val_accuracy: 0.9907\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.0380 - accuracy: 0.9910 - val_loss: 0.0368 - val_accuracy: 0.9911\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 204s 16ms/step - loss: 0.0363 - accuracy: 0.9914 - val_loss: 0.0348 - val_accuracy: 0.9918\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 204s 16ms/step - loss: 0.0354 - accuracy: 0.9917 - val_loss: 0.0400 - val_accuracy: 0.9906\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.0348 - accuracy: 0.9919 - val_loss: 0.0340 - val_accuracy: 0.9921\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 0.0324 - accuracy: 0.9924\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.1726 - accuracy: 0.9468\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 204s 16ms/step - loss: 0.0547 - accuracy: 0.9859 - val_loss: 0.0529 - val_accuracy: 0.9866\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 203s 16ms/step - loss: 0.0527 - accuracy: 0.9865 - val_loss: 0.0517 - val_accuracy: 0.9868\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 204s 16ms/step - loss: 0.0513 - accuracy: 0.9870 - val_loss: 0.0514 - val_accuracy: 0.9870\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 204s 16ms/step - loss: 0.0505 - accuracy: 0.9872 - val_loss: 0.0502 - val_accuracy: 0.9874\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.0499 - accuracy: 0.9874 - val_loss: 0.0502 - val_accuracy: 0.9874\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 0.0502 - accuracy: 0.9872\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.2166 - accuracy: 0.9328\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.0851 - accuracy: 0.9760 - val_loss: 0.0861 - val_accuracy: 0.9754\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 204s 16ms/step - loss: 0.0829 - accuracy: 0.9767 - val_loss: 0.0889 - val_accuracy: 0.9746\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.0818 - accuracy: 0.9773 - val_loss: 0.0879 - val_accuracy: 0.9748\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 206s 16ms/step - loss: 0.0811 - accuracy: 0.9773 - val_loss: 0.0834 - val_accuracy: 0.9767\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 206s 16ms/step - loss: 0.0807 - accuracy: 0.9774 - val_loss: 0.0824 - val_accuracy: 0.9769\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.0805 - accuracy: 0.9777\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.3092 - accuracy: 0.9143\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 204s 16ms/step - loss: 0.1373 - accuracy: 0.9563 - val_loss: 0.1375 - val_accuracy: 0.9562\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 204s 16ms/step - loss: 0.1338 - accuracy: 0.9577 - val_loss: 0.1354 - val_accuracy: 0.9572\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 204s 16ms/step - loss: 0.1323 - accuracy: 0.9584 - val_loss: 0.1346 - val_accuracy: 0.9571\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.1311 - accuracy: 0.9588 - val_loss: 0.1348 - val_accuracy: 0.9577\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 204s 16ms/step - loss: 0.1301 - accuracy: 0.9591 - val_loss: 0.1344 - val_accuracy: 0.9574\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.1316 - accuracy: 0.9593\n",
      "3125/3125 [==============================] - 38s 12ms/step - loss: 0.4551 - accuracy: 0.8788\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.2196 - accuracy: 0.9201 - val_loss: 0.2164 - val_accuracy: 0.9218\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.2125 - accuracy: 0.9228 - val_loss: 0.2139 - val_accuracy: 0.9229\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 207s 17ms/step - loss: 0.2085 - accuracy: 0.9247 - val_loss: 0.2115 - val_accuracy: 0.9238\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 205s 16ms/step - loss: 0.2055 - accuracy: 0.9262 - val_loss: 0.2141 - val_accuracy: 0.9237\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 204s 16ms/step - loss: 0.2028 - accuracy: 0.9272 - val_loss: 0.2075 - val_accuracy: 0.9255\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 0.2047 - accuracy: 0.9263\n"
     ]
    }
   ],
   "source": [
    "scale_steps = np.logspace(-3, 0, 10)\n",
    "before_train_loss = []\n",
    "after_train_loss = []\n",
    "\n",
    "for scale in scale_steps:\n",
    "    x_train2_gen = np.random.normal(x_train2, np.sqrt(x_train2)*scale)\n",
    "    x_test_gen = np.random.normal(x_test, np.sqrt(x_test)*scale)\n",
    "\n",
    "    before_train_loss.append(model.evaluate(x_test_gen, y_test)[0])\n",
    "\n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "               validation_split = 0.1,\n",
    "               batch_size=64,\n",
    "               epochs=5,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "    after_train_loss.append(model.evaluate(x_test_gen, y_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index = index\n",
    "index = 1\n",
    "path = '/home/ML4NO/ML/Classification/models_furthurTrain/0910_{}_{}.h5'\n",
    "while os.path.isfile(path.format(model_index, index)):\n",
    "    index += 1\n",
    "model.save(path.format(model_index, index))\n",
    "outfile = {'scale_steps': scale_steps,\n",
    "           'before_train_loss': before_train_loss,\n",
    "           'after_train_loss' :after_train_loss}\n",
    "np.save(file = '/home/ML4NO/ML/Classification/models_furthurTrain/0910_{}_{}_result.npy'.format(model_index, index),\n",
    "        arr = outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12516/12516 [==============================] - 223s 18ms/step - loss: 0.2047 - accuracy: 0.9265 - val_loss: 0.2034 - val_accuracy: 0.9274\n",
      "12516/12516 [==============================] - 219s 17ms/step - loss: 0.2021 - accuracy: 0.9280 - val_loss: 0.2025 - val_accuracy: 0.9284\n",
      "12516/12516 [==============================] - 222s 18ms/step - loss: 0.2002 - accuracy: 0.9286 - val_loss: 0.1999 - val_accuracy: 0.9291\n",
      "12516/12516 [==============================] - 223s 18ms/step - loss: 0.1983 - accuracy: 0.9296 - val_loss: 0.1985 - val_accuracy: 0.9291\n",
      "12516/12516 [==============================] - 223s 18ms/step - loss: 0.1961 - accuracy: 0.9307 - val_loss: 0.1973 - val_accuracy: 0.9304\n",
      "3125/3125 [==============================] - 48s 15ms/step - loss: 0.1963 - accuracy: 0.9305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19626706838607788, 0.9304999709129333]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test2_gen = np.random.poisson(x_test)\n",
    "\n",
    "for i in range(5):\n",
    "    x_train2_gen = np.random.poisson(x_train2)\n",
    "    \n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "              validation_split=0.1,\n",
    "               batch_size=64,\n",
    "               epochs=1,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "model.evaluate(x_test2_gen, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test2_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpc = np.where(y_test == 0)\n",
    "cpv = np.where(y_test == 1)\n",
    "plt.hist(pred[cpc])\n",
    "plt.hist(pred[cpv])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "furthur_index = index\n",
    "index = 1\n",
    "path = '/home/ML4NO/ML/Classification/models_PoissonTrain/0910_{}_{}_{}.h5'\n",
    "while os.path.isfile(path.format(model_index, furthur_index, index)):\n",
    "    index += 1\n",
    "model.save(path.format(model_index, furthur_index, index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
