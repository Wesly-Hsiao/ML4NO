{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import os\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Tensorflow Version is 2.4.0-rc3\n",
      "INFO:root:Keras Version is 2.4.0\n",
      "INFO:root:[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11593648224141348575\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5242880000\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14872525364283192121\n",
      "physical_device_desc: \"device: 0, name: TITAN RTX, pci bus id: 0000:03:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x7fd05bcbe988>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only use the first GPU\n",
    "try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     logging.info(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "except RuntimeError as e:\n",
    "# Visible devices must be set before GPUs have been initialized\n",
    "    logging.info(e)\n",
    "    \n",
    "    \n",
    "logging.info(\"Tensorflow Version is {}\".format(tf.__version__))\n",
    "logging.info(\"Keras Version is {}\".format(tf.keras.__version__))\n",
    "from tensorflow.python.client import device_lib\n",
    "logging.info(device_lib.list_local_devices())\n",
    "tf.device('/device:XLA_GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.load('/home/ML4NO/Data/n1000000_0910_classification.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = np.column_stack([data['ve_dune'], data['vu_dune'], data['vebar_dune'], data['vubar_dune'], data['ve_t2hk'], data['vu_t2hk'], data['vebar_t2hk'], data['vubar_t2hk']])\n",
    "target = data['cpv']\n",
    "\n",
    "x_train = data_all[:10000]\n",
    "y_train = target[:10000]\n",
    "x_train2 = data_all[10000:900000]\n",
    "y_train2 = target[10000:900000]\n",
    "x_test = data_all[900000:]\n",
    "y_test = target[900000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 01m 12s]\n",
      "val_accuracy: 0.8969298245614035\n",
      "\n",
      "Best val_accuracy So Far: 0.9923245614035088\n",
      "Total elapsed time: 01h 04m 13s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 6s 20ms/step - loss: 0.4660 - accuracy: 0.7547\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.1417 - accuracy: 0.9582\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.1191 - accuracy: 0.9672\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.1104 - accuracy: 0.9706\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 3s 22ms/step - loss: 0.1132 - accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0949 - accuracy: 0.9746\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.0884 - accuracy: 0.9764\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0813 - accuracy: 0.9779\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0884 - accuracy: 0.9765\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0723 - accuracy: 0.9809\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0958 - accuracy: 0.9721\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.0652 - accuracy: 0.9830\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.0691 - accuracy: 0.9827\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.0775 - accuracy: 0.9806\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0759 - accuracy: 0.9800\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0764 - accuracy: 0.9814\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.0712 - accuracy: 0.9812\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.0738 - accuracy: 0.9830\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.0769 - accuracy: 0.9801\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0740 - accuracy: 0.9791\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcfc41a0400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ak.StructuredDataClassifier(overwrite=True, max_trials=50)\n",
    "clf.fit(x_train, y_train,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=20,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 304)]             0         \n",
      "_________________________________________________________________\n",
      "multi_category_encoding (Mul (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 304)               609       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               39040     \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "classification_head_1 (Activ (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 106,210\n",
      "Trainable params: 105,601\n",
      "Non-trainable params: 609\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 285s 22ms/step - loss: 0.0525 - accuracy: 0.9875 - val_loss: 0.0486 - val_accuracy: 0.9884\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 279s 22ms/step - loss: 0.0413 - accuracy: 0.9906 - val_loss: 0.0333 - val_accuracy: 0.9920\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0370 - accuracy: 0.9917 - val_loss: 0.0362 - val_accuracy: 0.9932\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 275s 22ms/step - loss: 0.0334 - accuracy: 0.9926 - val_loss: 0.0250 - val_accuracy: 0.9940\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0311 - accuracy: 0.9933 - val_loss: 0.0389 - val_accuracy: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcfac72f390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train2, y_train2,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=5,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "while os.path.isfile('/home/ML4NO/ML/Classification/models/0910_{}.h5'.format(index)):\n",
    "    index += 1\n",
    "model.save('/home/ML4NO/ML/Classification/models/0910_{}.h5'.format(index), overwrite=False, include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 55s 17ms/step - loss: 0.0370 - accuracy: 0.9918\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 283s 23ms/step - loss: 0.0308 - accuracy: 0.9932 - val_loss: 0.0274 - val_accuracy: 0.9941\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 275s 22ms/step - loss: 0.0288 - accuracy: 0.9939 - val_loss: 0.0219 - val_accuracy: 0.9950\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 281s 22ms/step - loss: 0.0282 - accuracy: 0.9940 - val_loss: 0.0263 - val_accuracy: 0.9947\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 279s 22ms/step - loss: 0.0266 - accuracy: 0.9944 - val_loss: 0.0260 - val_accuracy: 0.9943\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0267 - accuracy: 0.9944 - val_loss: 0.0246 - val_accuracy: 0.9946\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.0236 - accuracy: 0.9950\n",
      "3125/3125 [==============================] - 53s 17ms/step - loss: 0.0236 - accuracy: 0.9950\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 278s 22ms/step - loss: 0.0256 - accuracy: 0.9946 - val_loss: 0.0328 - val_accuracy: 0.9927\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 284s 23ms/step - loss: 0.0248 - accuracy: 0.9948 - val_loss: 0.0232 - val_accuracy: 0.9949\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 278s 22ms/step - loss: 0.0248 - accuracy: 0.9948 - val_loss: 0.0212 - val_accuracy: 0.9955\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0242 - accuracy: 0.9949 - val_loss: 0.0229 - val_accuracy: 0.9953\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 279s 22ms/step - loss: 0.0238 - accuracy: 0.9951 - val_loss: 0.0190 - val_accuracy: 0.9960\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.0179 - accuracy: 0.9961\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.0189 - accuracy: 0.9962\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 281s 22ms/step - loss: 0.0244 - accuracy: 0.9948 - val_loss: 0.0297 - val_accuracy: 0.9937\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 282s 23ms/step - loss: 0.0238 - accuracy: 0.9950 - val_loss: 0.0207 - val_accuracy: 0.9956\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0233 - accuracy: 0.9951 - val_loss: 0.0250 - val_accuracy: 0.9950\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0228 - accuracy: 0.9953 - val_loss: 0.0205 - val_accuracy: 0.9955\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0230 - accuracy: 0.9952 - val_loss: 0.0211 - val_accuracy: 0.9956\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.0198 - accuracy: 0.9959\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.0232 - accuracy: 0.9953\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 278s 22ms/step - loss: 0.0261 - accuracy: 0.9943 - val_loss: 0.0344 - val_accuracy: 0.9913\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 278s 22ms/step - loss: 0.0255 - accuracy: 0.9944 - val_loss: 0.0263 - val_accuracy: 0.9942\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0246 - accuracy: 0.9947 - val_loss: 0.0217 - val_accuracy: 0.9951\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 279s 22ms/step - loss: 0.0243 - accuracy: 0.9947 - val_loss: 0.0221 - val_accuracy: 0.9950\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 279s 22ms/step - loss: 0.0240 - accuracy: 0.9948 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
      "3125/3125 [==============================] - 53s 17ms/step - loss: 0.0255 - accuracy: 0.9947\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.0379 - accuracy: 0.9899\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 279s 22ms/step - loss: 0.0321 - accuracy: 0.9927 - val_loss: 0.0306 - val_accuracy: 0.9928\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0307 - accuracy: 0.9930 - val_loss: 0.0309 - val_accuracy: 0.9930\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0299 - accuracy: 0.9932 - val_loss: 0.0301 - val_accuracy: 0.9929\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 279s 22ms/step - loss: 0.0291 - accuracy: 0.9934 - val_loss: 0.0293 - val_accuracy: 0.9932\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 278s 22ms/step - loss: 0.0287 - accuracy: 0.9935 - val_loss: 0.0247 - val_accuracy: 0.9943\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.0242 - accuracy: 0.9946\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.0837 - accuracy: 0.9741\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0418 - accuracy: 0.9899 - val_loss: 0.0400 - val_accuracy: 0.9904\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 278s 22ms/step - loss: 0.0394 - accuracy: 0.9906 - val_loss: 0.0394 - val_accuracy: 0.9909\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 279s 22ms/step - loss: 0.0377 - accuracy: 0.9910 - val_loss: 0.0357 - val_accuracy: 0.9915\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0366 - accuracy: 0.9914 - val_loss: 0.0376 - val_accuracy: 0.9910\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0358 - accuracy: 0.9915 - val_loss: 0.0341 - val_accuracy: 0.9918\n",
      "3125/3125 [==============================] - 55s 18ms/step - loss: 0.0328 - accuracy: 0.9921\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.1519 - accuracy: 0.9581\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 279s 22ms/step - loss: 0.0569 - accuracy: 0.9853 - val_loss: 0.0570 - val_accuracy: 0.9850\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0542 - accuracy: 0.9862 - val_loss: 0.0576 - val_accuracy: 0.9852\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 278s 22ms/step - loss: 0.0524 - accuracy: 0.9867 - val_loss: 0.0565 - val_accuracy: 0.9851\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 279s 22ms/step - loss: 0.0515 - accuracy: 0.9870 - val_loss: 0.0514 - val_accuracy: 0.9866\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 278s 22ms/step - loss: 0.0508 - accuracy: 0.9872 - val_loss: 0.0592 - val_accuracy: 0.9846\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.0588 - accuracy: 0.9849\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.3324 - accuracy: 0.9256\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0850 - accuracy: 0.9761 - val_loss: 0.0868 - val_accuracy: 0.9752\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0822 - accuracy: 0.9770 - val_loss: 0.0892 - val_accuracy: 0.9743\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0810 - accuracy: 0.9773 - val_loss: 0.0851 - val_accuracy: 0.9761\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0802 - accuracy: 0.9776 - val_loss: 0.0848 - val_accuracy: 0.9761\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.0795 - accuracy: 0.9778 - val_loss: 0.0843 - val_accuracy: 0.9764\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.0814 - accuracy: 0.9773\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.8172 - accuracy: 0.8701\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 278s 22ms/step - loss: 0.1372 - accuracy: 0.9565 - val_loss: 0.1370 - val_accuracy: 0.9569\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 278s 22ms/step - loss: 0.1329 - accuracy: 0.9582 - val_loss: 0.1373 - val_accuracy: 0.9571\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.1311 - accuracy: 0.9589 - val_loss: 0.1355 - val_accuracy: 0.9578\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 278s 22ms/step - loss: 0.1296 - accuracy: 0.9594 - val_loss: 0.1404 - val_accuracy: 0.9558\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 278s 22ms/step - loss: 0.1280 - accuracy: 0.9601 - val_loss: 0.1354 - val_accuracy: 0.9572\n",
      "3125/3125 [==============================] - 51s 16ms/step - loss: 0.1328 - accuracy: 0.9579\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 2.5419 - accuracy: 0.7301\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 277s 22ms/step - loss: 0.2202 - accuracy: 0.9206 - val_loss: 0.2117 - val_accuracy: 0.9238\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 280s 22ms/step - loss: 0.2104 - accuracy: 0.9243 - val_loss: 0.2079 - val_accuracy: 0.9255\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 281s 22ms/step - loss: 0.2055 - accuracy: 0.9267 - val_loss: 0.2069 - val_accuracy: 0.9260\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 281s 22ms/step - loss: 0.2019 - accuracy: 0.9284 - val_loss: 0.2066 - val_accuracy: 0.9258\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 279s 22ms/step - loss: 0.1991 - accuracy: 0.9295 - val_loss: 0.2095 - val_accuracy: 0.9241\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 0.2101 - accuracy: 0.9240\n"
     ]
    }
   ],
   "source": [
    "scale_steps = np.logspace(-3, 0, 10)\n",
    "before_train_loss = []\n",
    "after_train_loss = []\n",
    "\n",
    "for scale in scale_steps:\n",
    "    x_train2_gen = np.random.normal(x_train2, np.sqrt(x_train2)*scale)\n",
    "    x_test_gen = np.random.normal(x_test, np.sqrt(x_test)*scale)\n",
    "\n",
    "    before_train_loss.append(model.evaluate(x_test_gen, y_test)[0])\n",
    "\n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "               validation_split = 0.1,\n",
    "               batch_size=64,\n",
    "               epochs=5,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "    after_train_loss.append(model.evaluate(x_test_gen, y_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index = index\n",
    "index = 1\n",
    "path = '/home/ML4NO/ML/Classification/models_furthurTrain/0910_{}_{}.h5'\n",
    "while os.path.isfile(path.format(model_index, index)):\n",
    "    index += 1\n",
    "model.save(path.format(model_index, index))\n",
    "outfile = {'scale_steps': scale_steps,\n",
    "           'before_train_loss': before_train_loss,\n",
    "           'after_train_loss' :after_train_loss}\n",
    "np.save(file = '/home/ML4NO/ML/Classification/models_furthurTrain/0910_{}_{}_result.npy'.format(model_index, index),\n",
    "        arr = outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12516/12516 [==============================] - 292s 23ms/step - loss: 0.1970 - accuracy: 0.9304 - val_loss: 0.2004 - val_accuracy: 0.9287\n",
      "12516/12516 [==============================] - 294s 23ms/step - loss: 0.1962 - accuracy: 0.9307 - val_loss: 0.1961 - val_accuracy: 0.9311\n",
      "12516/12516 [==============================] - 292s 23ms/step - loss: 0.1954 - accuracy: 0.9313 - val_loss: 0.1967 - val_accuracy: 0.9316\n",
      "12516/12516 [==============================] - 293s 23ms/step - loss: 0.1939 - accuracy: 0.9319 - val_loss: 0.1980 - val_accuracy: 0.9299\n",
      "12516/12516 [==============================] - 293s 23ms/step - loss: 0.1945 - accuracy: 0.9315 - val_loss: 0.1965 - val_accuracy: 0.9307\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 0.1942 - accuracy: 0.9311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19423677468955516, 0.93107]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_gen = np.random.poisson(x_test)\n",
    "\n",
    "for i in range(5):\n",
    "    x_train2_gen = np.random.poisson(x_train2)\n",
    "    \n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "              validation_split=0.1,\n",
    "               batch_size=64,\n",
    "               epochs=1,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "model.evaluate(x_test_gen, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVjklEQVR4nO3df6xf9X3f8ecrNr+2BGzCLUK2V7PGXecw1ZA7cJVpS2ExxqliqrEItgYXeXHXwJRuURfT/QGFIIGmhBWJsDnFxURtDKPtuKJmnkWYUKYZfCkEMJRxC6TYc/AtNtAIBWb63h/fj6Nv3Ht9v/a99/s19vMhfXXPeZ/POedzjuz7uuecz/f7TVUhSTqxfWjQHZAkDZ5hIEkyDCRJhoEkCcNAkgTMHXQHjtZZZ51VixcvHnQ3JOkD5cknn/zLqho6tP6BDYPFixczOjo66G5I0gdKku9PVPc2kSTJMJAkGQaSJAwDSRJHEAZJ5iR5KslDbf7cJI8nGUtyX5KTW/2UNj/Wli/u2sb1rf5ikku76itbbSzJ+hk8PklSD47kyuBLwAtd87cBt1fVx4D9wNpWXwvsb/XbWzuSLAWuBD4OrAS+0QJmDnAncBmwFLiqtZUk9UlPYZBkIfAZ4HfbfICLgQdak03A5W16dZunLb+ktV8NbK6qd6vqFWAMuLC9xqrq5ap6D9jc2kqS+qTXK4P/BPx74K/b/EeBN6vqQJvfBSxo0wuA1wDa8rda+x/XD1lnsrokqU+mDIMkvwTsraon+9CfqfqyLsloktHx8fFBd0eSjhu9vAP5k8Bnk6wCTgVOB34HmJdkbvvrfyGwu7XfDSwCdiWZC5wBvNFVP6h7ncnqP6GqNgAbAIaHh/1WHkknhhvP6Jp+a1Z2MeWVQVVdX1ULq2oxnQfA36mqfwk8ClzRmq0BHmzTI22etvw71fk6tRHgyjba6FxgCfAEsANY0kYnndz2MTIjRydJ6sl0PpvoK8DmJF8FngLubvW7gW8lGQP20fnlTlXtTHI/8DxwALi2qt4HSHIdsBWYA2ysqp3T6Jck6Qjlg/odyMPDw+UH1Uk6IczgbaIkT1bV8KF134EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAksT0PrX0uLB4/Z/8ePrVWz8zwJ5I0uB4ZSBJMgwkSYaBJAnDQJJED2GQ5NQkTyT5XpKdSX671e9J8kqSp9trWasnyR1JxpI8k+SCrm2tSfJSe63pqn8iybNtnTuSZBaOVZI0iV5GE70LXFxVP0xyEvDdJA+3Zb9ZVQ8c0v4yOl92vwS4CLgLuCjJmcANwDBQwJNJRqpqf2vzBeBxYAuwEngYSVJfTHllUB0/bLMntdfhvjh5NXBvW287MC/JOcClwLaq2tcCYBuwsi07vaq2V+cLme8FLj/6Q5IkHamenhkkmZPkaWAvnV/oj7dFt7RbQbcnOaXVFgCvda2+q9UOV981QV2S1Cc9hUFVvV9Vy4CFwIVJzgOuB34O+IfAmcBXZquTByVZl2Q0yej4+Phs706SThhHNJqoqt4EHgVWVtWedivoXeD3gAtbs93Aoq7VFrba4eoLJ6hPtP8NVTVcVcNDQ0NH0nVJ0mH0MppoKMm8Nn0a8Gngz9q9ftrIn8uB59oqI8DVbVTRcuCtqtoDbAVWJJmfZD6wAtjalr2dZHnb1tXAgzN5kJKkw+tlNNE5wKYkc+iEx/1V9VCS7yQZAgI8Dfzr1n4LsAoYA94BrgGoqn1JbgZ2tHY3VdW+Nv1F4B7gNDqjiBxJJEl9NGUYVNUzwPkT1C+epH0B106ybCOwcYL6KHDeVH2RJM0O34EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEj2EQZJTkzyR5HtJdib57VY/N8njScaS3Jfk5FY/pc2PteWLu7Z1fau/mOTSrvrKVhtLsn4WjlOSdBi9XBm8C1xcVT8PLANWJlkO3AbcXlUfA/YDa1v7tcD+Vr+9tSPJUuBK4OPASuAbSeYkmQPcCVwGLAWuam0lSX0yZRhUxw/b7EntVcDFwAOtvgm4vE2vbvO05ZckSatvrqp3q+oVYAy4sL3GqurlqnoP2NzaSpL6pKdnBu0v+KeBvcA24M+BN6vqQGuyC1jQphcArwG05W8BH+2uH7LOZPWJ+rEuyWiS0fHx8V66LknqQU9hUFXvV9UyYCGdv+R/bjY7dZh+bKiq4aoaHhoaGkQXJOm4dESjiarqTeBR4BeAeUnmtkULgd1tejewCKAtPwN4o7t+yDqT1SVJfdLLaKKhJPPa9GnAp4EX6ITCFa3ZGuDBNj3S5mnLv1NV1epXttFG5wJLgCeAHcCSNjrpZDoPmUdm4NgkST2aO3UTzgE2tVE/HwLur6qHkjwPbE7yVeAp4O7W/m7gW0nGgH10frlTVTuT3A88DxwArq2q9wGSXAdsBeYAG6tq54wdoSRpSlOGQVU9A5w/Qf1lOs8PDq3/CPjnk2zrFuCWCepbgC099FeSNAt8B7IkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJLo7TuQFyV5NMnzSXYm+VKr35hkd5Kn22tV1zrXJxlL8mKSS7vqK1ttLMn6rvq5SR5v9fvadyFLkvqklyuDA8CXq2opsBy4NsnStuz2qlrWXlsA2rIrgY8DK4FvJJnTvkP5TuAyYClwVdd2bmvb+hiwH1g7Q8cnSerBlGFQVXuq6k/b9F8BLwALDrPKamBzVb1bVa8AY3S+K/lCYKyqXq6q94DNwOokAS4GHmjrbwIuP8rjkSQdhSN6ZpBkMXA+8HgrXZfkmSQbk8xvtQXAa12r7Wq1yeofBd6sqgOH1Cfa/7oko0lGx8fHj6TrkqTD6DkMknwY+EPgN6rqbeAu4GeAZcAe4Guz0cFuVbWhqoaranhoaGi2dydJJ4y5vTRKchKdIPj9qvojgKp6vWv5N4GH2uxuYFHX6gtbjUnqbwDzksxtVwfd7SVJfdDLaKIAdwMvVNXXu+rndDX7ZeC5Nj0CXJnklCTnAkuAJ4AdwJI2cuhkOg+ZR6qqgEeBK9r6a4AHp3dYkqQj0cuVwSeBzwPPJnm61X6LzmigZUABrwK/BlBVO5PcDzxPZyTStVX1PkCS64CtwBxgY1XtbNv7CrA5yVeBp+iEjySpT6YMg6r6LpAJFm05zDq3ALdMUN8y0XpV9TKd0UaSpAHwHciSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEmit+9AXpTk0STPJ9mZ5EutfmaSbUleaj/nt3qS3JFkLMkzSS7o2taa1v6lJGu66p9I8mxb5472vcuSpD7p5crgAPDlqloKLAeuTbIUWA88UlVLgEfaPMBlwJL2WgfcBZ3wAG4ALqLzFZc3HAyQ1uYLXeutnP6hSZJ6NWUYVNWeqvrTNv1XwAvAAmA1sKk12wRc3qZXA/dWx3ZgXpJzgEuBbVW1r6r2A9uAlW3Z6VW1vaoKuLdrW5KkPjiiZwZJFgPnA48DZ1fVnrboB8DZbXoB8FrXarta7XD1XRPUJ9r/uiSjSUbHx8ePpOuSpMPoOQySfBj4Q+A3qurt7mXtL/qa4b79DVW1oaqGq2p4aGhotncnSSeMnsIgyUl0guD3q+qPWvn1douH9nNvq+8GFnWtvrDVDldfOEFdktQnvYwmCnA38EJVfb1r0QhwcETQGuDBrvrVbVTRcuCtdjtpK7Aiyfz24HgFsLUtezvJ8ravq7u2JUnqg7k9tPkk8Hng2SRPt9pvAbcC9ydZC3wf+FxbtgVYBYwB7wDXAFTVviQ3Aztau5uqal+b/iJwD3Aa8HB7SZL6ZMowqKrvApON+79kgvYFXDvJtjYCGyeojwLnTdUXSdLs8B3IkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJorfvQN6YZG+S57pqNybZneTp9lrVtez6JGNJXkxyaVd9ZauNJVnfVT83yeOtfl+Sk2fyACVJU+vlyuAeYOUE9durall7bQFIshS4Evh4W+cbSeYkmQPcCVwGLAWuam0Bbmvb+hiwH1g7nQOSJB25KcOgqh4D9k3VrlkNbK6qd6vqFWAMuLC9xqrq5ap6D9gMrE4S4GLggbb+JuDyIzsESdJ0TeeZwXVJnmm3kea32gLgta42u1ptsvpHgTer6sAh9QklWZdkNMno+Pj4NLouSep2tGFwF/AzwDJgD/C1merQ4VTVhqoarqrhoaGhfuxSkk4Ic49mpap6/eB0km8CD7XZ3cCirqYLW41J6m8A85LMbVcH3e0lSX1yVFcGSc7pmv1l4OBIoxHgyiSnJDkXWAI8AewAlrSRQyfTecg8UlUFPApc0dZfAzx4NH2SJB29Ka8Mknwb+BRwVpJdwA3Ap5IsAwp4Ffg1gKrameR+4HngAHBtVb3ftnMdsBWYA2ysqp1tF18BNif5KvAUcPdMHZwkqTdThkFVXTVBedJf2FV1C3DLBPUtwJYJ6i/TGW0kSRoQ34EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkegiDJBuT7E3yXFftzCTbkrzUfs5v9SS5I8lYkmeSXNC1zprW/qUka7rqn0jybFvnjiSZ6YOUJB1eL1cG9wArD6mtBx6pqiXAI20e4DJgSXutA+6CTnjQ+e7ki+h8xeUNBwOktflC13qH7kuSNMumDIOqegzYd0h5NbCpTW8CLu+q31sd24F5Sc4BLgW2VdW+qtoPbANWtmWnV9X2qirg3q5tSZL65GifGZxdVXva9A+As9v0AuC1rna7Wu1w9V0T1CeUZF2S0SSj4+PjR9l1SdKhpv0Auf1FXzPQl172taGqhqtqeGhoqB+7lKQTwtGGwevtFg/t595W3w0s6mq3sNUOV184QV2S1EdHGwYjwMERQWuAB7vqV7dRRcuBt9rtpK3AiiTz24PjFcDWtuztJMvbKKKru7YlSeqTuVM1SPJt4FPAWUl20RkVdCtwf5K1wPeBz7XmW4BVwBjwDnANQFXtS3IzsKO1u6mqDj6U/iKdEUunAQ+3lySpj6YMg6q6apJFl0zQtoBrJ9nORmDjBPVR4Lyp+iFJmj2+A1mSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJElMMwySvJrk2SRPJxlttTOTbEvyUvs5v9WT5I4kY0meSXJB13bWtPYvJVkz2f4kSbNjJq4MfrGqllXVcJtfDzxSVUuAR9o8wGXAkvZaB9wFnfCg873KFwEXAjccDBBJUn/Mxm2i1cCmNr0JuLyrfm91bAfmJTkHuBTYVlX7qmo/sA1YOQv9kiRNYrphUMD/SPJkknWtdnZV7WnTPwDObtMLgNe61t3VapPV/4Yk65KMJhkdHx+fZtclSQfNneb6/6iqdif5KWBbkj/rXlhVlaSmuY/u7W0ANgAMDw/P2HYl6UQ3rSuDqtrdfu4F/pjOPf/X2+0f2s+9rfluYFHX6gtbbbK6JKlPjjoMkvztJB85OA2sAJ4DRoCDI4LWAA+26RHg6jaqaDnwVrudtBVYkWR+e3C8otUkSX0yndtEZwN/nOTgdv6gqv57kh3A/UnWAt8HPtfabwFWAWPAO8A1AFW1L8nNwI7W7qaq2jeNfkmSjtBRh0FVvQz8/AT1N4BLJqgXcO0k29oIbDzavkiSpsd3IEuSDANJkmEgScIwkCRhGEiSMAwkSUz/4yg+8F499V90zb01sH5I0iB5ZSBJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJLwfQY/YfH6P5mw/uqtn+lzTySpvwyDHnSHhMEg6XhkGBwhrx4k9cWNZ/R1d8dMGCRZCfwOMAf43aq6dcBdOiKThUQ3A0PSseqYCIMkc4A7gU8Du4AdSUaq6vnB9mxm9RIYR8OQkT7A+nwFMJljIgyAC4Gx9r3KJNkMrAb6GgY/+aF1HyA3dn4s/tEfTLi4+7gma3OiOtIg9fnRDOr+JXjjJB8SOVmbyX6B9tJGE0rne+oH3InkCmBlVf2rNv954KKquu6QduuAdW327wEv9rWjg3UW8JeD7sSAeQ48B+A5mO7x/3RVDR1aPFauDHpSVRuADYPuxyAkGa2q4UH3Y5A8B54D8BzM1vEfK2862w0s6ppf2GqSpD44VsJgB7AkyblJTgauBEYG3CdJOmEcE7eJqupAkuuArXSGlm6sqp0D7tax5oS8PXYIz4HnADwHs3L8x8QDZEnSYB0rt4kkSQNkGEiSDINjTZKVSV5MMpZk/QTL/12S55M8k+SRJD89iH7OpqnOQVe7f5akkhxXwwx7Of4kn2v/DnYmOe7eSdjD/4O/k+TRJE+1/wurBtHP2ZJkY5K9SZ6bZHmS3NHOzzNJLpj2TqvK1zHyovPw/M+BvwucDHwPWHpIm18E/lab/nXgvkH3u9/noLX7CPAYsB0YHnS/+/xvYAnwFDC/zf/UoPs9gHOwAfj1Nr0UeHXQ/Z7hc/CPgQuA5yZZvgp4GAiwHHh8uvv0yuDY8uOP5aiq94CDH8vxY1X1aFW902a303lPxvFkynPQ3AzcBvyon53rg16O/wvAnVW1H6Cq9va5j7Otl3NQwOlt+gzg//axf7Ouqh4D9h2myWrg3urYDsxLcs509mkYHFsWAK91ze9qtcmspfPXwfFkynPQLokXVdXsfPLfYPXyb+BngZ9N8r+SbG+f+Hs86eUc3Aj8SpJdwBbg3/Sna8eMI/1dMaVj4n0GOnJJfgUYBv7JoPvST0k+BHwd+NUBd2WQ5tK5VfQpOleGjyX5B1X15iA71WdXAfdU1deS/ALwrSTnVdVfD7pjH1ReGRxbevpYjiT/FPgPwGer6t0+9a1fpjoHHwHOA/5nklfp3C8dOY4eIvfyb2AXMFJV/6+qXgH+D51wOF70cg7WAvcDVNX/Bk6l8wFuJ4oZ/wgfw+DYMuXHciQ5H/gvdILgeLtXDFOcg6p6q6rOqqrFVbWYznOTz1bV6GC6O+N6+WiW/0bnqoAkZ9G5bfRyH/s423o5B38BXAKQ5O/TCYPxvvZysEaAq9uoouXAW1W1Zzob9DbRMaQm+ViOJDcBo1U1AvxH4MPAf00C8BdV9dmBdXqG9XgOjls9Hv9WYEWS54H3gd+sqjcG1+uZ1eM5+DLwzST/ls7D5F+tNszmeJDk23QC/6z2XOQG4CSAqvrPdJ6TrALGgHeAa6a9z+Po/EmSjpK3iSRJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRLw/wGP7gw271jDVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpc = np.where(y_test == 0)\n",
    "cpv = np.where(y_test == 1)\n",
    "plt.hist(pred[cpc], bins =100)\n",
    "plt.hist(pred[cpv], bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "furthur_index = index\n",
    "index = 1\n",
    "path = '/home/ML4NO/ML/Classification/models_PoissonTrain/0910_{}_{}_{}.h5'\n",
    "while os.path.isfile(path.format(model_index, furthur_index, index)):\n",
    "    index += 1\n",
    "model.save(path.format(model_index, furthur_index, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
