{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2fb0e0ea2336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#   # Restrict TensorFlow to only use the first GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     tf.config.experimental.set_virtual_device_configuration(\n\u001b[1;32m     11\u001b[0m     \u001b[0mgpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only use the first GPU\n",
    "try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     logging.info(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "except RuntimeError as e:\n",
    "# Visible devices must be set before GPUs have been initialized\n",
    "    logging.info(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exposure = 'p25'\n",
    "data = np.load('/home/ML4NO/Data/n1000000{}_0910_classification.npz'.format(exposure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selection = 1 # 0 for all, 1 for lowE(<5GeV), 2 for high(>5GeV)\n",
    "\n",
    "if data_selection == 0:\n",
    "    data_all = np.column_stack([data['ve_dune'], data['vu_dune'], data['vebar_dune'], data['vubar_dune']])\n",
    "    directory = './models_all/'\n",
    "elif data_selection == 1:\n",
    "    data_all = np.column_stack([data['ve_dune'][:,:36], data['vu_dune'][:,:36], data['vebar_dune'][:,:36], data['vubar_dune'][:,:36]])\n",
    "    directory = './models_lowE/'\n",
    "elif data_selection == 2:\n",
    "    data_all = np.column_stack([data['ve_dune'][:,36:], data['vu_dune'][:,36:], data['vebar_dune'][:,36:], data['vubar_dune'][:,36:]])\n",
    "    directory = './models_highE/'\n",
    "target = data['cpv']\n",
    "\n",
    "x_train = data_all[:10000]\n",
    "y_train = target[:10000]\n",
    "x_train2 = data_all[10000:900000]\n",
    "y_train2 = target[10000:900000]\n",
    "x_test = data_all[900000:]\n",
    "y_test = target[900000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 44s]\n",
      "val_accuracy: 0.9901315569877625\n",
      "\n",
      "Best val_accuracy So Far: 0.9912280440330505\n",
      "Total elapsed time: 00h 22m 00s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 3s 12ms/step - loss: 0.5826 - accuracy: 0.6904\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1890 - accuracy: 0.9393\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.1286 - accuracy: 0.9615\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.1057 - accuracy: 0.9697\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0931 - accuracy: 0.9737\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0846 - accuracy: 0.9757\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0799 - accuracy: 0.9796\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0756 - accuracy: 0.9806\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0726 - accuracy: 0.9804\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0690 - accuracy: 0.9826\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0678 - accuracy: 0.9823\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0666 - accuracy: 0.9833\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0632 - accuracy: 0.9831\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0637 - accuracy: 0.9835\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0595 - accuracy: 0.9844\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0600 - accuracy: 0.9843\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0555 - accuracy: 0.9854\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0605 - accuracy: 0.9847\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0537 - accuracy: 0.9874\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0545 - accuracy: 0.9864\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4fc00e8eb8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ak.StructuredDataClassifier(overwrite=True, max_trials=30)\n",
    "clf.fit(x_train, y_train,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=20,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 144)]             0         \n",
      "_________________________________________________________________\n",
      "multi_category_encoding (Mul (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 144)               289       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4640      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "classification_head_1 (Activ (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 7,074\n",
      "Trainable params: 6,785\n",
      "Non-trainable params: 289\n",
      "_________________________________________________________________\n",
      "3125/3125 [==============================] - 24s 7ms/step - loss: 0.0610 - accuracy: 0.9846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.060965023934841156, 0.9846199750900269]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0472 - accuracy: 0.9891 - val_loss: 0.0514 - val_accuracy: 0.9915\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0391 - accuracy: 0.9911 - val_loss: 0.0417 - val_accuracy: 0.9918\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.0348 - accuracy: 0.9921 - val_loss: 0.0306 - val_accuracy: 0.9938\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0322 - accuracy: 0.9929 - val_loss: 0.0280 - val_accuracy: 0.9939\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0307 - accuracy: 0.9932 - val_loss: 0.0302 - val_accuracy: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4f144215c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train2, y_train2,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=5,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_index = 1\n",
    "while os.path.isfile(directory + 'models/0910{}_{}.h5'.format(exposure, model_index)):\n",
    "    model_index += 1\n",
    "model.save(directory + 'models/0910{}_{}.h5'.format(exposure, model_index), overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "furthur_index = 1\n",
    "path = directory + 'models_furthurTrain/0910{}_{}_{}'\n",
    "while os.path.isdir(path.format(exposure, model_index, furthur_index)):\n",
    "    furthur_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0341 - accuracy: 0.9925\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0295 - accuracy: 0.9936 - val_loss: 0.0299 - val_accuracy: 0.9928\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0291 - accuracy: 0.9937 - val_loss: 0.0221 - val_accuracy: 0.9950\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0268 - accuracy: 0.9942 - val_loss: 0.0197 - val_accuracy: 0.9959\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 147s 12ms/step - loss: 0.0267 - accuracy: 0.9943 - val_loss: 0.0230 - val_accuracy: 0.9952\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0259 - accuracy: 0.9945 - val_loss: 0.0199 - val_accuracy: 0.9957\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0224 - accuracy: 0.9949\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0226 - accuracy: 0.9950\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0260 - accuracy: 0.9944 - val_loss: 0.0208 - val_accuracy: 0.9955\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0252 - accuracy: 0.9947 - val_loss: 0.0272 - val_accuracy: 0.9944\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.0250 - accuracy: 0.9947 - val_loss: 0.0221 - val_accuracy: 0.9956\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0243 - accuracy: 0.9949 - val_loss: 0.0193 - val_accuracy: 0.9959\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 147s 12ms/step - loss: 0.0237 - accuracy: 0.9950 - val_loss: 0.0228 - val_accuracy: 0.9959\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0251 - accuracy: 0.9952\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0252 - accuracy: 0.9951\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0243 - accuracy: 0.9949 - val_loss: 0.0216 - val_accuracy: 0.9959\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.0233 - accuracy: 0.9951 - val_loss: 0.0194 - val_accuracy: 0.9961\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0227 - accuracy: 0.9952 - val_loss: 0.0192 - val_accuracy: 0.9961\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0227 - accuracy: 0.9953 - val_loss: 0.0209 - val_accuracy: 0.9955\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0226 - accuracy: 0.9953 - val_loss: 0.0213 - val_accuracy: 0.9962\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0227 - accuracy: 0.9958\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0240 - accuracy: 0.9954\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0227 - accuracy: 0.9952 - val_loss: 0.0203 - val_accuracy: 0.9960\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0229 - accuracy: 0.9952 - val_loss: 0.0201 - val_accuracy: 0.9962\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0224 - accuracy: 0.9953 - val_loss: 0.0198 - val_accuracy: 0.9960\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.0218 - accuracy: 0.9954 - val_loss: 0.0168 - val_accuracy: 0.9964\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0219 - accuracy: 0.9954 - val_loss: 0.0241 - val_accuracy: 0.9957\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0266 - accuracy: 0.9950\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0285 - accuracy: 0.9945\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0226 - accuracy: 0.9952 - val_loss: 0.0181 - val_accuracy: 0.9961\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0226 - accuracy: 0.9952 - val_loss: 0.0175 - val_accuracy: 0.9962\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0226 - accuracy: 0.9952 - val_loss: 0.0189 - val_accuracy: 0.9961\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.0222 - accuracy: 0.9953 - val_loss: 0.0195 - val_accuracy: 0.9961\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0221 - accuracy: 0.9953 - val_loss: 0.0259 - val_accuracy: 0.9946\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0277 - accuracy: 0.9941\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0308 - accuracy: 0.9928\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0231 - accuracy: 0.9951 - val_loss: 0.0182 - val_accuracy: 0.9962\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0230 - accuracy: 0.9951 - val_loss: 0.0242 - val_accuracy: 0.9950\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.0228 - accuracy: 0.9951 - val_loss: 0.0194 - val_accuracy: 0.9961\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0227 - accuracy: 0.9952 - val_loss: 0.0195 - val_accuracy: 0.9959\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0224 - accuracy: 0.9952 - val_loss: 0.0198 - val_accuracy: 0.9959\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0215 - accuracy: 0.9955\n",
      "3125/3125 [==============================] - 23s 8ms/step - loss: 0.0230 - accuracy: 0.9952\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0241 - accuracy: 0.9947 - val_loss: 0.0211 - val_accuracy: 0.9953\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0239 - accuracy: 0.9948 - val_loss: 0.0245 - val_accuracy: 0.9949\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0238 - accuracy: 0.9949 - val_loss: 0.0204 - val_accuracy: 0.9957\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0236 - accuracy: 0.9949 - val_loss: 0.0205 - val_accuracy: 0.9955\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0235 - accuracy: 0.9949 - val_loss: 0.0200 - val_accuracy: 0.9957\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0221 - accuracy: 0.9952\n",
      "3125/3125 [==============================] - 23s 8ms/step - loss: 0.0231 - accuracy: 0.9951\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0258 - accuracy: 0.9944 - val_loss: 0.0219 - val_accuracy: 0.9954\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0258 - accuracy: 0.9943 - val_loss: 0.0219 - val_accuracy: 0.9954\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0257 - accuracy: 0.9944 - val_loss: 0.0223 - val_accuracy: 0.9955\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0255 - accuracy: 0.9944 - val_loss: 0.0294 - val_accuracy: 0.9932\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0252 - accuracy: 0.9945 - val_loss: 0.0339 - val_accuracy: 0.9925\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0356 - accuracy: 0.9919\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 0.0496 - accuracy: 0.9866\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0284 - accuracy: 0.9936 - val_loss: 0.0254 - val_accuracy: 0.9945\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0279 - accuracy: 0.9938 - val_loss: 0.0250 - val_accuracy: 0.9945\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0280 - accuracy: 0.9938 - val_loss: 0.0246 - val_accuracy: 0.9945\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0276 - accuracy: 0.9938 - val_loss: 0.0270 - val_accuracy: 0.9940\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0276 - accuracy: 0.9939 - val_loss: 0.0367 - val_accuracy: 0.9908\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0381 - accuracy: 0.9907\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0526 - accuracy: 0.9854\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0308 - accuracy: 0.9930 - val_loss: 0.0304 - val_accuracy: 0.9932\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0306 - accuracy: 0.9930 - val_loss: 0.0266 - val_accuracy: 0.9940\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.0302 - accuracy: 0.9931 - val_loss: 0.0269 - val_accuracy: 0.9939\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0299 - accuracy: 0.9932 - val_loss: 0.0281 - val_accuracy: 0.9939\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0298 - accuracy: 0.9933 - val_loss: 0.0288 - val_accuracy: 0.9937\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0314 - accuracy: 0.9929\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0390 - accuracy: 0.9907\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 153s 12ms/step - loss: 0.0339 - accuracy: 0.9921 - val_loss: 0.0329 - val_accuracy: 0.9926\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0337 - accuracy: 0.9922 - val_loss: 0.0291 - val_accuracy: 0.9933\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0330 - accuracy: 0.9924 - val_loss: 0.0289 - val_accuracy: 0.9936\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0329 - accuracy: 0.9924 - val_loss: 0.0296 - val_accuracy: 0.9932\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0327 - accuracy: 0.9925 - val_loss: 0.0293 - val_accuracy: 0.9933\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 0.0321 - accuracy: 0.9924\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 0.0379 - accuracy: 0.9908\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 146s 12ms/step - loss: 0.0377 - accuracy: 0.9911 - val_loss: 0.0338 - val_accuracy: 0.9921\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 147s 12ms/step - loss: 0.0371 - accuracy: 0.9912 - val_loss: 0.0362 - val_accuracy: 0.9913\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 0.0362 - val_accuracy: 0.9911\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 147s 12ms/step - loss: 0.0366 - accuracy: 0.9914 - val_loss: 0.0333 - val_accuracy: 0.9922\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0363 - accuracy: 0.9914 - val_loss: 0.0323 - val_accuracy: 0.9925\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0350 - accuracy: 0.9919\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 0.0461 - accuracy: 0.9881\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0420 - accuracy: 0.9898 - val_loss: 0.0387 - val_accuracy: 0.9908\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0416 - accuracy: 0.9900 - val_loss: 0.0399 - val_accuracy: 0.9906\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0413 - accuracy: 0.9900 - val_loss: 0.0378 - val_accuracy: 0.9910\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0410 - accuracy: 0.9902 - val_loss: 0.0379 - val_accuracy: 0.9908\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0409 - accuracy: 0.9901 - val_loss: 0.0372 - val_accuracy: 0.9912\n",
      "3125/3125 [==============================] - 23s 8ms/step - loss: 0.0405 - accuracy: 0.9903\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0516 - accuracy: 0.9865\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0471 - accuracy: 0.9882 - val_loss: 0.0447 - val_accuracy: 0.9889\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.0468 - accuracy: 0.9884 - val_loss: 0.0446 - val_accuracy: 0.9889\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0465 - accuracy: 0.9884 - val_loss: 0.0441 - val_accuracy: 0.9889\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 147s 12ms/step - loss: 0.0463 - accuracy: 0.9885 - val_loss: 0.0432 - val_accuracy: 0.9893\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0461 - accuracy: 0.9886 - val_loss: 0.0443 - val_accuracy: 0.9888\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0462 - accuracy: 0.9884\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0621 - accuracy: 0.9834\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0542 - accuracy: 0.9862 - val_loss: 0.0503 - val_accuracy: 0.9873\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 154s 12ms/step - loss: 0.0539 - accuracy: 0.9863 - val_loss: 0.0506 - val_accuracy: 0.9873\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0537 - accuracy: 0.9864 - val_loss: 0.0527 - val_accuracy: 0.9866\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0534 - accuracy: 0.9865 - val_loss: 0.0509 - val_accuracy: 0.9870\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0531 - accuracy: 0.9865 - val_loss: 0.0507 - val_accuracy: 0.9868\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 0.0535 - accuracy: 0.9865\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0699 - accuracy: 0.9802\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0620 - accuracy: 0.9837 - val_loss: 0.0607 - val_accuracy: 0.9843\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0615 - accuracy: 0.9839 - val_loss: 0.0589 - val_accuracy: 0.9844\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0612 - accuracy: 0.9840 - val_loss: 0.0591 - val_accuracy: 0.9845\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.0610 - accuracy: 0.9840 - val_loss: 0.0593 - val_accuracy: 0.9844\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0608 - accuracy: 0.9841 - val_loss: 0.0582 - val_accuracy: 0.9846\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0594 - accuracy: 0.9844\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0790 - accuracy: 0.9772\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0714 - accuracy: 0.9807 - val_loss: 0.0700 - val_accuracy: 0.9812\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0710 - accuracy: 0.9808 - val_loss: 0.0697 - val_accuracy: 0.9812\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0707 - accuracy: 0.9809 - val_loss: 0.0691 - val_accuracy: 0.9814\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0703 - accuracy: 0.9811 - val_loss: 0.0694 - val_accuracy: 0.9814\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0701 - accuracy: 0.9811 - val_loss: 0.0678 - val_accuracy: 0.9817\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0706 - accuracy: 0.9812\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 0.0925 - accuracy: 0.9735\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 147s 12ms/step - loss: 0.0825 - accuracy: 0.9768 - val_loss: 0.0849 - val_accuracy: 0.9764\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 153s 12ms/step - loss: 0.0819 - accuracy: 0.9770 - val_loss: 0.0818 - val_accuracy: 0.9769\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.0814 - accuracy: 0.9772 - val_loss: 0.0825 - val_accuracy: 0.9766\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 153s 12ms/step - loss: 0.0810 - accuracy: 0.9773 - val_loss: 0.0841 - val_accuracy: 0.9761\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.0806 - accuracy: 0.9774 - val_loss: 0.0813 - val_accuracy: 0.9774\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0823 - accuracy: 0.9769\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.1095 - accuracy: 0.9674\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0950 - accuracy: 0.9726 - val_loss: 0.0930 - val_accuracy: 0.9733\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.0942 - accuracy: 0.9729 - val_loss: 0.0922 - val_accuracy: 0.9734\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0935 - accuracy: 0.9731 - val_loss: 0.0929 - val_accuracy: 0.9730\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 153s 12ms/step - loss: 0.0930 - accuracy: 0.9734 - val_loss: 0.0909 - val_accuracy: 0.9742\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.0924 - accuracy: 0.9736 - val_loss: 0.0900 - val_accuracy: 0.9742\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0915 - accuracy: 0.9739\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.1212 - accuracy: 0.9620\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.1075 - accuracy: 0.9681 - val_loss: 0.1055 - val_accuracy: 0.9686\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1062 - accuracy: 0.9684 - val_loss: 0.1031 - val_accuracy: 0.9690\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1043 - accuracy: 0.9691 - val_loss: 0.1015 - val_accuracy: 0.9697\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.1026 - accuracy: 0.9697 - val_loss: 0.1006 - val_accuracy: 0.9704\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1005 - accuracy: 0.9705 - val_loss: 0.0988 - val_accuracy: 0.9708\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0994 - accuracy: 0.9706\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.1275 - accuracy: 0.9598\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1151 - accuracy: 0.9649 - val_loss: 0.1113 - val_accuracy: 0.9666\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 153s 12ms/step - loss: 0.1113 - accuracy: 0.9665 - val_loss: 0.1086 - val_accuracy: 0.9678\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.1080 - accuracy: 0.9677 - val_loss: 0.1060 - val_accuracy: 0.9682\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.1048 - accuracy: 0.9689 - val_loss: 0.1041 - val_accuracy: 0.9691\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.1023 - accuracy: 0.9699 - val_loss: 0.0999 - val_accuracy: 0.9709\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.0996 - accuracy: 0.9708\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.1255 - accuracy: 0.9609\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.1146 - accuracy: 0.9652 - val_loss: 0.1094 - val_accuracy: 0.9674\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.1107 - accuracy: 0.9668 - val_loss: 0.1074 - val_accuracy: 0.9681\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.1090 - accuracy: 0.9675 - val_loss: 0.1046 - val_accuracy: 0.9688\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1070 - accuracy: 0.9681 - val_loss: 0.1075 - val_accuracy: 0.9671\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1060 - accuracy: 0.9684 - val_loss: 0.1017 - val_accuracy: 0.9697\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.1036 - accuracy: 0.9695\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 0.1350 - accuracy: 0.9562\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.1226 - accuracy: 0.9620 - val_loss: 0.1221 - val_accuracy: 0.9620\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.1212 - accuracy: 0.9627 - val_loss: 0.1157 - val_accuracy: 0.9647\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.1205 - accuracy: 0.9629 - val_loss: 0.1222 - val_accuracy: 0.9616\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1195 - accuracy: 0.9632 - val_loss: 0.1179 - val_accuracy: 0.9638\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.1189 - accuracy: 0.9635 - val_loss: 0.1189 - val_accuracy: 0.9631\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.1189 - accuracy: 0.9638\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.1531 - accuracy: 0.9507\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.1380 - accuracy: 0.9560 - val_loss: 0.1338 - val_accuracy: 0.9573\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.1371 - accuracy: 0.9563 - val_loss: 0.1388 - val_accuracy: 0.9553\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1366 - accuracy: 0.9565 - val_loss: 0.1466 - val_accuracy: 0.9525\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1360 - accuracy: 0.9568 - val_loss: 0.1366 - val_accuracy: 0.9564\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 147s 12ms/step - loss: 0.1359 - accuracy: 0.9567 - val_loss: 0.1350 - val_accuracy: 0.9570\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 0.1330 - accuracy: 0.9582\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 0.1677 - accuracy: 0.9435\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1581 - accuracy: 0.9478 - val_loss: 0.1572 - val_accuracy: 0.9472\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1575 - accuracy: 0.9479 - val_loss: 0.1567 - val_accuracy: 0.9482\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 147s 12ms/step - loss: 0.1572 - accuracy: 0.9480 - val_loss: 0.1569 - val_accuracy: 0.9481\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.1567 - accuracy: 0.9482 - val_loss: 0.1578 - val_accuracy: 0.9482\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.1566 - accuracy: 0.9483 - val_loss: 0.1591 - val_accuracy: 0.9474\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 0.1585 - accuracy: 0.9475\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.1984 - accuracy: 0.9330\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1835 - accuracy: 0.9365 - val_loss: 0.1818 - val_accuracy: 0.9372\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1826 - accuracy: 0.9368 - val_loss: 0.1809 - val_accuracy: 0.9377\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.1823 - accuracy: 0.9370 - val_loss: 0.1814 - val_accuracy: 0.9373\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1820 - accuracy: 0.9370 - val_loss: 0.1830 - val_accuracy: 0.9361\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.1817 - accuracy: 0.9371 - val_loss: 0.1812 - val_accuracy: 0.9376\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.1811 - accuracy: 0.9377\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 0.2279 - accuracy: 0.9176\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.2125 - accuracy: 0.9228 - val_loss: 0.2141 - val_accuracy: 0.9228\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.2114 - accuracy: 0.9234 - val_loss: 0.2131 - val_accuracy: 0.9222\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.2110 - accuracy: 0.9235 - val_loss: 0.2145 - val_accuracy: 0.9222\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 152s 12ms/step - loss: 0.2106 - accuracy: 0.9238 - val_loss: 0.2135 - val_accuracy: 0.9228\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.2104 - accuracy: 0.9239 - val_loss: 0.2135 - val_accuracy: 0.9222\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 0.2106 - accuracy: 0.9238\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.2657 - accuracy: 0.8999\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.2466 - accuracy: 0.9062 - val_loss: 0.2509 - val_accuracy: 0.9041\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.2455 - accuracy: 0.9070 - val_loss: 0.2522 - val_accuracy: 0.9039\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.2449 - accuracy: 0.9070 - val_loss: 0.2509 - val_accuracy: 0.9042\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 147s 12ms/step - loss: 0.2444 - accuracy: 0.9074 - val_loss: 0.2535 - val_accuracy: 0.9035\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.2444 - accuracy: 0.9072 - val_loss: 0.2497 - val_accuracy: 0.9041\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.2451 - accuracy: 0.9063\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 0.3056 - accuracy: 0.8827\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.2865 - accuracy: 0.8857 - val_loss: 0.2911 - val_accuracy: 0.8822\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.2846 - accuracy: 0.8866 - val_loss: 0.2898 - val_accuracy: 0.8829\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.2838 - accuracy: 0.8869 - val_loss: 0.2915 - val_accuracy: 0.8814\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 150s 12ms/step - loss: 0.2835 - accuracy: 0.8872 - val_loss: 0.2885 - val_accuracy: 0.8841\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.2832 - accuracy: 0.8873 - val_loss: 0.2885 - val_accuracy: 0.8839\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.2862 - accuracy: 0.8861\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.3608 - accuracy: 0.8570\n",
      "Epoch 1/5\n",
      "12516/12516 [==============================] - 147s 12ms/step - loss: 0.3342 - accuracy: 0.8601 - val_loss: 0.3374 - val_accuracy: 0.8587\n",
      "Epoch 2/5\n",
      "12516/12516 [==============================] - 151s 12ms/step - loss: 0.3319 - accuracy: 0.8605 - val_loss: 0.3331 - val_accuracy: 0.8598\n",
      "Epoch 3/5\n",
      "12516/12516 [==============================] - 149s 12ms/step - loss: 0.3312 - accuracy: 0.8610 - val_loss: 0.3357 - val_accuracy: 0.8594\n",
      "Epoch 4/5\n",
      "12516/12516 [==============================] - 147s 12ms/step - loss: 0.3308 - accuracy: 0.8615 - val_loss: 0.3334 - val_accuracy: 0.8602\n",
      "Epoch 5/5\n",
      "12516/12516 [==============================] - 148s 12ms/step - loss: 0.3302 - accuracy: 0.8617 - val_loss: 0.3375 - val_accuracy: 0.8575\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 0.3352 - accuracy: 0.8590\n"
     ]
    }
   ],
   "source": [
    "scale_steps = np.logspace(-3, 0, 30)\n",
    "before_train_loss = []\n",
    "after_train_loss = []\n",
    "\n",
    "for scale in scale_steps:\n",
    "    x_train2_gen = np.random.normal(x_train2, np.sqrt(x_train2)*scale)\n",
    "    x_test_gen = np.random.normal(x_test, np.sqrt(x_test)*scale)\n",
    "\n",
    "    before_train_loss.append(model.evaluate(x_test_gen, y_test)[0])\n",
    "\n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "               validation_split = 0.1,\n",
    "               batch_size=64,\n",
    "               epochs=5,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "\n",
    "    after_train_loss.append(model.evaluate(x_test_gen, y_test)[0])\n",
    "    model.save(path.format(exposure, model_index, furthur_index) + '/std={}.h5'.format(scale))\n",
    "model.save(path.format(exposure, model_index, furthur_index) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Poisson_index = 1\n",
    "path = directory + 'models_PoissonTrain/0910{}_{}_{}_{}'\n",
    "while os.path.isdir(path.format(exposure, model_index, furthur_index, Poisson_index)):\n",
    "    Poisson_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12516/12516 [==============================] - 164s 13ms/step - loss: 0.3308 - accuracy: 0.8614 - val_loss: 0.3312 - val_accuracy: 0.8617\n",
      "12516/12516 [==============================] - 162s 13ms/step - loss: 0.3316 - accuracy: 0.8610 - val_loss: 0.3359 - val_accuracy: 0.8577\n",
      "12516/12516 [==============================] - 163s 13ms/step - loss: 0.3307 - accuracy: 0.8611 - val_loss: 0.3345 - val_accuracy: 0.8595\n",
      "12516/12516 [==============================] - 162s 13ms/step - loss: 0.3299 - accuracy: 0.8620 - val_loss: 0.3322 - val_accuracy: 0.8604\n",
      "12516/12516 [==============================] - 161s 13ms/step - loss: 0.3301 - accuracy: 0.8615 - val_loss: 0.3359 - val_accuracy: 0.8579\n",
      "12516/12516 [==============================] - 161s 13ms/step - loss: 0.3307 - accuracy: 0.8612 - val_loss: 0.3332 - val_accuracy: 0.8612\n",
      "12516/12516 [==============================] - 164s 13ms/step - loss: 0.3304 - accuracy: 0.8616 - val_loss: 0.3312 - val_accuracy: 0.8617\n",
      "12516/12516 [==============================] - 162s 13ms/step - loss: 0.3294 - accuracy: 0.8619 - val_loss: 0.3315 - val_accuracy: 0.8611\n",
      "12516/12516 [==============================] - 161s 13ms/step - loss: 0.3303 - accuracy: 0.8617 - val_loss: 0.3326 - val_accuracy: 0.8602\n",
      "12516/12516 [==============================] - 164s 13ms/step - loss: 0.3300 - accuracy: 0.8619 - val_loss: 0.3312 - val_accuracy: 0.8607\n",
      "3125/3125 [==============================] - 33s 10ms/step - loss: 0.3297 - accuracy: 0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3296508491039276, 0.8612099885940552]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_gen = np.random.poisson(x_test)\n",
    "\n",
    "for i in range(10):\n",
    "    x_train2_gen = np.random.poisson(x_train2)\n",
    "    \n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "              validation_split=0.1,\n",
    "               batch_size=64,\n",
    "               epochs=1,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "    model.save(path.format(exposure, model_index, furthur_index, Poisson_index) + '/steps={}.h5'.format(i))\n",
    "model.save(path.format(exposure, model_index, furthur_index, Poisson_index) + '.h5')\n",
    "model.evaluate(x_test_gen, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpc = np.where(y_test == 0)\n",
    "cpv = np.where(y_test == 1)\n",
    "plt.hist(pred[cpc], bins =100)\n",
    "plt.hist(pred[cpv], bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
