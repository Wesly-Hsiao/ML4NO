{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "parliamentary-triangle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import os\n",
    "import importlib\n",
    "import logging\n",
    "from functions import load_train_data\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=40000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feeffb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3flavor_clean, 3flavor_poisson, nsi_clean, nsi_poisson\n",
    "learn_target = '3flavor_clean'\n",
    "\n",
    "x_train, y_train, x_val, y_val = load_train_data(learn_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5fa6e9",
   "metadata": {},
   "source": [
    "Encoder 1 (parameter + spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "particular-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder1(guassian_number, latent_dim, latent_dim_2, x_parameter_node, x_spectrum_node, x_latent_node):\n",
    "    encoder_parameter_inputs = layers.Input(shape=(len(y_train[0]),),name = 'encoder_parameter_inputs')\n",
    "    encoder_spectrum_inputs = layers.Input(shape=(len(x_train[0])),name = 'encoder_spectrum_inputs')\n",
    "    encoder_spectrum_inputs_norm = layers.BatchNormalization()(encoder_spectrum_inputs)\n",
    "    encoder1_inputs = Concatenate()([encoder_parameter_inputs, encoder_spectrum_inputs_norm])\n",
    "    x_parameter = layers.Dense(x_parameter_node[0], activation=\"relu\")(encoder1_inputs)\n",
    "    x_parameter = layers.Dense(x_parameter_node[1], activation=\"relu\")(x_parameter)\n",
    "    x_parameter = layers.Dense(x_parameter_node[2], activation=\"relu\")(x_parameter)\n",
    "\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x_parameter)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x_parameter)\n",
    "\n",
    "    return keras.Model(inputs=[encoder_parameter_inputs, encoder_spectrum_inputs], outputs=[z_mean, z_log_var], name=\"encoder_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86632ca6",
   "metadata": {},
   "source": [
    "Encoder2 (spectrum to latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "controlled-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder2(guassian_number, latent_dim, latent_dim_2, x_parameter_node, x_spectrum_node, x_latent_node):\n",
    "    encoder_spectrum_inputs = layers.Input(shape=(len(x_train[0]),),name = 'encoder_spectrum_inputs')\n",
    "    encoder_spectrum_inputs_norm = layers.BatchNormalization()(encoder_spectrum_inputs)\n",
    "    x_spectrum = layers.Dense(x_spectrum_node[0], activation=\"relu\")(encoder_spectrum_inputs_norm)\n",
    "    x_spectrum = layers.Dense(x_spectrum_node[1], activation=\"relu\")(x_spectrum)\n",
    "    x_spectrum = layers.Dense(x_spectrum_node[2], activation=\"relu\")(x_spectrum)\n",
    "\n",
    "    z_mean = layers.Dense(guassian_number*latent_dim, name=\"z_mean\")(x_spectrum)\n",
    "    z_log_var = layers.Dense(guassian_number*latent_dim, name=\"z_log_var\")(x_spectrum)\n",
    "    z_weight = layers.Dense(guassian_number, name=\"z_weight\")(x_spectrum)\n",
    "\n",
    "    return keras.Model(inputs=encoder_spectrum_inputs, outputs=[z_mean, z_log_var, z_weight], name=\"encoder_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef690d",
   "metadata": {},
   "source": [
    "Decoder (latent to spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fantastic-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(guassian_number, latent_dim, latent_dim_2, x_parameter_node, x_spectrum_node, x_latent_node):\n",
    "    decoder_latent_inputs = keras.Input(shape=(latent_dim,),name = 'decoder_latent_inputs')\n",
    "    decoder_spectrum_inputs = layers.Input(shape=(len(x_train[0]),),name = 'decoder_spectrum_inputs')\n",
    "    decoder_spectrum_inputs_norm = layers.BatchNormalization()(decoder_spectrum_inputs)\n",
    "    decoder_inputs = Concatenate()([decoder_latent_inputs,decoder_spectrum_inputs_norm])\n",
    "\n",
    "    x_latent = layers.Dense(x_latent_node[0], activation=\"relu\", name = 'dense_1')(decoder_inputs)\n",
    "    x_latent = layers.Dense(x_latent_node[1], activation=\"relu\", name = 'dense_2')(x_latent)\n",
    "    x_latent = layers.Dense(x_latent_node[2], activation=\"relu\", name = 'dense_3')(x_latent)\n",
    "\n",
    "    z2_mean = layers.Dense(latent_dim_2, name=\"z_mean\")(x_latent)\n",
    "    z2_log_var = layers.Dense(latent_dim_2, name=\"z_log_var\")(x_latent)\n",
    "\n",
    "    return keras.Model(inputs=[decoder_latent_inputs, decoder_spectrum_inputs], outputs=[z2_mean, z2_log_var], name=\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specific-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_cvae_model(keras.Model):\n",
    "    def __init__(self, guassian_number, latent_dim, latent_dim_2, x_parameter_node, x_spectrum_node, x_latent_node, kl_scaling, **kwargs):\n",
    "        super(create_cvae_model, self).__init__(**kwargs)\n",
    "        self.encoder1 = encoder1(guassian_number, latent_dim, latent_dim_2, x_parameter_node, x_spectrum_node, x_latent_node)\n",
    "        self.encoder2 = encoder2(guassian_number, latent_dim, latent_dim_2, x_parameter_node, x_spectrum_node, x_latent_node)\n",
    "        self.decoder = decoder(guassian_number, latent_dim, latent_dim_2, x_parameter_node, x_spectrum_node, x_latent_node)\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.val_reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.val_reconstruction_loss_tracker,\n",
    "                ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            SMALL_CONSTANT = 1e-12\n",
    "            \n",
    "            z1_mean, z1_log_var = self.encoder1(x)\n",
    "            \n",
    "            temp_var_q = SMALL_CONSTANT + tf.exp(z1_log_var)\n",
    "            mvn_q = tfp.distributions.MultivariateNormalDiag(\n",
    "                          loc=z1_mean,\n",
    "                          scale_diag=temp_var_q)\n",
    "            \n",
    "            z1 = mvn_q.sample()\n",
    "            \n",
    "            z2_mean, z2_log_var, z2_weight = self.encoder2(x[1])\n",
    "\n",
    "            z2_mean = tf.reshape(z2_mean, (-1, gaussian_number, latent_dim))\n",
    "            z2_log_var = tf.reshape(z2_log_var, (-1, gaussian_number, latent_dim))\n",
    "            z2_weight = tf.reshape(z2_weight, (-1, gaussian_number))\n",
    "            \n",
    "            temp_var_r1 = SMALL_CONSTANT + tf.exp(z2_log_var)\n",
    "            bimix_gauss = tfp.distributions.MixtureSameFamily(\n",
    "                          mixture_distribution=tfp.distributions.Categorical(logits=z2_weight),\n",
    "                          components_distribution=tfp.distributions.MultivariateNormalDiag(\n",
    "                          loc=z2_mean,\n",
    "                          scale_diag=temp_var_r1))\n",
    "            \n",
    "            reconstruction_mean, reconstruction_var = self.decoder([z1, x[1]])     \n",
    "            \n",
    "            temp_var_r2 = SMALL_CONSTANT + tf.exp(reconstruction_var)\n",
    "            reconstruction_parameter = tfp.distributions.MultivariateNormalDiag(\n",
    "                                     loc=reconstruction_mean,\n",
    "                                     scale_diag=temp_var_r2)\n",
    "\n",
    "            kl_loss = tf.reduce_mean(mvn_q.log_prob(z1) - bimix_gauss.log_prob(z1))*kl_scaling\n",
    "            reconstruction_loss = -1.0*tf.reduce_mean(reconstruction_parameter.log_prob(y))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def evaluate(self,\n",
    "               x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None,\n",
    "               callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False,return_dict=False,\n",
    "               **kwargs):\n",
    "        SMALL_CONSTANT = 1e-12\n",
    "        \n",
    "        z2_mean, z2_log_var, z2_weight = self.encoder2(x[1])\n",
    "\n",
    "        z2_mean = tf.reshape(z2_mean, (-1, gaussian_number, latent_dim))\n",
    "        z2_log_var = tf.reshape(z2_log_var, (-1, gaussian_number, latent_dim))\n",
    "        z2_weight = tf.reshape(z2_weight, (-1, gaussian_number))\n",
    "        \n",
    "        temp_var_r1 = SMALL_CONSTANT + tf.exp(z2_log_var)\n",
    "        bimix_gauss = tfp.distributions.MixtureSameFamily(\n",
    "                        mixture_distribution=\n",
    "                        tfp.distributions.Categorical(logits=z2_weight), components_distribution=\n",
    "                        tfp.distributions.MultivariateNormalDiag(loc=z2_mean, scale_diag=temp_var_r1))\n",
    "        z3 = bimix_gauss.sample()\n",
    "        reconstruction_mean, reconstruction_var = self.decoder([z3, x[1]])     \n",
    "        \n",
    "        temp_var_r2 = SMALL_CONSTANT + tf.exp(reconstruction_var)\n",
    "        reconstruction_parameter = tfp.distributions.MultivariateNormalDiag(\n",
    "                                    loc=reconstruction_mean,\n",
    "                                    scale_diag=temp_var_r2)\n",
    "\n",
    "        reconstruction_loss = -1.0*tf.reduce_mean(reconstruction_parameter.log_prob(y))\n",
    "        \n",
    "        self.val_reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        return {\"reconstruction_loss\": self.val_reconstruction_loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3b812",
   "metadata": {},
   "source": [
    "Model Building, Train, and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc69e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_number = 10\n",
    "latent_dim = 10\n",
    "latent_dim_2 = len(y_train[0])\n",
    "x_parameter_node = [64, 64, 64]\n",
    "x_spectrum_node = x_parameter_node\n",
    "x_latent_node = x_parameter_node\n",
    "kl_scaling = 1\n",
    "lr = 0.0001\n",
    "# x_spectrum_node = [256, 64, 16]\n",
    "# x_latent_node = [256, 64, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "subsequent-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/distributions/distribution.py:342: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n",
      "900/900 [==============================] - 10s 8ms/step - loss: 0.6806 - reconstruction_loss: -1.7103 - kl_loss: 0.0269 - val_reconstruction_loss: -3.1930\n",
      "Epoch 2/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -3.6002 - reconstruction_loss: -3.7559 - kl_loss: 0.0118 - val_reconstruction_loss: -4.0354\n",
      "Epoch 3/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.0573 - reconstruction_loss: -4.1034 - kl_loss: 0.0105 - val_reconstruction_loss: -4.1796\n",
      "Epoch 4/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.1615 - reconstruction_loss: -4.1760 - kl_loss: 0.0107 - val_reconstruction_loss: -4.2131\n",
      "Epoch 5/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.2285 - reconstruction_loss: -4.2635 - kl_loss: 0.0120 - val_reconstruction_loss: -4.3603\n",
      "Epoch 6/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.3509 - reconstruction_loss: -4.3891 - kl_loss: 0.0123 - val_reconstruction_loss: -4.4538\n",
      "Epoch 7/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.4288 - reconstruction_loss: -4.4604 - kl_loss: 0.0136 - val_reconstruction_loss: -4.4879\n",
      "Epoch 8/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.5052 - reconstruction_loss: -4.5192 - kl_loss: 0.0144 - val_reconstruction_loss: -4.5477\n",
      "Epoch 9/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.5199 - reconstruction_loss: -4.5578 - kl_loss: 0.0141 - val_reconstruction_loss: -4.4897\n",
      "Epoch 10/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.5539 - reconstruction_loss: -4.5790 - kl_loss: 0.0147 - val_reconstruction_loss: -4.6123\n",
      "Epoch 11/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.6094 - reconstruction_loss: -4.6272 - kl_loss: 0.0144 - val_reconstruction_loss: -4.6108\n",
      "Epoch 12/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.6423 - reconstruction_loss: -4.6656 - kl_loss: 0.0156 - val_reconstruction_loss: -4.6489\n",
      "Epoch 13/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.6607 - reconstruction_loss: -4.6845 - kl_loss: 0.0152 - val_reconstruction_loss: -4.5216\n",
      "Epoch 14/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.6975 - reconstruction_loss: -4.7250 - kl_loss: 0.0168 - val_reconstruction_loss: -4.7492\n",
      "Epoch 15/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.7214 - reconstruction_loss: -4.7392 - kl_loss: 0.0176 - val_reconstruction_loss: -4.7028\n",
      "Epoch 16/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.7674 - reconstruction_loss: -4.7897 - kl_loss: 0.0173 - val_reconstruction_loss: -4.7766\n",
      "Epoch 17/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.7994 - reconstruction_loss: -4.8227 - kl_loss: 0.0193 - val_reconstruction_loss: -4.6030\n",
      "Epoch 18/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.8310 - reconstruction_loss: -4.8578 - kl_loss: 0.0194 - val_reconstruction_loss: -4.8645\n",
      "Epoch 19/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -4.8744 - reconstruction_loss: -4.9191 - kl_loss: 0.0197 - val_reconstruction_loss: -4.8954\n",
      "Epoch 20/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.9224 - reconstruction_loss: -4.9737 - kl_loss: 0.0204 - val_reconstruction_loss: -5.0342\n",
      "Epoch 21/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.0124 - reconstruction_loss: -5.0436 - kl_loss: 0.0216 - val_reconstruction_loss: -5.0835\n",
      "Epoch 22/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.0857 - reconstruction_loss: -5.1285 - kl_loss: 0.0219 - val_reconstruction_loss: -5.0973\n",
      "Epoch 23/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.1360 - reconstruction_loss: -5.1917 - kl_loss: 0.0244 - val_reconstruction_loss: -5.2497\n",
      "Epoch 24/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.2373 - reconstruction_loss: -5.2836 - kl_loss: 0.0245 - val_reconstruction_loss: -5.3661\n",
      "Epoch 25/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.3726 - reconstruction_loss: -5.4317 - kl_loss: 0.0255 - val_reconstruction_loss: -5.4966\n",
      "Epoch 26/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.4948 - reconstruction_loss: -5.5707 - kl_loss: 0.0283 - val_reconstruction_loss: -5.5331\n",
      "Epoch 27/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.6535 - reconstruction_loss: -5.7500 - kl_loss: 0.0301 - val_reconstruction_loss: -5.8949\n",
      "Epoch 28/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.9361 - reconstruction_loss: -6.0378 - kl_loss: 0.0329 - val_reconstruction_loss: -6.1941\n",
      "Epoch 29/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -6.2027 - reconstruction_loss: -6.3364 - kl_loss: 0.0363 - val_reconstruction_loss: -6.3844\n",
      "Epoch 30/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -6.4752 - reconstruction_loss: -6.5969 - kl_loss: 0.0392 - val_reconstruction_loss: -6.6737\n",
      "Epoch 31/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -6.7279 - reconstruction_loss: -6.8173 - kl_loss: 0.0426 - val_reconstruction_loss: -6.8679\n",
      "Epoch 32/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -6.9184 - reconstruction_loss: -6.9867 - kl_loss: 0.0464 - val_reconstruction_loss: -7.0523\n",
      "Epoch 33/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.0757 - reconstruction_loss: -7.1829 - kl_loss: 0.0520 - val_reconstruction_loss: -7.2266\n",
      "Epoch 34/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.2637 - reconstruction_loss: -7.3847 - kl_loss: 0.0602 - val_reconstruction_loss: -6.9638\n",
      "Epoch 35/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.5738 - reconstruction_loss: -7.7259 - kl_loss: 0.0680 - val_reconstruction_loss: -7.7929\n",
      "Epoch 36/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.8572 - reconstruction_loss: -7.9677 - kl_loss: 0.0714 - val_reconstruction_loss: -8.0012\n",
      "Epoch 37/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.0068 - reconstruction_loss: -8.1034 - kl_loss: 0.0747 - val_reconstruction_loss: -8.0882\n",
      "Epoch 38/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.1113 - reconstruction_loss: -8.2070 - kl_loss: 0.0775 - val_reconstruction_loss: -8.1491\n",
      "Epoch 39/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.1735 - reconstruction_loss: -8.2585 - kl_loss: 0.0798 - val_reconstruction_loss: -8.1466\n",
      "Epoch 40/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.2163 - reconstruction_loss: -8.2923 - kl_loss: 0.0858 - val_reconstruction_loss: -8.2496\n",
      "Epoch 41/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.2469 - reconstruction_loss: -8.3359 - kl_loss: 0.0865 - val_reconstruction_loss: -7.8474\n",
      "Epoch 42/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.2659 - reconstruction_loss: -8.3689 - kl_loss: 0.0916 - val_reconstruction_loss: -8.2913\n",
      "Epoch 43/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.2977 - reconstruction_loss: -8.4147 - kl_loss: 0.0931 - val_reconstruction_loss: -8.3391\n",
      "Epoch 44/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.3615 - reconstruction_loss: -8.4729 - kl_loss: 0.0964 - val_reconstruction_loss: -8.3811\n",
      "Epoch 45/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.4369 - reconstruction_loss: -8.5376 - kl_loss: 0.1024 - val_reconstruction_loss: -8.3174\n",
      "Epoch 46/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.4621 - reconstruction_loss: -8.5874 - kl_loss: 0.1102 - val_reconstruction_loss: -8.3686\n",
      "Epoch 47/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.5278 - reconstruction_loss: -8.6534 - kl_loss: 0.1191 - val_reconstruction_loss: -8.3070\n",
      "Epoch 48/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.5769 - reconstruction_loss: -8.7217 - kl_loss: 0.1333 - val_reconstruction_loss: -8.1603\n",
      "Epoch 49/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.5795 - reconstruction_loss: -8.7595 - kl_loss: 0.1476 - val_reconstruction_loss: -8.4019\n",
      "Epoch 50/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.6527 - reconstruction_loss: -8.8366 - kl_loss: 0.1692 - val_reconstruction_loss: -8.4328\n",
      "Epoch 51/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.7032 - reconstruction_loss: -8.9043 - kl_loss: 0.1940 - val_reconstruction_loss: -8.1592\n",
      "Epoch 52/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.7012 - reconstruction_loss: -8.9494 - kl_loss: 0.2257 - val_reconstruction_loss: -8.4074\n",
      "Epoch 53/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.8033 - reconstruction_loss: -9.0859 - kl_loss: 0.2699 - val_reconstruction_loss: -8.2678\n",
      "Epoch 54/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.8559 - reconstruction_loss: -9.1920 - kl_loss: 0.3294 - val_reconstruction_loss: -7.9203\n",
      "Epoch 55/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.9217 - reconstruction_loss: -9.3441 - kl_loss: 0.4016 - val_reconstruction_loss: -7.4275\n",
      "Epoch 56/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.9953 - reconstruction_loss: -9.4908 - kl_loss: 0.4870 - val_reconstruction_loss: -7.3153\n",
      "Epoch 57/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.0506 - reconstruction_loss: -9.6345 - kl_loss: 0.5638 - val_reconstruction_loss: -6.7695\n",
      "Epoch 58/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.0604 - reconstruction_loss: -9.7077 - kl_loss: 0.6217 - val_reconstruction_loss: -6.3543\n",
      "Epoch 59/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.1687 - reconstruction_loss: -9.8385 - kl_loss: 0.6777 - val_reconstruction_loss: -6.2314\n",
      "Epoch 60/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.2603 - reconstruction_loss: -9.9899 - kl_loss: 0.7361 - val_reconstruction_loss: -5.6615\n",
      "Epoch 61/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.3048 - reconstruction_loss: -10.0857 - kl_loss: 0.7830 - val_reconstruction_loss: -5.1502\n",
      "Epoch 62/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.3276 - reconstruction_loss: -10.1585 - kl_loss: 0.8183 - val_reconstruction_loss: -3.9988\n",
      "Epoch 63/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.4255 - reconstruction_loss: -10.3091 - kl_loss: 0.8713 - val_reconstruction_loss: -3.6716\n",
      "Epoch 64/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.2903 - reconstruction_loss: -10.2347 - kl_loss: 0.8713 - val_reconstruction_loss: -3.4580\n",
      "Epoch 65/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.4993 - reconstruction_loss: -10.4251 - kl_loss: 0.9248 - val_reconstruction_loss: -2.4979\n",
      "Epoch 66/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.5219 - reconstruction_loss: -10.4681 - kl_loss: 0.9471 - val_reconstruction_loss: -2.5036\n",
      "Epoch 67/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.6055 - reconstruction_loss: -10.5778 - kl_loss: 0.9736 - val_reconstruction_loss: -1.2250\n",
      "Epoch 68/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.6217 - reconstruction_loss: -10.6599 - kl_loss: 1.0086 - val_reconstruction_loss: -0.4492\n",
      "Epoch 69/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.6849 - reconstruction_loss: -10.7130 - kl_loss: 1.0281 - val_reconstruction_loss: -1.1589\n",
      "Epoch 70/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.7404 - reconstruction_loss: -10.7850 - kl_loss: 1.0435 - val_reconstruction_loss: 0.9224\n",
      "Epoch 71/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.7260 - reconstruction_loss: -10.8026 - kl_loss: 1.0554 - val_reconstruction_loss: 1.2586\n",
      "Epoch 72/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.8372 - reconstruction_loss: -10.9186 - kl_loss: 1.0824 - val_reconstruction_loss: 1.7848\n",
      "Epoch 73/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.8778 - reconstruction_loss: -10.9779 - kl_loss: 1.1011 - val_reconstruction_loss: 3.0672\n",
      "Epoch 74/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.9142 - reconstruction_loss: -11.0326 - kl_loss: 1.1142 - val_reconstruction_loss: 2.9032\n",
      "Epoch 75/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.9523 - reconstruction_loss: -11.0355 - kl_loss: 1.1146 - val_reconstruction_loss: 1.6725\n",
      "Epoch 76/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.9715 - reconstruction_loss: -11.0909 - kl_loss: 1.1140 - val_reconstruction_loss: 4.0253\n",
      "Epoch 77/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.0085 - reconstruction_loss: -11.1833 - kl_loss: 1.1397 - val_reconstruction_loss: 4.2477\n",
      "Epoch 78/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.1062 - reconstruction_loss: -11.2459 - kl_loss: 1.1525 - val_reconstruction_loss: 3.6312\n",
      "Epoch 79/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.1703 - reconstruction_loss: -11.3604 - kl_loss: 1.1654 - val_reconstruction_loss: 6.2634\n",
      "Epoch 80/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.1964 - reconstruction_loss: -11.3506 - kl_loss: 1.1650 - val_reconstruction_loss: 6.0962\n",
      "Epoch 81/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.1782 - reconstruction_loss: -11.4031 - kl_loss: 1.1677 - val_reconstruction_loss: 7.3421\n",
      "Epoch 82/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.9883 - reconstruction_loss: -11.3240 - kl_loss: 1.1439 - val_reconstruction_loss: 6.5642\n",
      "Epoch 83/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.3250 - reconstruction_loss: -11.5241 - kl_loss: 1.1738 - val_reconstruction_loss: 7.1404\n",
      "Epoch 84/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.4317 - reconstruction_loss: -11.6085 - kl_loss: 1.1808 - val_reconstruction_loss: 9.8735\n",
      "Epoch 85/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.4612 - reconstruction_loss: -11.6774 - kl_loss: 1.1882 - val_reconstruction_loss: 10.1366\n",
      "Epoch 86/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.5466 - reconstruction_loss: -11.7216 - kl_loss: 1.1935 - val_reconstruction_loss: 8.0431\n",
      "Epoch 87/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.7292 - reconstruction_loss: -11.8939 - kl_loss: 1.2017 - val_reconstruction_loss: 10.4934\n",
      "Epoch 88/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.6940 - reconstruction_loss: -11.9100 - kl_loss: 1.1955 - val_reconstruction_loss: 14.6542\n",
      "Epoch 89/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.7745 - reconstruction_loss: -11.9499 - kl_loss: 1.1867 - val_reconstruction_loss: 12.9701\n",
      "Epoch 90/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.8070 - reconstruction_loss: -12.0474 - kl_loss: 1.1764 - val_reconstruction_loss: 12.2353\n",
      "Epoch 91/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.0223 - reconstruction_loss: -12.2980 - kl_loss: 1.2043 - val_reconstruction_loss: 17.4059\n",
      "Epoch 92/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.1574 - reconstruction_loss: -12.4383 - kl_loss: 1.2013 - val_reconstruction_loss: 17.3115\n",
      "Epoch 93/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.4681 - reconstruction_loss: -12.7876 - kl_loss: 1.2218 - val_reconstruction_loss: 16.3906\n",
      "Epoch 94/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.8142 - reconstruction_loss: -13.1833 - kl_loss: 1.2262 - val_reconstruction_loss: 16.7551\n",
      "Epoch 95/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -12.2184 - reconstruction_loss: -13.5657 - kl_loss: 1.2300 - val_reconstruction_loss: 22.7587\n",
      "Epoch 96/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -12.4804 - reconstruction_loss: -13.7447 - kl_loss: 1.2307 - val_reconstruction_loss: 19.5536\n",
      "Epoch 97/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -12.6280 - reconstruction_loss: -13.8482 - kl_loss: 1.2289 - val_reconstruction_loss: 20.1566\n",
      "Epoch 98/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -12.6104 - reconstruction_loss: -13.8416 - kl_loss: 1.2118 - val_reconstruction_loss: 17.2466\n",
      "Epoch 99/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -12.8231 - reconstruction_loss: -14.0463 - kl_loss: 1.2363 - val_reconstruction_loss: 23.2230\n",
      "Epoch 100/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -12.8511 - reconstruction_loss: -14.0899 - kl_loss: 1.2398 - val_reconstruction_loss: 22.6100\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/100\n",
      "900/900 [==============================] - 9s 8ms/step - loss: 0.3029 - reconstruction_loss: -2.0312 - kl_loss: 0.0284 - val_reconstruction_loss: -3.6134\n",
      "Epoch 2/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -3.7266 - reconstruction_loss: -3.8426 - kl_loss: 0.0121 - val_reconstruction_loss: -4.0302\n",
      "Epoch 3/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.0456 - reconstruction_loss: -4.0817 - kl_loss: 0.0099 - val_reconstruction_loss: -4.1351\n",
      "Epoch 4/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.1247 - reconstruction_loss: -4.1405 - kl_loss: 0.0093 - val_reconstruction_loss: -4.0887\n",
      "Epoch 5/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.1454 - reconstruction_loss: -4.1583 - kl_loss: 0.0092 - val_reconstruction_loss: -4.1291\n",
      "Epoch 6/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.1719 - reconstruction_loss: -4.1993 - kl_loss: 0.0105 - val_reconstruction_loss: -4.2131\n",
      "Epoch 7/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.2353 - reconstruction_loss: -4.2607 - kl_loss: 0.0111 - val_reconstruction_loss: -4.2764\n",
      "Epoch 8/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.2952 - reconstruction_loss: -4.3282 - kl_loss: 0.0124 - val_reconstruction_loss: -4.2935\n",
      "Epoch 9/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.3390 - reconstruction_loss: -4.3781 - kl_loss: 0.0132 - val_reconstruction_loss: -4.4400\n",
      "Epoch 10/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.4286 - reconstruction_loss: -4.4571 - kl_loss: 0.0147 - val_reconstruction_loss: -4.4953\n",
      "Epoch 11/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.4728 - reconstruction_loss: -4.4961 - kl_loss: 0.0160 - val_reconstruction_loss: -4.5225\n",
      "Epoch 12/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.5305 - reconstruction_loss: -4.5546 - kl_loss: 0.0173 - val_reconstruction_loss: -4.5986\n",
      "Epoch 13/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.5428 - reconstruction_loss: -4.5563 - kl_loss: 0.0174 - val_reconstruction_loss: -4.6079\n",
      "Epoch 14/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.5960 - reconstruction_loss: -4.6297 - kl_loss: 0.0178 - val_reconstruction_loss: -4.5488\n",
      "Epoch 15/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.6305 - reconstruction_loss: -4.6555 - kl_loss: 0.0185 - val_reconstruction_loss: -4.6500\n",
      "Epoch 16/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.6663 - reconstruction_loss: -4.6946 - kl_loss: 0.0193 - val_reconstruction_loss: -4.6125\n",
      "Epoch 17/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.6878 - reconstruction_loss: -4.7095 - kl_loss: 0.0208 - val_reconstruction_loss: -4.6036\n",
      "Epoch 18/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.7206 - reconstruction_loss: -4.7675 - kl_loss: 0.0226 - val_reconstruction_loss: -4.6999\n",
      "Epoch 19/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.7605 - reconstruction_loss: -4.7968 - kl_loss: 0.0266 - val_reconstruction_loss: -4.8015\n",
      "Epoch 20/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.8012 - reconstruction_loss: -4.8399 - kl_loss: 0.0293 - val_reconstruction_loss: -4.8606\n",
      "Epoch 21/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.8663 - reconstruction_loss: -4.9110 - kl_loss: 0.0356 - val_reconstruction_loss: -4.8996\n",
      "Epoch 22/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.9106 - reconstruction_loss: -4.9788 - kl_loss: 0.0453 - val_reconstruction_loss: -4.9489\n",
      "Epoch 23/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.9818 - reconstruction_loss: -5.0603 - kl_loss: 0.0603 - val_reconstruction_loss: -4.9745\n",
      "Epoch 24/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.0995 - reconstruction_loss: -5.2167 - kl_loss: 0.0832 - val_reconstruction_loss: -4.6281\n",
      "Epoch 25/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.1959 - reconstruction_loss: -5.3995 - kl_loss: 0.1058 - val_reconstruction_loss: -5.4067\n",
      "Epoch 26/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.5980 - reconstruction_loss: -5.8497 - kl_loss: 0.1384 - val_reconstruction_loss: -5.8426\n",
      "Epoch 27/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -6.0160 - reconstruction_loss: -6.3390 - kl_loss: 0.2283 - val_reconstruction_loss: -6.0931\n",
      "Epoch 28/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -6.3262 - reconstruction_loss: -6.6560 - kl_loss: 0.2863 - val_reconstruction_loss: -6.2920\n",
      "Epoch 29/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -6.5491 - reconstruction_loss: -6.9191 - kl_loss: 0.3182 - val_reconstruction_loss: -6.4690\n",
      "Epoch 30/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -6.7945 - reconstruction_loss: -7.2090 - kl_loss: 0.3586 - val_reconstruction_loss: -6.6755\n",
      "Epoch 31/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.0460 - reconstruction_loss: -7.4872 - kl_loss: 0.3956 - val_reconstruction_loss: -6.8251\n",
      "Epoch 32/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.2276 - reconstruction_loss: -7.7119 - kl_loss: 0.4198 - val_reconstruction_loss: -7.0224\n",
      "Epoch 33/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.4023 - reconstruction_loss: -7.8774 - kl_loss: 0.4343 - val_reconstruction_loss: -7.1220\n",
      "Epoch 34/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.5672 - reconstruction_loss: -8.0266 - kl_loss: 0.4289 - val_reconstruction_loss: -7.3283\n",
      "Epoch 35/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.7185 - reconstruction_loss: -8.1669 - kl_loss: 0.4243 - val_reconstruction_loss: -7.4752\n",
      "Epoch 36/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.8549 - reconstruction_loss: -8.2821 - kl_loss: 0.4154 - val_reconstruction_loss: -7.5617\n",
      "Epoch 37/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.9512 - reconstruction_loss: -8.3802 - kl_loss: 0.4074 - val_reconstruction_loss: -7.7678\n",
      "Epoch 38/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.0430 - reconstruction_loss: -8.4550 - kl_loss: 0.3985 - val_reconstruction_loss: -7.7125\n",
      "Epoch 39/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.1150 - reconstruction_loss: -8.5469 - kl_loss: 0.3969 - val_reconstruction_loss: -7.9350\n",
      "Epoch 40/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.2213 - reconstruction_loss: -8.6413 - kl_loss: 0.3979 - val_reconstruction_loss: -7.9838\n",
      "Epoch 41/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.3313 - reconstruction_loss: -8.7203 - kl_loss: 0.3955 - val_reconstruction_loss: -8.0496\n",
      "Epoch 42/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.3825 - reconstruction_loss: -8.8111 - kl_loss: 0.3993 - val_reconstruction_loss: -8.1246\n",
      "Epoch 43/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.4245 - reconstruction_loss: -8.8576 - kl_loss: 0.4068 - val_reconstruction_loss: -8.2533\n",
      "Epoch 44/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.5652 - reconstruction_loss: -8.9852 - kl_loss: 0.4052 - val_reconstruction_loss: -8.1875\n",
      "Epoch 45/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -8.6197 - reconstruction_loss: -9.0666 - kl_loss: 0.4190 - val_reconstruction_loss: -8.2943\n",
      "Epoch 46/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.7315 - reconstruction_loss: -9.1418 - kl_loss: 0.4165 - val_reconstruction_loss: -8.4057\n",
      "Epoch 47/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.7835 - reconstruction_loss: -9.2067 - kl_loss: 0.4256 - val_reconstruction_loss: -7.9297\n",
      "Epoch 48/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.7465 - reconstruction_loss: -9.2189 - kl_loss: 0.4256 - val_reconstruction_loss: -8.5560\n",
      "Epoch 49/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.8205 - reconstruction_loss: -9.2619 - kl_loss: 0.4296 - val_reconstruction_loss: -8.4991\n",
      "Epoch 50/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.9025 - reconstruction_loss: -9.3531 - kl_loss: 0.4339 - val_reconstruction_loss: -8.5385\n",
      "Epoch 51/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.0232 - reconstruction_loss: -9.4669 - kl_loss: 0.4401 - val_reconstruction_loss: -8.5452\n",
      "Epoch 52/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.0504 - reconstruction_loss: -9.5089 - kl_loss: 0.4372 - val_reconstruction_loss: -8.7406\n",
      "Epoch 53/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.0737 - reconstruction_loss: -9.5121 - kl_loss: 0.4436 - val_reconstruction_loss: -8.7789\n",
      "Epoch 54/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.1025 - reconstruction_loss: -9.5916 - kl_loss: 0.4442 - val_reconstruction_loss: -8.7978\n",
      "Epoch 55/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.1118 - reconstruction_loss: -9.5723 - kl_loss: 0.4497 - val_reconstruction_loss: -8.8630\n",
      "Epoch 56/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.1976 - reconstruction_loss: -9.6003 - kl_loss: 0.4483 - val_reconstruction_loss: -8.8738\n",
      "Epoch 57/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.0553 - reconstruction_loss: -9.5645 - kl_loss: 0.4400 - val_reconstruction_loss: -8.9102\n",
      "Epoch 58/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -9.1799 - reconstruction_loss: -9.6767 - kl_loss: 0.4453 - val_reconstruction_loss: -8.7208\n",
      "Epoch 59/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.2552 - reconstruction_loss: -9.6975 - kl_loss: 0.4405 - val_reconstruction_loss: -8.9539\n",
      "Epoch 60/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.3455 - reconstruction_loss: -9.7771 - kl_loss: 0.4468 - val_reconstruction_loss: -9.0094\n",
      "Epoch 61/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.3341 - reconstruction_loss: -9.7154 - kl_loss: 0.4450 - val_reconstruction_loss: -9.0061\n",
      "Epoch 62/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.2988 - reconstruction_loss: -9.7544 - kl_loss: 0.4451 - val_reconstruction_loss: -8.6711\n",
      "Epoch 63/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.4009 - reconstruction_loss: -9.8360 - kl_loss: 0.4463 - val_reconstruction_loss: -9.0496\n",
      "Epoch 64/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.4112 - reconstruction_loss: -9.8620 - kl_loss: 0.4403 - val_reconstruction_loss: -9.0909\n",
      "Epoch 65/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.4457 - reconstruction_loss: -9.8817 - kl_loss: 0.4424 - val_reconstruction_loss: -9.0872\n",
      "Epoch 66/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.4505 - reconstruction_loss: -9.8941 - kl_loss: 0.4358 - val_reconstruction_loss: -9.1040\n",
      "Epoch 67/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.5090 - reconstruction_loss: -9.9440 - kl_loss: 0.4404 - val_reconstruction_loss: -8.6845\n",
      "Epoch 68/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.5028 - reconstruction_loss: -9.9201 - kl_loss: 0.4383 - val_reconstruction_loss: -9.1902\n",
      "Epoch 69/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.4818 - reconstruction_loss: -9.9495 - kl_loss: 0.4410 - val_reconstruction_loss: -9.1809\n",
      "Epoch 70/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.5308 - reconstruction_loss: -9.9351 - kl_loss: 0.4377 - val_reconstruction_loss: -9.2217\n",
      "Epoch 71/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.5916 - reconstruction_loss: -10.0361 - kl_loss: 0.4313 - val_reconstruction_loss: -9.1056\n",
      "Epoch 72/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.6062 - reconstruction_loss: -10.0148 - kl_loss: 0.4347 - val_reconstruction_loss: -9.1089\n",
      "Epoch 73/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.5528 - reconstruction_loss: -9.9079 - kl_loss: 0.4335 - val_reconstruction_loss: -9.2968\n",
      "Epoch 74/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.5722 - reconstruction_loss: -10.0326 - kl_loss: 0.4272 - val_reconstruction_loss: -9.3256\n",
      "Epoch 75/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.6356 - reconstruction_loss: -10.0682 - kl_loss: 0.4393 - val_reconstruction_loss: -9.3725\n",
      "Epoch 76/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.6524 - reconstruction_loss: -10.0778 - kl_loss: 0.4335 - val_reconstruction_loss: -9.1859\n",
      "Epoch 77/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.6458 - reconstruction_loss: -10.1140 - kl_loss: 0.4367 - val_reconstruction_loss: -9.3550\n",
      "Epoch 78/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.6746 - reconstruction_loss: -10.1200 - kl_loss: 0.4333 - val_reconstruction_loss: -9.3030\n",
      "Epoch 79/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.7375 - reconstruction_loss: -10.1682 - kl_loss: 0.4374 - val_reconstruction_loss: -9.3488\n",
      "Epoch 80/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.7568 - reconstruction_loss: -10.1428 - kl_loss: 0.4296 - val_reconstruction_loss: -9.3922\n",
      "Epoch 81/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.7073 - reconstruction_loss: -10.1745 - kl_loss: 0.4390 - val_reconstruction_loss: -9.4027\n",
      "Epoch 82/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.8123 - reconstruction_loss: -10.2576 - kl_loss: 0.4404 - val_reconstruction_loss: -9.3929\n",
      "Epoch 83/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.7725 - reconstruction_loss: -10.2123 - kl_loss: 0.4431 - val_reconstruction_loss: -9.4336\n",
      "Epoch 84/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.7940 - reconstruction_loss: -10.2218 - kl_loss: 0.4358 - val_reconstruction_loss: -9.2210\n",
      "Epoch 85/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.8032 - reconstruction_loss: -10.2526 - kl_loss: 0.4424 - val_reconstruction_loss: -9.3462\n",
      "Epoch 86/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.8291 - reconstruction_loss: -10.2982 - kl_loss: 0.4493 - val_reconstruction_loss: -9.4297\n",
      "Epoch 87/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.8730 - reconstruction_loss: -10.3198 - kl_loss: 0.4517 - val_reconstruction_loss: -9.4238\n",
      "Epoch 88/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.8714 - reconstruction_loss: -10.3365 - kl_loss: 0.4513 - val_reconstruction_loss: -9.4686\n",
      "Epoch 89/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.9140 - reconstruction_loss: -10.3534 - kl_loss: 0.4519 - val_reconstruction_loss: -8.5054\n",
      "Epoch 90/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.6741 - reconstruction_loss: -10.2568 - kl_loss: 0.4599 - val_reconstruction_loss: -9.4107\n",
      "Epoch 91/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.8891 - reconstruction_loss: -10.3129 - kl_loss: 0.4567 - val_reconstruction_loss: -9.4573\n",
      "Epoch 92/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.9304 - reconstruction_loss: -10.3309 - kl_loss: 0.4522 - val_reconstruction_loss: -9.4822\n",
      "Epoch 93/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -9.7978 - reconstruction_loss: -10.3324 - kl_loss: 0.4555 - val_reconstruction_loss: -9.4570\n",
      "Epoch 94/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.9339 - reconstruction_loss: -10.4272 - kl_loss: 0.4608 - val_reconstruction_loss: -9.5234\n",
      "Epoch 95/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.0215 - reconstruction_loss: -10.4694 - kl_loss: 0.4694 - val_reconstruction_loss: -9.5775\n",
      "Epoch 96/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.0255 - reconstruction_loss: -10.4447 - kl_loss: 0.4677 - val_reconstruction_loss: -9.5995\n",
      "Epoch 97/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.9277 - reconstruction_loss: -10.4723 - kl_loss: 0.4717 - val_reconstruction_loss: -9.5649\n",
      "Epoch 98/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.0249 - reconstruction_loss: -10.4713 - kl_loss: 0.4751 - val_reconstruction_loss: -9.3042\n",
      "Epoch 99/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.9300 - reconstruction_loss: -10.4060 - kl_loss: 0.4717 - val_reconstruction_loss: -9.2385\n",
      "Epoch 100/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.9880 - reconstruction_loss: -10.4925 - kl_loss: 0.4802 - val_reconstruction_loss: -9.5491\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/100\n",
      "900/900 [==============================] - 9s 8ms/step - loss: 0.6898 - reconstruction_loss: -1.7163 - kl_loss: 0.0214 - val_reconstruction_loss: -3.6759\n",
      "Epoch 2/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -3.7685 - reconstruction_loss: -3.8851 - kl_loss: 0.0104 - val_reconstruction_loss: -3.8559\n",
      "Epoch 3/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.0885 - reconstruction_loss: -4.1282 - kl_loss: 0.0088 - val_reconstruction_loss: -4.1546\n",
      "Epoch 4/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.1447 - reconstruction_loss: -4.1630 - kl_loss: 0.0091 - val_reconstruction_loss: -4.0378\n",
      "Epoch 5/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.1751 - reconstruction_loss: -4.2142 - kl_loss: 0.0092 - val_reconstruction_loss: -4.2654\n",
      "Epoch 6/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.2644 - reconstruction_loss: -4.2863 - kl_loss: 0.0101 - val_reconstruction_loss: -4.3160\n",
      "Epoch 7/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.3477 - reconstruction_loss: -4.3823 - kl_loss: 0.0125 - val_reconstruction_loss: -4.4725\n",
      "Epoch 8/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.4669 - reconstruction_loss: -4.4915 - kl_loss: 0.0142 - val_reconstruction_loss: -4.4987\n",
      "Epoch 9/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -4.5748 - reconstruction_loss: -4.6172 - kl_loss: 0.0144 - val_reconstruction_loss: -4.6753\n",
      "Epoch 10/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.6481 - reconstruction_loss: -4.6823 - kl_loss: 0.0152 - val_reconstruction_loss: -4.7223\n",
      "Epoch 11/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.6851 - reconstruction_loss: -4.7191 - kl_loss: 0.0158 - val_reconstruction_loss: -4.7658\n",
      "Epoch 12/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.7572 - reconstruction_loss: -4.7838 - kl_loss: 0.0161 - val_reconstruction_loss: -4.8232\n",
      "Epoch 13/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.8000 - reconstruction_loss: -4.8155 - kl_loss: 0.0176 - val_reconstruction_loss: -4.8579\n",
      "Epoch 14/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.8300 - reconstruction_loss: -4.8608 - kl_loss: 0.0194 - val_reconstruction_loss: -4.8969\n",
      "Epoch 15/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.8776 - reconstruction_loss: -4.9112 - kl_loss: 0.0225 - val_reconstruction_loss: -4.9076\n",
      "Epoch 16/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.9404 - reconstruction_loss: -4.9801 - kl_loss: 0.0263 - val_reconstruction_loss: -4.9768\n",
      "Epoch 17/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -4.9894 - reconstruction_loss: -5.0317 - kl_loss: 0.0316 - val_reconstruction_loss: -5.0106\n",
      "Epoch 18/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.0386 - reconstruction_loss: -5.0937 - kl_loss: 0.0373 - val_reconstruction_loss: -5.0914\n",
      "Epoch 19/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.1062 - reconstruction_loss: -5.1656 - kl_loss: 0.0465 - val_reconstruction_loss: -5.0321\n",
      "Epoch 20/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.1526 - reconstruction_loss: -5.2551 - kl_loss: 0.0587 - val_reconstruction_loss: -5.0363\n",
      "Epoch 21/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.3271 - reconstruction_loss: -5.4522 - kl_loss: 0.0768 - val_reconstruction_loss: -5.3960\n",
      "Epoch 22/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -5.6216 - reconstruction_loss: -5.8771 - kl_loss: 0.1187 - val_reconstruction_loss: -5.9727\n",
      "Epoch 23/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -6.1967 - reconstruction_loss: -6.4762 - kl_loss: 0.1851 - val_reconstruction_loss: -6.3198\n",
      "Epoch 24/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -6.5273 - reconstruction_loss: -6.8416 - kl_loss: 0.2245 - val_reconstruction_loss: -6.6245\n",
      "Epoch 25/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -6.8210 - reconstruction_loss: -7.1251 - kl_loss: 0.2565 - val_reconstruction_loss: -6.7515\n",
      "Epoch 26/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -6.9895 - reconstruction_loss: -7.2934 - kl_loss: 0.2731 - val_reconstruction_loss: -6.6854\n",
      "Epoch 27/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.0898 - reconstruction_loss: -7.4070 - kl_loss: 0.2783 - val_reconstruction_loss: -6.9842\n",
      "Epoch 28/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.2005 - reconstruction_loss: -7.4807 - kl_loss: 0.2726 - val_reconstruction_loss: -7.1605\n",
      "Epoch 29/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.2601 - reconstruction_loss: -7.5252 - kl_loss: 0.2642 - val_reconstruction_loss: -7.1335\n",
      "Epoch 30/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.2897 - reconstruction_loss: -7.5669 - kl_loss: 0.2582 - val_reconstruction_loss: -7.2797\n",
      "Epoch 31/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.3583 - reconstruction_loss: -7.6141 - kl_loss: 0.2486 - val_reconstruction_loss: -7.3184\n",
      "Epoch 32/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.3942 - reconstruction_loss: -7.6339 - kl_loss: 0.2437 - val_reconstruction_loss: -7.3482\n",
      "Epoch 33/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.4158 - reconstruction_loss: -7.6432 - kl_loss: 0.2345 - val_reconstruction_loss: -7.4156\n",
      "Epoch 34/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.4437 - reconstruction_loss: -7.6967 - kl_loss: 0.2257 - val_reconstruction_loss: -7.4421\n",
      "Epoch 35/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.4958 - reconstruction_loss: -7.7021 - kl_loss: 0.2228 - val_reconstruction_loss: -7.2789\n",
      "Epoch 36/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.5137 - reconstruction_loss: -7.7644 - kl_loss: 0.2156 - val_reconstruction_loss: -7.4355\n",
      "Epoch 37/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.5744 - reconstruction_loss: -7.7956 - kl_loss: 0.2092 - val_reconstruction_loss: -7.4645\n",
      "Epoch 38/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.5982 - reconstruction_loss: -7.8021 - kl_loss: 0.2038 - val_reconstruction_loss: -7.5008\n",
      "Epoch 39/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.6350 - reconstruction_loss: -7.8407 - kl_loss: 0.2013 - val_reconstruction_loss: -7.5350\n",
      "Epoch 40/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.6648 - reconstruction_loss: -7.8674 - kl_loss: 0.1975 - val_reconstruction_loss: -7.6183\n",
      "Epoch 41/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.7007 - reconstruction_loss: -7.8821 - kl_loss: 0.1932 - val_reconstruction_loss: -7.6228\n",
      "Epoch 42/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.7178 - reconstruction_loss: -7.9330 - kl_loss: 0.1907 - val_reconstruction_loss: -7.6970\n",
      "Epoch 43/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.7584 - reconstruction_loss: -7.9474 - kl_loss: 0.1883 - val_reconstruction_loss: -7.5643\n",
      "Epoch 44/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.7989 - reconstruction_loss: -7.9916 - kl_loss: 0.1855 - val_reconstruction_loss: -7.7703\n",
      "Epoch 45/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.8124 - reconstruction_loss: -8.0143 - kl_loss: 0.1841 - val_reconstruction_loss: -7.7475\n",
      "Epoch 46/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.8498 - reconstruction_loss: -8.0308 - kl_loss: 0.1832 - val_reconstruction_loss: -7.8184\n",
      "Epoch 47/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.8707 - reconstruction_loss: -8.0495 - kl_loss: 0.1826 - val_reconstruction_loss: -7.8226\n",
      "Epoch 48/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.8606 - reconstruction_loss: -8.0729 - kl_loss: 0.1815 - val_reconstruction_loss: -7.8705\n",
      "Epoch 49/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.9556 - reconstruction_loss: -8.1329 - kl_loss: 0.1814 - val_reconstruction_loss: -7.9211\n",
      "Epoch 50/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -7.9750 - reconstruction_loss: -8.1560 - kl_loss: 0.1765 - val_reconstruction_loss: -7.9535\n",
      "Epoch 51/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.0210 - reconstruction_loss: -8.2058 - kl_loss: 0.1761 - val_reconstruction_loss: -7.8242\n",
      "Epoch 52/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.0349 - reconstruction_loss: -8.2281 - kl_loss: 0.1780 - val_reconstruction_loss: -8.0051\n",
      "Epoch 53/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.0927 - reconstruction_loss: -8.2767 - kl_loss: 0.1766 - val_reconstruction_loss: -8.0270\n",
      "Epoch 54/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.1154 - reconstruction_loss: -8.3091 - kl_loss: 0.1742 - val_reconstruction_loss: -8.0030\n",
      "Epoch 55/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.1743 - reconstruction_loss: -8.3662 - kl_loss: 0.1776 - val_reconstruction_loss: -8.0660\n",
      "Epoch 56/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.2082 - reconstruction_loss: -8.3976 - kl_loss: 0.1750 - val_reconstruction_loss: -8.2040\n",
      "Epoch 57/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.2587 - reconstruction_loss: -8.4708 - kl_loss: 0.1762 - val_reconstruction_loss: -8.2519\n",
      "Epoch 58/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.3550 - reconstruction_loss: -8.5398 - kl_loss: 0.1770 - val_reconstruction_loss: -8.2495\n",
      "Epoch 59/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -8.4062 - reconstruction_loss: -8.6010 - kl_loss: 0.1812 - val_reconstruction_loss: -8.1910\n",
      "Epoch 60/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.4275 - reconstruction_loss: -8.6472 - kl_loss: 0.1853 - val_reconstruction_loss: -8.4743\n",
      "Epoch 61/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.5561 - reconstruction_loss: -8.7717 - kl_loss: 0.1911 - val_reconstruction_loss: -8.5076\n",
      "Epoch 62/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.6792 - reconstruction_loss: -8.8926 - kl_loss: 0.1971 - val_reconstruction_loss: -8.6321\n",
      "Epoch 63/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.7719 - reconstruction_loss: -9.0184 - kl_loss: 0.2107 - val_reconstruction_loss: -8.7800\n",
      "Epoch 64/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -8.9147 - reconstruction_loss: -9.1895 - kl_loss: 0.2297 - val_reconstruction_loss: -8.9576\n",
      "Epoch 65/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -9.1066 - reconstruction_loss: -9.3940 - kl_loss: 0.2453 - val_reconstruction_loss: -9.0931\n",
      "Epoch 66/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.2993 - reconstruction_loss: -9.6271 - kl_loss: 0.2647 - val_reconstruction_loss: -9.3549\n",
      "Epoch 67/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.5192 - reconstruction_loss: -9.8519 - kl_loss: 0.2884 - val_reconstruction_loss: -9.5292\n",
      "Epoch 68/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.6899 - reconstruction_loss: -10.0230 - kl_loss: 0.3071 - val_reconstruction_loss: -9.6971\n",
      "Epoch 69/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.8243 - reconstruction_loss: -10.1482 - kl_loss: 0.3204 - val_reconstruction_loss: -9.7517\n",
      "Epoch 70/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -9.9178 - reconstruction_loss: -10.2669 - kl_loss: 0.3255 - val_reconstruction_loss: -9.7885\n",
      "Epoch 71/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.0007 - reconstruction_loss: -10.3597 - kl_loss: 0.3384 - val_reconstruction_loss: -9.8529\n",
      "Epoch 72/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.0948 - reconstruction_loss: -10.4528 - kl_loss: 0.3451 - val_reconstruction_loss: -9.9442\n",
      "Epoch 73/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.1355 - reconstruction_loss: -10.5143 - kl_loss: 0.3568 - val_reconstruction_loss: -10.0619\n",
      "Epoch 74/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -10.2024 - reconstruction_loss: -10.5813 - kl_loss: 0.3587 - val_reconstruction_loss: -9.9439\n",
      "Epoch 75/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.2848 - reconstruction_loss: -10.6528 - kl_loss: 0.3646 - val_reconstruction_loss: -9.8136\n",
      "Epoch 76/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -10.2925 - reconstruction_loss: -10.6897 - kl_loss: 0.3704 - val_reconstruction_loss: -10.0091\n",
      "Epoch 77/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.3858 - reconstruction_loss: -10.7755 - kl_loss: 0.3752 - val_reconstruction_loss: -10.2193\n",
      "Epoch 78/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.4452 - reconstruction_loss: -10.8171 - kl_loss: 0.3781 - val_reconstruction_loss: -10.3128\n",
      "Epoch 79/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -10.4911 - reconstruction_loss: -10.8670 - kl_loss: 0.3796 - val_reconstruction_loss: -10.2283\n",
      "Epoch 80/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -10.5439 - reconstruction_loss: -10.9361 - kl_loss: 0.3833 - val_reconstruction_loss: -10.4044\n",
      "Epoch 81/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.5947 - reconstruction_loss: -10.9780 - kl_loss: 0.3847 - val_reconstruction_loss: -10.4500\n",
      "Epoch 82/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.6459 - reconstruction_loss: -11.0403 - kl_loss: 0.3884 - val_reconstruction_loss: -10.4958\n",
      "Epoch 83/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -10.6885 - reconstruction_loss: -11.0800 - kl_loss: 0.3897 - val_reconstruction_loss: -10.5111\n",
      "Epoch 84/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.7214 - reconstruction_loss: -11.1353 - kl_loss: 0.3968 - val_reconstruction_loss: -10.4355\n",
      "Epoch 85/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.7555 - reconstruction_loss: -11.1757 - kl_loss: 0.3901 - val_reconstruction_loss: -10.5348\n",
      "Epoch 86/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.8289 - reconstruction_loss: -11.2306 - kl_loss: 0.3933 - val_reconstruction_loss: -10.6764\n",
      "Epoch 87/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.8801 - reconstruction_loss: -11.2773 - kl_loss: 0.3929 - val_reconstruction_loss: -10.6821\n",
      "Epoch 88/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.9282 - reconstruction_loss: -11.3298 - kl_loss: 0.3991 - val_reconstruction_loss: -10.6757\n",
      "Epoch 89/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -10.9696 - reconstruction_loss: -11.3725 - kl_loss: 0.3957 - val_reconstruction_loss: -10.7443\n",
      "Epoch 90/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.0089 - reconstruction_loss: -11.3954 - kl_loss: 0.3976 - val_reconstruction_loss: -10.6684\n",
      "Epoch 91/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.0312 - reconstruction_loss: -11.4470 - kl_loss: 0.4104 - val_reconstruction_loss: -10.7711\n",
      "Epoch 92/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.0915 - reconstruction_loss: -11.5141 - kl_loss: 0.4070 - val_reconstruction_loss: -10.5789\n",
      "Epoch 93/100\n",
      "900/900 [==============================] - 7s 7ms/step - loss: -11.1207 - reconstruction_loss: -11.5385 - kl_loss: 0.4179 - val_reconstruction_loss: -10.8975\n",
      "Epoch 94/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.1542 - reconstruction_loss: -11.5967 - kl_loss: 0.4146 - val_reconstruction_loss: -10.7995\n",
      "Epoch 95/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.2337 - reconstruction_loss: -11.6546 - kl_loss: 0.4217 - val_reconstruction_loss: -10.8190\n",
      "Epoch 96/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.2337 - reconstruction_loss: -11.7067 - kl_loss: 0.4356 - val_reconstruction_loss: -10.8449\n",
      "Epoch 97/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.2853 - reconstruction_loss: -11.7369 - kl_loss: 0.4413 - val_reconstruction_loss: -10.9724\n",
      "Epoch 98/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.3764 - reconstruction_loss: -11.7919 - kl_loss: 0.4375 - val_reconstruction_loss: -10.8506\n",
      "Epoch 99/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.3887 - reconstruction_loss: -11.8134 - kl_loss: 0.4470 - val_reconstruction_loss: -11.0515\n",
      "Epoch 100/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: -11.4126 - reconstruction_loss: -11.8852 - kl_loss: 0.4533 - val_reconstruction_loss: -10.9438\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "search_target = 'gaussian_number'\n",
    "if not os.path.isdir('./tb_log/cvae/{}/{}'.format(learn_target, search_target)): os.mkdir('./tb_log/cvae/{}/{}'.format(learn_target, search_target))\n",
    "search_value = [10, 15, 20]\n",
    "\n",
    "for num in search_value:\n",
    "    cvae = create_cvae_model(gaussian_number, latent_dim, latent_dim_2, x_parameter_node, x_spectrum_node, x_latent_node, kl_scaling)\n",
    "    cvae.compile(optimizer=keras.optimizers.Adam(learning_rate=lr))\n",
    "    dir = './tb_log/cvae/{}/{}/{}'.format(learn_target, search_target, num)\n",
    "    os.mkdir(dir)\n",
    "    with open(dir + \"/model_info.txt\".format(search_target, num), 'w') as f:\n",
    "        f.writelines('gaussian_number = {}\\n'.format(gaussian_number))\n",
    "        f.writelines('latent_dim = {}\\n'.format(latent_dim))\n",
    "        f.writelines('latent_dim_2 = {}\\n'.format(latent_dim_2))\n",
    "        f.writelines('x_parameter_node = {}\\n'.format(x_parameter_node))\n",
    "        f.writelines('x_spectrum_node = {}\\n'.format(x_spectrum_node))\n",
    "        f.writelines('x_latent_node = {}\\n'.format(x_latent_node))\n",
    "        f.writelines('kl_scaling = {}\\n'.format(kl_scaling))\n",
    "        f.writelines('lr = {}\\n'.format(lr))\n",
    "    \n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir = dir, histogram_freq = 1)\n",
    "    cvae.fit(x = [y_train, x_train/1000],\n",
    "                y = [y_train],\n",
    "                batch_size=1000,\n",
    "                epochs=100,\n",
    "                validation_data=([[y_val, x_val/1000], y_val]),\n",
    "                verbose=1,\n",
    "                shuffle=True,\n",
    "                callbacks=[tensorboard_callback]\n",
    "    )\n",
    "\n",
    "    path = \"./cvae/{}/{}/{}/\".format(learn_target, search_target, num)\n",
    "    cvae.encoder1.save(path + \"encoder_1.h5\")\n",
    "    cvae.encoder2.save(path + \"encoder_2.h5\")\n",
    "    cvae.decoder.save(path + \"decoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ff1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
