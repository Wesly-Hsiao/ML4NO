{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only use the first GPU\n",
    "try:\n",
    "    tf.config.experimental.set_visible_devices(gpus, 'GPU')\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus,\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     logging.info(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "except RuntimeError as e:\n",
    "# Visible devices must be set before GPUs have been initialized\n",
    "    logging.info(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.load(\"./nsi_data/sample_nsi_regression_1e7_v1.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ve_dune',\n",
       " 'vebar_dune',\n",
       " 'vu_dune',\n",
       " 'vubar_dune',\n",
       " 've_t2hk',\n",
       " 'vu_t2hk',\n",
       " 'vebar_t2hk',\n",
       " 'vubar_t2hk',\n",
       " 'theta12',\n",
       " 'theta13',\n",
       " 'theta23',\n",
       " 'delta',\n",
       " 'sdm',\n",
       " 'ldm',\n",
       " 'mumu',\n",
       " 'emu',\n",
       " 'etau']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_selection = 1 # 0 for all, 1 for lowE(<5GeV), 2 for high(>5GeV)\n",
    "\n",
    "if data_selection == 0:\n",
    "    data_all = np.column_stack([data['ve_dune'], data['vu_dune'], data['vebar_dune'], data['vubar_dune']])\n",
    "elif data_selection == 1:\n",
    "    data_all = np.column_stack([data['ve_dune'][:,:36], data['vu_dune'][:,:36], data['vebar_dune'][:,:36], data['vubar_dune'][:,:36]])\n",
    "elif data_selection == 2:\n",
    "    data_all = np.column_stack([data['ve_dune'][:,36:], data['vu_dune'][:,36:], data['vebar_dune'][:,36:], data['vubar_dune'][:,36:]])\n",
    "\n",
    "target = np.column_stack([data['theta12'],data['theta13'],data['theta23'],data['delta'],data['delta'],data['sdm'],data['ldm'],data['mumu'],data['emu'],data['etau']])\n",
    "\n",
    "x_train = data_all[:10000]\n",
    "y_train = target[:10000]\n",
    "\n",
    "x_train2 = data_all[10000:9000000]\n",
    "y_train2 = target[10000:9000000]\n",
    "\n",
    "x_test = data_all[9000000:]\n",
    "y_test = target[9000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 Complete [00h 00m 38s]\n",
      "val_loss: 821.2763061523438\n",
      "\n",
      "Best val_loss So Far: 548.804443359375\n",
      "Total elapsed time: 00h 22m 36s\n",
      "\n",
      "Search: Running Trial #39\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "structured_data...|False             |True              \n",
      "structured_data...|True              |True              \n",
      "structured_data...|3                 |3                 \n",
      "structured_data...|128               |128               \n",
      "structured_data...|0                 |0                 \n",
      "structured_data...|128               |128               \n",
      "regression_head...|0.25              |0.25              \n",
      "optimizer         |adam              |adam              \n",
      "learning_rate     |0.001             |0.001             \n",
      "structured_data...|512               |512               \n",
      "\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 3s 15ms/step - loss: 7974.4499 - mean_squared_error: 7974.4499 - val_loss: 2715.2910 - val_mean_squared_error: 2715.2910\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 4254.9762 - mean_squared_error: 4254.9762 - val_loss: 2796.5383 - val_mean_squared_error: 2796.5383\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 1662.1266 - mean_squared_error: 1662.1266 - val_loss: 1891.0503 - val_mean_squared_error: 1891.0503\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 1030.2198 - mean_squared_error: 1030.2198 - val_loss: 1587.7640 - val_mean_squared_error: 1587.7640\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 911.0539 - mean_squared_error: 911.0539 - val_loss: 1212.3207 - val_mean_squared_error: 1212.3207\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 866.3811 - mean_squared_error: 866.3811 - val_loss: 1176.4095 - val_mean_squared_error: 1176.4095\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 809.2199 - mean_squared_error: 809.2199 - val_loss: 1686.6926 - val_mean_squared_error: 1686.6926\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 782.1101 - mean_squared_error: 782.1101 - val_loss: 1237.2913 - val_mean_squared_error: 1237.2913\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 739.7610 - mean_squared_error: 739.7610 - val_loss: 1186.8699 - val_mean_squared_error: 1186.8699\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 707.5278 - mean_squared_error: 707.5278 - val_loss: 1140.8208 - val_mean_squared_error: 1140.8208\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 688.1225 - mean_squared_error: 688.1225 - val_loss: 1189.0450 - val_mean_squared_error: 1189.0450\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 662.7341 - mean_squared_error: 662.7341 - val_loss: 1239.5178 - val_mean_squared_error: 1239.5178\n",
      "Epoch 13/20\n",
      "122/142 [========================>.....] - ETA: 0s - loss: 648.9256 - mean_squared_error: 648.9256"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = ak.StructuredDataRegressor(overwrite=True, max_trials=50)\n",
    "clf.fit(x_train, y_train,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=20,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 144)]             0         \n",
      "_________________________________________________________________\n",
      "multi_category_encoding (Mul (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 144)               289       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               18560     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "regression_head_1 (Dense)    (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 109,611\n",
      "Trainable params: 107,786\n",
      "Non-trainable params: 1,825\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 15261/126422 [==>...........................] - ETA: 19:36 - loss: 490.6187 - mean_squared_error: 490.6187"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70905/126422 [===============>..............] - ETA: 9:48 - loss: 385.8705 - mean_squared_error: 385.8705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126422/126422 [==============================] - 1448s 11ms/step - loss: 348.5049 - mean_squared_error: 348.5049 - val_loss: 209.2881 - val_mean_squared_error: 209.2881\n",
      "Epoch 2/20\n",
      "   321/126422 [..............................] - ETA: 22:12 - loss: 292.3326 - mean_squared_error: 292.3326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55982/126422 [============>.................] - ETA: 12:23 - loss: 277.0593 - mean_squared_error: 277.0593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112160/126422 [=========================>....] - ETA: 2:29 - loss: 269.2462 - mean_squared_error: 269.2462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40100/126422 [========>.....................] - ETA: 15:02 - loss: 249.8857 - mean_squared_error: 249.8857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94426/126422 [=====================>........] - ETA: 5:34 - loss: 246.3710 - mean_squared_error: 246.3710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23695/126422 [====>.........................] - ETA: 17:47 - loss: 235.0649 - mean_squared_error: 235.0649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77971/126422 [=================>............] - ETA: 8:24 - loss: 231.6170 - mean_squared_error: 231.6170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126422/126422 [==============================] - 1432s 11ms/step - loss: 229.6811 - mean_squared_error: 229.6811 - val_loss: 140.9905 - val_mean_squared_error: 140.9905\n",
      "Epoch 5/20\n",
      "  6583/126422 [>.............................] - ETA: 20:51 - loss: 227.0544 - mean_squared_error: 227.0544"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61644/126422 [=============>................] - ETA: 11:20 - loss: 222.1697 - mean_squared_error: 222.1697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115898/126422 [==========================>...] - ETA: 1:50 - loss: 220.4018 - mean_squared_error: 220.4018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44611/126422 [=========>....................] - ETA: 14:17 - loss: 215.2961 - mean_squared_error: 215.2961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98858/126422 [======================>.......] - ETA: 4:48 - loss: 213.5948 - mean_squared_error: 213.5948"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26742/126422 [=====>........................] - ETA: 17:21 - loss: 210.2709 - mean_squared_error: 210.2709"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82286/126422 [==================>...........] - ETA: 7:39 - loss: 209.0311 - mean_squared_error: 209.0311"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126422/126422 [==============================] - 1432s 11ms/step - loss: 208.2127 - mean_squared_error: 208.2127 - val_loss: 121.2042 - val_mean_squared_error: 121.2042\n",
      "Epoch 8/20\n",
      "  9863/126422 [=>............................] - ETA: 20:16 - loss: 206.2909 - mean_squared_error: 206.2909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65228/126422 [==============>...............] - ETA: 10:37 - loss: 204.8826 - mean_squared_error: 204.8826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119499/126422 [===========================>..] - ETA: 1:12 - loss: 204.0926 - mean_squared_error: 204.0926"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47143/126422 [==========>...................] - ETA: 13:49 - loss: 201.1118 - mean_squared_error: 201.1118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102256/126422 [=======================>......] - ETA: 4:12 - loss: 200.1254 - mean_squared_error: 200.1254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37852/126422 [=======>......................] - ETA: 15:29 - loss: 196.9774 - mean_squared_error: 196.9774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92511/126422 [====================>.........] - ETA: 5:54 - loss: 197.0025 - mean_squared_error: 197.0025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21457/126422 [====>.........................] - ETA: 18:24 - loss: 194.9017 - mean_squared_error: 194.9017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75989/126422 [=================>............] - ETA: 8:47 - loss: 195.1754 - mean_squared_error: 195.1754"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126422/126422 [==============================] - 1434s 11ms/step - loss: 194.2837 - mean_squared_error: 194.2837 - val_loss: 109.7397 - val_mean_squared_error: 109.7397\n",
      "Epoch 12/20\n",
      "  4074/126422 [..............................] - ETA: 21:25 - loss: 187.2640 - mean_squared_error: 187.2640"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59474/126422 [=============>................] - ETA: 11:41 - loss: 191.8913 - mean_squared_error: 191.8913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114245/126422 [==========================>...] - ETA: 2:07 - loss: 191.7577 - mean_squared_error: 191.7577"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42967/126422 [=========>....................] - ETA: 14:36 - loss: 190.6294 - mean_squared_error: 190.6294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126422/126422 [==============================] - 1406s 11ms/step - loss: 178.5114 - mean_squared_error: 178.5114 - val_loss: 109.2419 - val_mean_squared_error: 109.2419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f69800da198>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train2, y_train2,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=64,\n",
    "           epochs=20,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "while os.path.isfile('./models/0910_allparams_{}.h5'.format(index)):\n",
    "    index += 1\n",
    "model.save('./models/0910_allparams_{}.h5'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31250/31250 [==============================] - 192s 6ms/step - loss: 108.2265 - mean_squared_error: 108.2265\n",
      "Epoch 1/5\n",
      "126422/126422 [==============================] - 1437s 11ms/step - loss: 177.0900 - mean_squared_error: 177.0900 - val_loss: 100.0299 - val_mean_squared_error: 100.0299\n",
      "Epoch 2/5\n",
      "126422/126422 [==============================] - 1403s 11ms/step - loss: 176.0323 - mean_squared_error: 176.0323 - val_loss: 100.7920 - val_mean_squared_error: 100.7920\n",
      "Epoch 3/5\n",
      "126422/126422 [==============================] - 1432s 11ms/step - loss: 174.7666 - mean_squared_error: 174.7666 - val_loss: 111.5225 - val_mean_squared_error: 111.5225\n",
      "Epoch 4/5\n",
      " 57010/126422 [============>.................] - ETA: 12:07 - loss: 174.8160 - mean_squared_error: 174.8160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113533/126422 [=========================>....] - ETA: 2:14 - loss: 174.2241 - mean_squared_error: 174.2241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126422/126422 [==============================] - 1403s 11ms/step - loss: 172.6409 - mean_squared_error: 172.6409 - val_loss: 101.0904 - val_mean_squared_error: 101.0904\n",
      "31250/31250 [==============================] - 177s 6ms/step - loss: 100.1524 - mean_squared_error: 100.1524\n",
      "31250/31250 [==============================] - 171s 5ms/step - loss: 100.1464 - mean_squared_error: 100.1464\n",
      "Epoch 1/5\n",
      " 57458/126422 [============>.................] - ETA: 10:54 - loss: 169.8601 - mean_squared_error: 169.8601"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121160/126422 [===========================>..] - ETA: 49s - loss: 169.8002 - mean_squared_error: 169.8002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126422/126422 [==============================] - 1278s 10ms/step - loss: 167.6484 - mean_squared_error: 167.6484 - val_loss: 92.9263 - val_mean_squared_error: 92.9263\n",
      "Epoch 2/5\n",
      "126422/126422 [==============================] - 1288s 10ms/step - loss: 166.9387 - mean_squared_error: 166.9387 - val_loss: 88.6473 - val_mean_squared_error: 88.6473\n",
      "Epoch 3/5\n",
      "126422/126422 [==============================] - 1297s 10ms/step - loss: 166.4952 - mean_squared_error: 166.4952 - val_loss: 92.4097 - val_mean_squared_error: 92.4097\n",
      "Epoch 4/5\n",
      " 61042/126422 [=============>................] - ETA: 10:23 - loss: 166.4170 - mean_squared_error: 166.4170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126422/126422 [==============================] - 1307s 10ms/step - loss: 166.4232 - mean_squared_error: 166.4232 - val_loss: 95.2701 - val_mean_squared_error: 95.2701\n",
      "Epoch 5/5\n",
      "122143/126422 [===========================>..] - ETA: 40s - loss: 163.3841 - mean_squared_error: 163.3841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126422/126422 [==============================] - 1285s 10ms/step - loss: 163.3866 - mean_squared_error: 163.3866 - val_loss: 91.1494 - val_mean_squared_error: 91.1494\n",
      "Epoch 4/5\n",
      "126422/126422 [==============================] - 1294s 10ms/step - loss: 162.4245 - mean_squared_error: 162.4245 - val_loss: 90.0371 - val_mean_squared_error: 90.0371\n",
      "Epoch 5/5\n",
      "126422/126422 [==============================] - 1296s 10ms/step - loss: 161.8096 - mean_squared_error: 161.8096 - val_loss: 85.5402 - val_mean_squared_error: 85.5402\n",
      "12765/31250 [===========>..................] - ETA: 1:45 - loss: 84.8408 - mean_squared_error: 84.8408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126422/126422 [==============================] - 1205s 10ms/step - loss: 159.0624 - mean_squared_error: 159.0624 - val_loss: 89.1545 - val_mean_squared_error: 89.1545\n",
      "Epoch 3/5\n",
      " 73458/126422 [================>.............] - ETA: 7:46 - loss: 158.4892 - mean_squared_error: 158.4892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126422/126422 [==============================] - 1207s 10ms/step - loss: 158.2774 - mean_squared_error: 158.2774 - val_loss: 88.2888 - val_mean_squared_error: 88.2888\n",
      "Epoch 5/5\n",
      "126422/126422 [==============================] - 1210s 10ms/step - loss: 157.2373 - mean_squared_error: 157.2373 - val_loss: 92.6753 - val_mean_squared_error: 92.6753\n",
      "31250/31250 [==============================] - 164s 5ms/step - loss: 90.7185 - mean_squared_error: 90.7185\n",
      "31250/31250 [==============================] - 164s 5ms/step - loss: 91.1315 - mean_squared_error: 91.1315\n",
      "Epoch 1/5\n",
      "126422/126422 [==============================] - 1214s 10ms/step - loss: 156.7151 - mean_squared_error: 156.7151 - val_loss: 88.4791 - val_mean_squared_error: 88.4791\n",
      "Epoch 2/5\n",
      " 85965/126422 [===================>..........] - ETA: 5:58 - loss: 157.7446 - mean_squared_error: 157.7446"
     ]
    }
   ],
   "source": [
    "scale_steps = np.logspace(-3, 0, 30)\n",
    "before_train_loss = []\n",
    "after_train_loss = []\n",
    "\n",
    "for scale in scale_steps:\n",
    "    x_train2_gen = np.random.normal(x_train2, np.sqrt(x_train2)*scale)\n",
    "    x_test_gen = np.random.normal(x_test, np.sqrt(x_test)*scale)\n",
    "\n",
    "    before_train_loss.append(model.evaluate(x_test_gen, y_test)[0])\n",
    "\n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "               validation_split = 0.1,\n",
    "               batch_size=64,\n",
    "               epochs=5,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "\n",
    "    after_train_loss.append(model.evaluate(x_test_gen, y_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index = index\n",
    "index = 1\n",
    "path = './models_furthurTrain/0910_allparams_{}_{}.h5'\n",
    "while os.path.isfile(path.format(model_index, index)):\n",
    "    index += 1\n",
    "model.save(path.format(model_index, index))\n",
    "outfile = {'scale_steps': scale_steps,\n",
    "           'before_train_loss': before_train_loss,\n",
    "           'after_train_loss' :after_train_loss}\n",
    "np.save(file = './models_furthurTrain/0910_allparams_{}_{}_result.npy'.format(model_index, index),\n",
    "        arr = outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test2_gen = np.random.poisson(x_test)\n",
    "\n",
    "for i in range(10):\n",
    "    x_train2_gen = np.random.poisson(x_train2)\n",
    "    \n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "              validation_split=0.1,\n",
    "               batch_size=64,\n",
    "               epochs=1,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "model.evaluate(x_test2_gen, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furthur_index = index\n",
    "index = 1\n",
    "path = './models_PoissonTrain/0910_allparams_{}_{}_{}.h5'\n",
    "while os.path.isfile(path.format(model_index, furthur_index, index)):\n",
    "    index += 1\n",
    "model.save(path.format(model_index, furthur_index, index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
