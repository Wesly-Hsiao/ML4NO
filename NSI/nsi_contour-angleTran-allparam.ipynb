{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a627fc59-e50a-4241-835e-3730691d87df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:17:33.015007: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-02 15:17:33.540709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20000 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_probability as tfp\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "import importlib\n",
    "import logging\n",
    "from tensorflow import keras\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "importlib.reload(logging)\n",
    "\n",
    "# limit GPU memory\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=20000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "except RuntimeError as e:\n",
    "# Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032df987-c8d6-4b96-916d-417b41eb1d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_number = 1\n",
    "training_data = np.load(\"./nsi_data/sample_nsi_regression_1e7_v{}.npz\".format(dataset_number))\n",
    "data_all = np.column_stack([training_data['ve_dune'][:,:36], training_data['vu_dune'][:,:36], training_data['vebar_dune'][:,:36], training_data['vubar_dune'][:,:36]])\n",
    "\n",
    "# theta13, theta23, delta, mumu, emu, etau\n",
    "target = np.column_stack([training_data[\"theta13\"]/180, training_data[\"theta23\"]/180,\n",
    "                          np.sin(training_data[\"delta\"]/180*np.pi), np.cos(training_data[\"delta\"]/180*np.pi),\n",
    "                         training_data[\"mumu\"], training_data[\"emu\"],\n",
    "                         training_data[\"etau\"]])\n",
    "\n",
    "x_train = data_all[:90]\n",
    "y_train = target[:90]\n",
    "\n",
    "x_train_poisson = np.random.poisson(x_train)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de93372",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_number = 10\n",
    "latent_dim = 4\n",
    "latent_dim_2 = 7\n",
    "x_parameter_node = [2048, 2048, 2048]\n",
    "x_spectrum_node = [2048, 2048, 2048]\n",
    "x_latent_node = [2048, 2048, 2048]\n",
    "kl_scaling = 10000.0\n",
    "lr = 2e-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3227fe3e-de14-442a-be80-3b187d22a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './CVAE/model_{}'.format(model_index)\n",
    "encoder1 = load_model(path + \"/encoder_1.h5\", compile=False)\n",
    "encoder2 = load_model(path + \"/encoder_2.h5\", compile=False)\n",
    "decoder = load_model(path + \"/decoder.h5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cafe950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(keras.Model):\n",
    "    def __init__(self, encoder1, encoder2, decoder, **kwargs):\n",
    "        super(CVAE, self).__init__(**kwargs)\n",
    "        self.encoder1 = encoder1\n",
    "        self.encoder2 = encoder2\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    \n",
    "    def evaluate(self, data):\n",
    "        x, y = data\n",
    "        SMALL_CONSTANT = 1e-12\n",
    "        \n",
    "        z1_mean, z1_log_var = self.encoder1(x)\n",
    "        \n",
    "        temp_var_q = SMALL_CONSTANT + tf.exp(z1_log_var)\n",
    "        mvn_q = tfp.distributions.MultivariateNormalDiag(\n",
    "                        loc=z1_mean,\n",
    "                        scale_diag=tf.sqrt(temp_var_q))\n",
    "        \n",
    "        z1 = mvn_q.sample()\n",
    "        \n",
    "        z2_mean, z2_log_var, z2_weight = self.encoder2(x[1])\n",
    "\n",
    "        z2_mean = tf.reshape(z2_mean, (-1, gaussian_number, latent_dim))\n",
    "        z2_log_var = tf.reshape(z2_log_var, (-1, gaussian_number, latent_dim))\n",
    "        z2_weight = tf.reshape(z2_weight, (-1, gaussian_number))\n",
    "        \n",
    "        temp_var_r1 = SMALL_CONSTANT + tf.exp(z2_log_var)\n",
    "        bimix_gauss = tfp.distributions.MixtureSameFamily(\n",
    "                        mixture_distribution=tfp.distributions.Categorical(logits=z2_weight),\n",
    "                        components_distribution=tfp.distributions.MultivariateNormalDiag(\n",
    "                        loc=z2_mean,\n",
    "                        scale_diag=tf.sqrt(temp_var_r1)))\n",
    "        \n",
    "        reconstruction_mean, reconstruction_var = self.decoder([z1, x[1]])     \n",
    "        \n",
    "        temp_var_r2 = SMALL_CONSTANT + tf.exp(reconstruction_var)\n",
    "        reconstruction_parameter = tfp.distributions.MultivariateNormalDiag(\n",
    "                                    loc=reconstruction_mean,\n",
    "                                    scale_diag= tf.sqrt(temp_var_r2))\n",
    "\n",
    "        kl_loss = tf.reduce_mean(mvn_q.log_prob(z1) - bimix_gauss.log_prob(z1))*kl_scaling\n",
    "        reconstruction_loss = -1.0*tf.reduce_mean(reconstruction_parameter.log_prob(y))\n",
    "        \n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea34d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae = CVAE(encoder1, encoder2, decoder)\n",
    "cvae.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5dba7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=1826.0387>,\n",
       " 'reconstruction_loss': <tf.Tensor: shape=(), dtype=float32, numpy=1829.6212>,\n",
       " 'kl_loss': <tf.Tensor: shape=(), dtype=float32, numpy=-3.582504>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvae.evaluate(data = [[y_train, x_train_poisson], y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d8c9e4-b35f-482a-9b6e-a3d8d3f7b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "data_poisson_array = x_train[n:n+1]/1000\n",
    "\n",
    "mean, log_var, weight = encoder2.predict(data_poisson_array)\n",
    "\n",
    "mean = tf.reshape(mean, (-1, gaussian_number, latent_dim))\n",
    "log_var = tf.reshape(log_var, (-1, gaussian_number, latent_dim))\n",
    "weight = tf.reshape(weight, (-1, gaussian_number))\n",
    "\n",
    "SMALL_CONSTANT = 1e-10\n",
    "temp_var = SMALL_CONSTANT + tf.exp(log_var)\n",
    "test_sampling = tfp.distributions.MixtureSameFamily(\n",
    "              mixture_distribution=tfp.distributions.Categorical(logits=weight),\n",
    "              components_distribution=tfp.distributions.MultivariateNormalDiag(\n",
    "              loc=mean,\n",
    "              scale_diag=tf.sqrt(temp_var)))\n",
    "\n",
    "sample_amount= 10000\n",
    "sample_times = 1\n",
    "prediction = []\n",
    "for i in range(sample_times):\n",
    "\n",
    "    Z3 = np.reshape(test_sampling.sample(sample_shape=(sample_amount)), (sample_amount, latent_dim))\n",
    "    target_array = np.reshape([data_poisson_array for i in range(sample_amount)], (sample_amount, 144))\n",
    "    reconstruction_mean, reconstruction_var = decoder.predict([Z3, target_array])\n",
    "    temp_var = SMALL_CONSTANT + tf.exp(reconstruction_var)\n",
    "    reconstruction_parameter = tfp.distributions.MultivariateNormalDiag(\n",
    "                            loc=reconstruction_mean,\n",
    "                            scale_diag= tf.sqrt(temp_var))\n",
    "    prediction.extend(reconstruction_parameter.sample().numpy())\n",
    "\n",
    "prediction = np.array(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346578e2-7369-4fe8-956f-c5b83c41c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = np.angle(prediction[:,3] + 1j*np.array(prediction[:,2]), deg=True)\n",
    "degree = [d if d > 0 else 360+d for d in degree]\n",
    "prediction2 = np.column_stack([prediction[:,:2]*180/np.pi, degree, prediction[:, 4:]])\n",
    "label = [\"theta13\", \"theta23\", 'deltacp', 'mumu', 'emu', 'etau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(len(label)):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    plt.hist(prediction2[:, i], bins=100)\n",
    "    plt.xlabel(label[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bbaae4-45c7-4d7a-8ee3-6ae57af6fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [1,6,11,16,21,7,12,17,22,13,18,23,19,24,25]\n",
    "k = 0\n",
    "plt.figure(figsize = (30, 30))\n",
    "for i in range(len(prediction2[0])):\n",
    "    for j in range(i+1, len(prediction2[0])):\n",
    "        plt.subplot(5, 5, index[k])\n",
    "        plt.hist2d(prediction2[:,i], prediction2[:,j], bins = 100)\n",
    "        plt.xlabel(label[i])\n",
    "        plt.ylabel(label[j])\n",
    "        plt.colorbar()\n",
    "        k += 1\n",
    "plt.savefig(path + '/dataset_v{}_{}'.format(dataset_number, n) + ' ML triangular density plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d3db5-1895-4202-88ae-8c3130ed2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = corner.corner(prediction2,\n",
    "                    levels = [[0.68] for i in range(15)],\n",
    "                    scale_hist=True,\n",
    "                    plot_datapoints=False,\n",
    "                    labels = label,\n",
    "                    plot_contours = True,\n",
    "                    plot_density = False,\n",
    "                    bins=100,\n",
    "                    smooth=True\n",
    "                    )\n",
    "figure.savefig(path + '/dataset_v{}_{}'.format(dataset_number, n) + ' ML triangular contour')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a863fc-b160-4c3c-abeb-a57f38d16221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(x, y, c, i, name):\n",
    "    plt.scatter(x, y, c=c)\n",
    "    plt.colorbar()\n",
    "    plt.title('data{}_chi-square value'.format(i))\n",
    "    plt.xlabel('$\\\\theta_{23}$ (degree)')\n",
    "    plt.ylabel('$\\delta_{cp}$ (degree)')\n",
    "    plt.clim(0,)\n",
    "    plt.savefig('./graph/dataset_v{}_{}'.format(dataset_number, n) + name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee50d3a-53f2-4b82-9bd6-11f94490552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n+1, n+2):\n",
    "    a = np.loadtxt('./chi_theta23_delta_contour/chi_theta23_delta_v{}.dat'.format(i))\n",
    "    arr = list(zip(*a))\n",
    "    x0 = sorted(set(arr[0]))\n",
    "    y0 = sorted(set(arr[1]))\n",
    "    z0 = np.reshape(arr[2], (81, 37))\n",
    "    f = RectBivariateSpline(x0, y0, z0)\n",
    "    xnew = np.linspace(35, 55, 1000)\n",
    "    ynew = np.linspace(0, 360, 1000)\n",
    "    znew = f(xnew, ynew)\n",
    "    mx, my = np.meshgrid(ynew, xnew)\n",
    "    x = np.reshape(mx, 1000000)\n",
    "    y = np.reshape(my, 1000000)\n",
    "    z = np.reshape(znew, 1000000)\n",
    "    plot_graph(y, x, z, i , 'chi-square value_full (RectBivariateSpline)')\n",
    "    loc = np.where(z < 5.99)\n",
    "    plot_graph(y[loc], x[loc], z[loc], i, 'chi-square value_two_sigma (RectBivariateSpline)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a01cff-120c-459f-87b9-df1364040d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(15,15))\n",
    "plot_axis = plt.subplot(2,2,1)\n",
    "plot_axis = plt.subplot(2,2,4)\n",
    "plot_axis = plt.subplot(2,2,3)\n",
    "r1 = corner.hist2d(prediction2[:, 1], prediction2[:, 2],\n",
    "                    levels=(0.95,),\n",
    "                    scale_hist=True,\n",
    "                    plot_datapoints=False,\n",
    "                    color='green',\n",
    "                    labels= [\"$\\\\theta_{23} $($^\\circ$)\", \"$\\delta_{cp} $($^\\circ$)\"],\n",
    "                    # range=[[35,55], [0, 360]],\n",
    "                    plot_contours = True,\n",
    "                    plot_density = False,\n",
    "                    fontsize=30,\n",
    "                    bins = [200, 200],\n",
    "                    label_kwargs={\"fontsize\": 30},\n",
    "                    smooth=True\n",
    "                   )\n",
    "one_sigma_region_boundary = np.where(znew > 5.99, 1, 0 )\n",
    "r2 = CS_1_sigma = plot_axis.contour(xnew, ynew, one_sigma_region_boundary.T, 0, colors='red', linestyles=\"-\", linewidths=1, label = 'Prediction')\n",
    "plot_axis.set_xlabel(\"$\\\\theta_{23} $($^\\circ$)\", fontsize = 20)\n",
    "plot_axis.set_ylabel(\"$\\delta_{cp} $($^\\circ$)\", fontsize = 20)\n",
    "r2.collections[0].set_label(\"GLOBES (1$\\sigma$)\")\n",
    "plt.legend(bbox_to_anchor=(2.3, 1.7), ncol=1,fontsize=20, markerscale=4, edgecolor = \"w\",fancybox=False, framealpha=0)\n",
    "plt.savefig(path + '/dataset_v{}_{}'.format(dataset_number, n) + 'theta23 vs deltacp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21099862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
