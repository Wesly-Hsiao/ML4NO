{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D , Lambda, Conv2D, Activation,Concatenate\n",
    "from tensorflow.keras.layers import ActivityRegularization, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam , SGD , Adagrad\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers , initializers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import NumpyArrayIterator\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only use the first GPU\n",
    "try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     logging.info(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "except RuntimeError as e:\n",
    "# Visible devices must be set before GPUs have been initialized\n",
    "    logging.info(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.load(\"./nsi_data/sample_nsi_regression_1e7_v1.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selection = 1 # 0 for all, 1 for lowE(<5GeV), 2 for high(>5GeV)\n",
    "\n",
    "if data_selection == 0:\n",
    "    data_all = np.column_stack([data['ve_dune'], data['vu_dune'], data['vebar_dune'], data['vubar_dune']])\n",
    "elif data_selection == 1:\n",
    "    data_all = np.column_stack([data['ve_dune'][:,:36], data['vu_dune'][:,:36], data['vebar_dune'][:,:36], data['vubar_dune'][:,:36]])\n",
    "elif data_selection == 2:\n",
    "    data_all = np.column_stack([data['ve_dune'][:,36:], data['vu_dune'][:,36:], data['vebar_dune'][:,36:], data['vubar_dune'][:,36:]])\n",
    "\n",
    "pre_target = np.column_stack([data['theta23']/5,data['delta']/180+5,data['mumu']+5,data['emu']+5,data['etau']+5])\n",
    "target = np.column_stack([pre_target, pre_target])\n",
    "\n",
    "x_train = data_all[:10000]\n",
    "y_train = target[:10000]\n",
    "x_train2 = data_all[10000:9000000]\n",
    "y_train2 = target[10000:9000000]\n",
    "x_test = data_all[9000000:]\n",
    "y_test = target[9000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nsi_degen_allparams\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def custom_mse(y_true, y_pred):\n",
    "    loss = K.square(y_pred - y_true)\n",
    "    loss1 = loss[0]+loss[1]+loss[2]+loss[3]+loss[4]\n",
    "    loss2 = loss[6]+loss[7]+loss[8]+loss[9]+loss[5]\n",
    "    return K.switch(loss1<loss2, loss1, loss2)\n",
    "\n",
    "\n",
    "def DNN_Model(name):\n",
    "    model_DNN = Sequential(name = \"Model_DNN_\"+str(name))\n",
    "\n",
    "    model_DNN.add(keras.Input(shape=(len(x_train[0]),), name = 'input'))\n",
    "    model_DNN.add(BatchNormalization(name = 'BatchNormalization'))\n",
    "    model_DNN.add(Dense(512, activation='relu', name = 'dense_1'))\n",
    "    model_DNN.add(Dense(512, activation='relu', name = 'dense_2'))\n",
    "\n",
    "    model_DNN.add(Dense(10, activation='relu', name = 'output'))\n",
    "    model_opt = keras.optimizers.Adam()\n",
    "    model_DNN.compile(loss=custom_mse,#keras.losses.binary_crossentropy\n",
    "                              optimizer=model_opt,\n",
    "                              metrics=['mse'])\n",
    "    model_DNN.summary()\n",
    "    return model_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_DNN_regression\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "BatchNormalization (BatchNor (None, 144)               576       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               74240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 342,602\n",
      "Trainable params: 342,314\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = DNN_Model(\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3951/3951 [==============================] - 15s 3ms/step - loss: 5.2567 - mse: 1.4724 - val_loss: 0.9013 - val_mse: 0.2702\n",
      "Epoch 2/20\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.9716 - mse: 0.3001 - val_loss: 0.9360 - val_mse: 0.2949\n",
      "Epoch 3/20\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.7353 - mse: 0.2304 - val_loss: 0.5919 - val_mse: 0.1854\n",
      "Epoch 4/20\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.5531 - mse: 0.1865 - val_loss: 0.5333 - val_mse: 0.1833\n",
      "Epoch 5/20\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.4559 - mse: 0.1581 - val_loss: 0.4104 - val_mse: 0.1446\n",
      "Epoch 6/20\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.3705 - mse: 0.1346 - val_loss: 0.3213 - val_mse: 0.1179\n",
      "Epoch 7/20\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.3266 - mse: 0.1211 - val_loss: 0.2727 - val_mse: 0.1056\n",
      "Epoch 8/20\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.2949 - mse: 0.1107 - val_loss: 0.2791 - val_mse: 0.1082\n",
      "Epoch 9/20\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.2738 - mse: 0.1058 - val_loss: 0.2424 - val_mse: 0.0945\n",
      "Epoch 10/20\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.2474 - mse: 0.0954 - val_loss: 0.2854 - val_mse: 0.1092\n",
      "Epoch 11/20\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.2335 - mse: 0.0918 - val_loss: 0.2210 - val_mse: 0.0884\n",
      "Epoch 12/20\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.2135 - mse: 0.0869 - val_loss: 0.2103 - val_mse: 0.0879\n",
      "Epoch 13/20\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.2038 - mse: 0.0838 - val_loss: 0.2021 - val_mse: 0.0798\n",
      "Epoch 14/20\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.1920 - mse: 0.0803 - val_loss: 0.1655 - val_mse: 0.0713\n",
      "Epoch 15/20\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.1881 - mse: 0.0785 - val_loss: 0.1706 - val_mse: 0.0737\n",
      "Epoch 16/20\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.1734 - mse: 0.0754 - val_loss: 0.1535 - val_mse: 0.0676\n",
      "Epoch 17/20\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1691 - mse: 0.0717 - val_loss: 0.1376 - val_mse: 0.0620\n",
      "Epoch 18/20\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1654 - mse: 0.0697 - val_loss: 0.1439 - val_mse: 0.0634\n",
      "Epoch 19/20\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.1588 - mse: 0.0680 - val_loss: 0.1308 - val_mse: 0.0606\n",
      "Epoch 20/20\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.1514 - mse: 0.0668 - val_loss: 0.1505 - val_mse: 0.0685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fae800b20b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "model.fit(x_train2, y_train2,\n",
    "           validation_split = 0.1,\n",
    "           batch_size=batch_size,\n",
    "           epochs=20,\n",
    "           verbose=1,\n",
    "           shuffle = True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_index = 1\n",
    "while os.path.isfile('./models/{}_{}.h5'.format(model_name, model_index)):\n",
    "    model_index += 1\n",
    "model.save('./models/{}_{}.h5'.format(model_name, model_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.1541 - mse: 0.0685\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1457 - mse: 0.0652 - val_loss: 0.1431 - val_mse: 0.0637\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1416 - mse: 0.0632 - val_loss: 0.1411 - val_mse: 0.0641\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1368 - mse: 0.0613 - val_loss: 0.1268 - val_mse: 0.0601\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1364 - mse: 0.0608 - val_loss: 0.1666 - val_mse: 0.0678\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1316 - mse: 0.0598 - val_loss: 0.1308 - val_mse: 0.0607\n",
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.1347 - mse: 0.0607\n",
      "31250/31250 [==============================] - 55s 2ms/step - loss: 0.1347 - mse: 0.0607\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1309 - mse: 0.0589 - val_loss: 0.1150 - val_mse: 0.0581\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1257 - mse: 0.0575 - val_loss: 0.0972 - val_mse: 0.0484\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1210 - mse: 0.0557 - val_loss: 0.1050 - val_mse: 0.0506\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1191 - mse: 0.0552 - val_loss: 0.1223 - val_mse: 0.0606\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1158 - mse: 0.0541 - val_loss: 0.1123 - val_mse: 0.0537\n",
      "31250/31250 [==============================] - 55s 2ms/step - loss: 0.1195 - mse: 0.0535\n",
      "31250/31250 [==============================] - 56s 2ms/step - loss: 0.1195 - mse: 0.0535\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1149 - mse: 0.0539 - val_loss: 0.1073 - val_mse: 0.0548\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.1127 - mse: 0.0526 - val_loss: 0.1024 - val_mse: 0.0493\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1133 - mse: 0.0528 - val_loss: 0.1151 - val_mse: 0.0527\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1080 - mse: 0.0513 - val_loss: 0.1014 - val_mse: 0.0474\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1071 - mse: 0.0514 - val_loss: 0.0890 - val_mse: 0.0437\n",
      "31250/31250 [==============================] - 55s 2ms/step - loss: 0.0897 - mse: 0.0437\n",
      "31250/31250 [==============================] - 54s 2ms/step - loss: 0.0897 - mse: 0.0437\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1027 - mse: 0.0497 - val_loss: 0.0963 - val_mse: 0.0451\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1031 - mse: 0.0490 - val_loss: 0.0961 - val_mse: 0.0472\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1031 - mse: 0.0491 - val_loss: 0.1032 - val_mse: 0.0525\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1000 - mse: 0.0488 - val_loss: 0.1021 - val_mse: 0.0484\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1019 - mse: 0.0478 - val_loss: 0.0854 - val_mse: 0.0457\n",
      "31250/31250 [==============================] - 55s 2ms/step - loss: 0.0890 - mse: 0.0456\n",
      "31250/31250 [==============================] - 55s 2ms/step - loss: 0.0891 - mse: 0.0456\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 14s 3ms/step - loss: 0.0983 - mse: 0.0470 - val_loss: 0.0952 - val_mse: 0.0487\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0988 - mse: 0.0474 - val_loss: 0.0917 - val_mse: 0.0475\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0956 - mse: 0.0461 - val_loss: 0.0806 - val_mse: 0.0402\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0925 - mse: 0.0455 - val_loss: 0.0818 - val_mse: 0.0407\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0951 - mse: 0.0455 - val_loss: 0.0942 - val_mse: 0.0462\n",
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.0938 - mse: 0.0461\n",
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.0940 - mse: 0.0461\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 15s 4ms/step - loss: 0.0908 - mse: 0.0441 - val_loss: 0.0825 - val_mse: 0.0425\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0910 - mse: 0.0445 - val_loss: 0.0756 - val_mse: 0.0380\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0928 - mse: 0.0446 - val_loss: 0.0860 - val_mse: 0.0465\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0891 - mse: 0.0445 - val_loss: 0.0862 - val_mse: 0.0431\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0881 - mse: 0.0434 - val_loss: 0.0772 - val_mse: 0.0417\n",
      "31250/31250 [==============================] - 55s 2ms/step - loss: 0.0798 - mse: 0.0417\n",
      "31250/31250 [==============================] - 56s 2ms/step - loss: 0.0800 - mse: 0.0418\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 14s 3ms/step - loss: 0.0859 - mse: 0.0426 - val_loss: 0.0890 - val_mse: 0.0439\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0860 - mse: 0.0426 - val_loss: 0.0794 - val_mse: 0.0430\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0845 - mse: 0.0423 - val_loss: 0.0666 - val_mse: 0.0369\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0848 - mse: 0.0428 - val_loss: 0.0722 - val_mse: 0.0401\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0839 - mse: 0.0424 - val_loss: 0.0902 - val_mse: 0.0446\n",
      "31250/31250 [==============================] - 56s 2ms/step - loss: 0.0931 - mse: 0.0443\n",
      "31250/31250 [==============================] - 54s 2ms/step - loss: 0.0934 - mse: 0.0444\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0825 - mse: 0.0422 - val_loss: 0.0766 - val_mse: 0.0418\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0832 - mse: 0.0419 - val_loss: 0.0818 - val_mse: 0.0426\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0793 - mse: 0.0414 - val_loss: 0.0749 - val_mse: 0.0389\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0798 - mse: 0.0409 - val_loss: 0.0769 - val_mse: 0.0424\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0795 - mse: 0.0405 - val_loss: 0.0900 - val_mse: 0.0420\n",
      "31250/31250 [==============================] - 52s 2ms/step - loss: 0.0917 - mse: 0.0419\n",
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.0920 - mse: 0.0420\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0808 - mse: 0.0405 - val_loss: 0.0717 - val_mse: 0.0370\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0801 - mse: 0.0408 - val_loss: 0.0694 - val_mse: 0.0388\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0792 - mse: 0.0402 - val_loss: 0.0751 - val_mse: 0.0384\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0790 - mse: 0.0396 - val_loss: 0.0705 - val_mse: 0.0361\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0779 - mse: 0.0398 - val_loss: 0.0649 - val_mse: 0.0356\n",
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.0664 - mse: 0.0354\n",
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.0669 - mse: 0.0357\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0801 - mse: 0.0402 - val_loss: 0.0668 - val_mse: 0.0359\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0750 - mse: 0.0392 - val_loss: 0.0750 - val_mse: 0.0389\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0772 - mse: 0.0405 - val_loss: 0.0711 - val_mse: 0.0385\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0756 - mse: 0.0390 - val_loss: 0.0820 - val_mse: 0.0386\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0787 - mse: 0.0390 - val_loss: 0.0554 - val_mse: 0.0318\n",
      "31250/31250 [==============================] - 52s 2ms/step - loss: 0.0574 - mse: 0.0317\n",
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.0583 - mse: 0.0321\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0752 - mse: 0.0396 - val_loss: 0.0653 - val_mse: 0.0368\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0769 - mse: 0.0391 - val_loss: 0.0822 - val_mse: 0.0426\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0735 - mse: 0.0384 - val_loss: 0.0773 - val_mse: 0.0421\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0748 - mse: 0.0387 - val_loss: 0.0686 - val_mse: 0.0404\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0761 - mse: 0.0397 - val_loss: 0.0680 - val_mse: 0.0382\n",
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.0697 - mse: 0.0381\n",
      "31250/31250 [==============================] - 52s 2ms/step - loss: 0.0711 - mse: 0.0387\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0751 - mse: 0.0399 - val_loss: 0.0688 - val_mse: 0.0376\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0778 - mse: 0.0398 - val_loss: 0.0614 - val_mse: 0.0338\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0718 - mse: 0.0387 - val_loss: 0.0679 - val_mse: 0.0380\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0735 - mse: 0.0398 - val_loss: 0.0833 - val_mse: 0.0447\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0726 - mse: 0.0388 - val_loss: 0.0705 - val_mse: 0.0385\n",
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.0724 - mse: 0.0386\n",
      "20463/31250 [==================>...........] - ETA: 18s - loss: 0.0742 - mse: 0.0396"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.0747 - mse: 0.0395\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 15s 4ms/step - loss: 0.0790 - mse: 0.0402 - val_loss: 0.0750 - val_mse: 0.0378\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0762 - mse: 0.0402 - val_loss: 0.0622 - val_mse: 0.0395\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0778 - mse: 0.0402 - val_loss: 0.0696 - val_mse: 0.0378\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0742 - mse: 0.0393 - val_loss: 0.0676 - val_mse: 0.0380\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0761 - mse: 0.0394 - val_loss: 0.0780 - val_mse: 0.0426\n",
      "31250/31250 [==============================] - 54s 2ms/step - loss: 0.0799 - mse: 0.0439\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0775 - mse: 0.0402 - val_loss: 0.0854 - val_mse: 0.0448\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0797 - mse: 0.0412 - val_loss: 0.0729 - val_mse: 0.0404\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0755 - mse: 0.0416 - val_loss: 0.0734 - val_mse: 0.0391\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0767 - mse: 0.0412 - val_loss: 0.0752 - val_mse: 0.0438\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0742 - mse: 0.0403 - val_loss: 0.0697 - val_mse: 0.0393\n",
      "30922/31250 [============================>.] - ETA: 0s - loss: 0.0700 - mse: 0.0391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0918 - mse: 0.0467 - val_loss: 0.0865 - val_mse: 0.0435\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0885 - mse: 0.0463 - val_loss: 0.0910 - val_mse: 0.0482\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.0865 - mse: 0.0456 - val_loss: 0.0884 - val_mse: 0.0437\n",
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.0882 - mse: 0.0437\n",
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.0979 - mse: 0.0482\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.0987 - mse: 0.0510 - val_loss: 0.0961 - val_mse: 0.0489\n",
      "Epoch 2/5\n",
      "2210/3951 [===============>..............] - ETA: 4s - loss: 0.0990 - mse: 0.0518"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31250/31250 [==============================] - 52s 2ms/step - loss: 0.1038 - mse: 0.0526\n",
      "31250/31250 [==============================] - 52s 2ms/step - loss: 0.1230 - mse: 0.0607\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1388 - mse: 0.0660 - val_loss: 0.1263 - val_mse: 0.0644\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1352 - mse: 0.0651 - val_loss: 0.1391 - val_mse: 0.0651\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.1336 - mse: 0.0638 - val_loss: 0.1284 - val_mse: 0.0612\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1298 - mse: 0.0631 - val_loss: 0.1109 - val_mse: 0.0580\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1328 - mse: 0.0630 - val_loss: 0.1326 - val_mse: 0.0628\n",
      " 6784/31250 [=====>........................] - ETA: 41s - loss: 0.1388 - mse: 0.0628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31250/31250 [==============================] - 53s 2ms/step - loss: 0.2115 - mse: 0.0894\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.1993 - mse: 0.0865 - val_loss: 0.2003 - val_mse: 0.0879\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.1928 - mse: 0.0835 - val_loss: 0.1837 - val_mse: 0.0830\n",
      "Epoch 3/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.1893 - mse: 0.0820 - val_loss: 0.2022 - val_mse: 0.0840\n",
      "Epoch 4/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.1864 - mse: 0.0825 - val_loss: 0.1737 - val_mse: 0.0782\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.1873 - mse: 0.0809 - val_loss: 0.1812 - val_mse: 0.0804\n",
      "31250/31250 [==============================] - 52s 2ms/step - loss: 0.1837 - mse: 0.0802\n",
      "17166/31250 [===============>..............] - ETA: 23s - loss: 0.2166 - mse: 0.0931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.2693 - mse: 0.1072 - val_loss: 0.2686 - val_mse: 0.1047\n",
      "Epoch 5/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.2708 - mse: 0.1073 - val_loss: 0.2517 - val_mse: 0.1019\n",
      "31250/31250 [==============================] - 52s 2ms/step - loss: 0.2482 - mse: 0.1017\n",
      "31250/31250 [==============================] - 52s 2ms/step - loss: 0.2921 - mse: 0.1180\n",
      "Epoch 1/5\n",
      "3951/3951 [==============================] - 13s 3ms/step - loss: 0.3091 - mse: 0.1204 - val_loss: 0.2930 - val_mse: 0.1173\n",
      "Epoch 2/5\n",
      "3951/3951 [==============================] - 12s 3ms/step - loss: 0.3027 - mse: 0.1198 - val_loss: 0.2944 - val_mse: 0.1136\n",
      "Epoch 3/5\n",
      "2055/3951 [==============>...............] - ETA: 5s - loss: 0.3039 - mse: 0.1184"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scale_steps = np.logspace(-3, 0, 30)\n",
    "before_train_loss = []\n",
    "after_train_loss = []\n",
    "\n",
    "for scale in scale_steps:\n",
    "    x_train2_gen = np.random.normal(x_train2, np.sqrt(x_train2)*scale)\n",
    "    x_test_gen = np.random.normal(x_test, np.sqrt(x_test)*scale)\n",
    "\n",
    "    before_train_loss.append(model.evaluate(x_test_gen, y_test)[0])\n",
    "\n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "               validation_split = 0.1,\n",
    "               batch_size=batch_size,\n",
    "               epochs=5,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "    \n",
    "    after_train_loss.append(model.evaluate(x_test_gen, y_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "furthur_index = 1\n",
    "path = './models_furthurTrain/{}_{}_{}.h5'\n",
    "while os.path.isfile(path.format(model_name, model_index, furthur_index)):\n",
    "    index += 1\n",
    "model.save(path.format(model_name, model_index, furthur_index))\n",
    "outfile = {'scale_steps': scale_steps,\n",
    "           'before_train_loss': before_train_loss,\n",
    "           'after_train_loss' :after_train_loss}\n",
    "np.save(file = './models_furthurTrain/{}_{}_{}_result.npy'.format(model_name, model_index, furthur_index),\n",
    "        arr = outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3951/3951 [==============================] - 16s 4ms/step - loss: 0.3711 - mse: 0.1396 - val_loss: 0.3779 - val_mse: 0.1448\n",
      "3951/3951 [==============================] - 16s 4ms/step - loss: 0.3631 - mse: 0.1396 - val_loss: 0.3734 - val_mse: 0.1383\n",
      "3951/3951 [==============================] - 16s 4ms/step - loss: 0.3661 - mse: 0.1394 - val_loss: 0.3531 - val_mse: 0.1372\n",
      "3951/3951 [==============================] - 16s 4ms/step - loss: 0.3680 - mse: 0.1390 - val_loss: 0.3619 - val_mse: 0.1373\n",
      "3951/3951 [==============================] - 19s 5ms/step - loss: 0.3645 - mse: 0.1387 - val_loss: 0.3537 - val_mse: 0.1357\n",
      "3951/3951 [==============================] - 16s 4ms/step - loss: 0.3653 - mse: 0.1379 - val_loss: 0.3564 - val_mse: 0.1336\n",
      "3951/3951 [==============================] - 16s 4ms/step - loss: 0.3562 - mse: 0.1373 - val_loss: 0.3631 - val_mse: 0.1378\n",
      "3951/3951 [==============================] - 16s 4ms/step - loss: 0.3628 - mse: 0.1369 - val_loss: 0.3402 - val_mse: 0.1316\n",
      "3951/3951 [==============================] - 15s 4ms/step - loss: 0.3535 - mse: 0.1352 - val_loss: 0.3661 - val_mse: 0.1364\n",
      "3951/3951 [==============================] - 16s 4ms/step - loss: 0.3564 - mse: 0.1367 - val_loss: 0.3492 - val_mse: 0.1354\n",
      " 7960/31250 [======>.......................] - ETA: 43s - loss: 0.3476 - mse: 0.1351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_test2_gen = np.random.poisson(x_test)\n",
    "\n",
    "for i in range(10):\n",
    "    x_train2_gen = np.random.poisson(x_train2)\n",
    "    \n",
    "    model.fit(x_train2_gen, y_train2,\n",
    "              validation_split=0.1,\n",
    "               batch_size=batch_size,\n",
    "               epochs=1,\n",
    "               verbose=1,\n",
    "               shuffle = True\n",
    "             )\n",
    "model.evaluate(x_test2_gen, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "path = './models_PoissonTrain/{}_{}_{}_{}.h5'\n",
    "while os.path.isfile(path.format(model_name, model_index, furthur_index, index)):\n",
    "    index += 1\n",
    "model.save(path.format(model_name, model_index, furthur_index, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
